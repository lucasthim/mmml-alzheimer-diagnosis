{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20211012_Run_CNN_Experiments_02.ipynb","provenance":[{"file_id":"1wpK88gLqCTxaM4Shmr41Ad2VhF0goWXe","timestamp":1602044624429},{"file_id":"1knFP_EJxyRKKLD-JzyJ9ZxEarFuUSYRC","timestamp":1602044559127}],"collapsed_sections":["Ze1UpiX_M9ll","69JHv8ext4my","zRnkoVqUMPLy","rtjqRuDhMm_w","-N0N5unJwRLu","2nYka2QtwRLu","tXnUL-amwRLw","A5l_XNYMxBOk","YaAMsulMxBOm","IJMsMZ58wIrb","jd0FFIazKlp7","lzKpQvscC0ou","UnqR_CGXG_F-"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"3ie1orW8lnWb"},"source":["https://discuss.pytorch.org/t/loaded-model-returns-different-predictions/77588/2\n","\n","https://discuss.pytorch.org/t/model-shows-different-predictions-after-training-without-weight-update/75877/5\n","\n"]},{"cell_type":"code","metadata":{"id":"1UFjI1Rts6fx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634168575998,"user_tz":180,"elapsed":28374,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"c3adb492-c523-46ad-95fa-55704f0095ae"},"source":["!pip install antspyx"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting antspyx\n","  Downloading antspyx-0.2.9-cp37-cp37m-manylinux1_x86_64.whl (300.4 MB)\n","\u001b[K     |████████████████████████████████| 300.4 MB 15 kB/s \n","\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from antspyx) (0.16.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from antspyx) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from antspyx) (1.4.1)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from antspyx) (0.10.2)\n","Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from antspyx) (3.0.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from antspyx) (7.1.2)\n","Collecting webcolors\n","  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from antspyx) (0.22.2.post1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from antspyx) (3.2.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from antspyx) (3.13)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from antspyx) (1.1.5)\n","Collecting chart-studio\n","  Downloading chart_studio-1.1.0-py3-none-any.whl (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 3.6 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from chart-studio->antspyx) (1.15.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from chart-studio->antspyx) (4.4.1)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from chart-studio->antspyx) (1.3.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from chart-studio->antspyx) (2.23.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->antspyx) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->antspyx) (1.3.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->antspyx) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->antspyx) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->antspyx) (2018.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio->antspyx) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio->antspyx) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio->antspyx) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio->antspyx) (3.0.4)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->antspyx) (1.1.1)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->antspyx) (2.4.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->antspyx) (2.6.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->antspyx) (1.0.1)\n","Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->antspyx) (0.5.2)\n","Installing collected packages: webcolors, chart-studio, antspyx\n","Successfully installed antspyx-0.2.9 chart-studio-1.1.0 webcolors-1.11.1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c2S_oZ94fHlT","executionInfo":{"status":"ok","timestamp":1634168650403,"user_tz":180,"elapsed":74410,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"90c44c36-d508-4ba4-8955-1270ac0263a2"},"source":["from google.colab import drive\n","import os\n","%load_ext autoreload\n","%autoreload 2\n","\n","drive.mount('/content/gdrive', force_remount=True)\n","os.chdir('/content/gdrive/MyDrive/Lucas_Thimoteo/')"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","metadata":{"id":"L6QJIUmIEyar"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"AMJYmnZ2up8H","executionInfo":{"status":"ok","timestamp":1634168680704,"user_tz":180,"elapsed":992,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}}},"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import scipy.stats as sp\n","from joblib import dump, load\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","plt.style.use('seaborn')\n","pd.set_option('display.max_columns', 150)\n","pd.set_option('display.max_rows', 150)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"VuJsQRFVTIEz","executionInfo":{"status":"ok","timestamp":1634168680710,"user_tz":180,"elapsed":14,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}}},"source":["from pathlib import Path\n","def list_available_images(input_dir,file_format = '.nii',verbose=1):\n","\n","    '''\n","    List full path to available images.\n","    \n","    Params\n","    ---------------------\n","    \n","    input_dir: input directory to read the image files\n","    \n","    file_format: file format of the images\n","    \n","    \n","    Returns\n","    ---------------------\n","    \n","    selected_images: Selected images that can be processed\n","    \n","    available_images: All the available images in the provided directory\n","    \n","    masks_and_wrong_images: Masks and other images that will not be processed\n","    '''\n","\n","    available_images = []\n","    if verbose > 0: print(\"Looking for MRI images in path:\",input_dir,'\\n')\n","    \n","    available_images = list(Path(input_dir).rglob(\"*\"+file_format))\n","    if verbose > 0: print(\"Found a total of \",len(available_images),\" images.\")\n","\n","    masks_and_wrong_images = list(Path(input_dir).rglob(\"*[Mm]ask*\"+file_format))\n","    if verbose > 0: print(\"Found a total of \",len(masks_and_wrong_images),\" mask images.\")\n","    \n","    if verbose > 0: print(\"Available images to process: \",len(available_images) - len(masks_and_wrong_images),\"\\n\")\n","    selected_images = list(set(available_images) - set(masks_and_wrong_images))\n","    \n","    if selected_images: \n","        selected_images = [x.as_posix() for x in selected_images]\n","\n","    if available_images: \n","        available_images = [x.as_posix() for x in available_images]\n","\n","    if masks_and_wrong_images:\n","        masks_and_wrong_images = [x.as_posix() for x in masks_and_wrong_images]\n","        \n","    return selected_images,available_images,masks_and_wrong_images\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"2s1de7MjTah5","executionInfo":{"status":"ok","timestamp":1634168680712,"user_tz":180,"elapsed":15,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}}},"source":["# os.chdir('/content/gdrive/MyDrive/Lucas_Thimoteo/data/mri/processed')\n","# !ls"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"nEGxWlH_XuD-","executionInfo":{"status":"ok","timestamp":1634168680712,"user_tz":180,"elapsed":13,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}}},"source":["# !git config --global user.password \"0fbeca7ef860e10864645575aaddb4146df87f6f\"\n","# !git config --global user.email \"lucasthim@yahoo.com\"\n","# !git config --global user.name \"Lucas Thimoteo\"\n","# !git config --global credential.helper cache"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"lGLE8X2WYBhd","executionInfo":{"status":"ok","timestamp":1634168680713,"user_tz":180,"elapsed":13,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}}},"source":["# !git clone https://lucasthim:0fbeca7ef860e10864645575aaddb4146df87f6f@github.com/lucasthim/mmml-alzheimer-diagnosis.git"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"TQDjo2g_imD-","executionInfo":{"status":"ok","timestamp":1634168680714,"user_tz":180,"elapsed":14,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}}},"source":["# os.chdir('/content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/')\n","# !git status"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"SanbBzRv2kS-","executionInfo":{"status":"ok","timestamp":1634168680714,"user_tz":180,"elapsed":13,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}}},"source":["# os.chdir('/content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/src/data_preparation/')\n","# import mri_metadata_preparation\n","# os.chdir('/content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/src/model_training')"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"r_aYRZJ4l-3d","executionInfo":{"status":"ok","timestamp":1634168680715,"user_tz":180,"elapsed":13,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}}},"source":["# df_cor = pd.read_csv('/content/gdrive/MyDrive/Lucas_Thimoteo/data/reference/PROCESSED_MRI_REFERENCE_20211011_1730.csv')\n","# df_axi_1 = pd.read_csv('/content/gdrive/MyDrive/Lucas_Thimoteo/data/reference/PROCESSED_MRI_REFERENCE_20211011_1856.csv')\n","# df_sag_1 = pd.read_csv('/content/gdrive/MyDrive/Lucas_Thimoteo/data/reference/PROCESSED_MRI_REFERENCE_20211011_1954.csv')\n","# df_ref = pd.concat([df_cor,df_axi_1,df_sag_1])\n","# now = datetime.now().strftime(\"%Y%m%d_%H%M\")\n","# df_ref.to_csv(f'/content/gdrive/MyDrive/Lucas_Thimoteo/data/reference/PROCESSED_MRI_REFERENCE_ALL_ORIENTATIONS_{now}.csv',index=False)\n","# f'/content/gdrive/MyDrive/Lucas_Thimoteo/data/reference/PROCESSED_MRI_REFERENCE_ALL_ORIENTATIONS_{now}.csv'"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"UEkPGlYRNkfX","executionInfo":{"status":"ok","timestamp":1634168681066,"user_tz":180,"elapsed":364,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}}},"source":["os.chdir('/content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/src/data_preparation/')\n","# import mri_metadata_preparation"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"piLiNHOfPrxw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634168685039,"user_tz":180,"elapsed":3977,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"933d2e59-6217-4cd2-bf42-c5a91b0121ba"},"source":["import os\n","import sys\n","import time\n","import random\n","import argparse\n","from pathlib import Path\n","from datetime import datetime\n","\n","import numpy as np\n","import pandas as pd\n","\n","from mri_augmentation import *\n","sys.path.append(\"./../utils\")\n","from base_mri import *\n","from utils import *\n","\n","def generate_mri_dataset_reference(mri_reference_path,\n","                                output_path,\n","                                orientation = 'coronal',\n","                                orientation_slice = 50,\n","                                num_sampled_images = 5,\n","                                sampling_range = 3,\n","                                num_rotations = 3,\n","                                save_reference_file = True):\n","\n","    '''\n","    Execute MRI metadata preparation for training the deep learning model. The final image will be generated only during training/test/validation step.\n","\n","    Main Steps:\n","\n","    - Select orientation of training.\n","    \n","    - Select slice indication.\n","\n","    - Executes Data Augmentation (optional) generating more images based on rotation and flipping. \n","\n","    Parameters\n","    ----------\n"," \n","    mri_reference_path: path of the processed MRI reference file.\n","    \n","    output_path: path to save the metadata reference file.\n","    \n","    orientation: Orientation to slice the image. Values can be \"coronal\", \"sagittal\" or \"axial\".\n","    \n","    orientation_slice: Mark to slice the 3D image. Values range from 0 to 100. TODO: fix future bug if sampling_range is outside of the image.\n","    \n","    num_sampled_images: Number of images to sample.\n","    \n","    sampling_range: Range to sample new images from original 3D image, with reference to the orientation_slice.\n","\n","    num_rotations: Number of different rotations to augment original image.\n","\n","    save_reference_file: Flag to save the reference file or not.\n","    \n","    '''\n","\n","    df_mri_reference = pd.read_csv(mri_reference_path)\n","\n","    if not os.path.exists(output_path):\n","        print(\"Creating output path... \\n\")\n","        os.makedirs(output_path)\n","\n","    df_mri_dataset = df_mri_reference.query(\"ORIENTATION == @orientation and VALID_IMAGE == True\")\n","    df_mri_dataset['MAIN_SLICE'] = orientation_slice\n","    images= df_mri_reference['IMAGE_DATA_ID'].unique().tolist()\n","    \n","    print(\"Creating augmented samples...\")\n","    df_samples = generate_augmented_slices(orientation_slice,sampling_range,num_sampled_images,preprocessed_images = images)\n","    df_mri_dataset = df_mri_dataset.merge(df_samples,on=['IMAGE_DATA_ID','SLICE'],how='inner').reset_index(drop=True)\n","    df_mri_dataset['SLICE_ID'] = df_mri_dataset['IMAGE_DATA_ID'] + '_' + df_mri_dataset['SLICE'].astype(str)\n","    \n","    if num_rotations > 0:\n","        print(\"Creating 2d image rotations...\")\n","        df_samples_rot = generate_augmented_rotations(num_rotations=num_rotations,preprocessed_images=df_mri_dataset['SLICE_ID'])\n","        df_mri_dataset = df_mri_dataset.merge(df_samples_rot,on='SLICE_ID')\n","\n","    print(\"Creating final reference file for prepared images...\")\n","    if save_reference_file:\n","        now = datetime.now().strftime(\"%Y%m%d_%H%M\")\n","        reference_file_name = 'PROCESSED_MRI_REFERENCE_' + orientation + '_' + str(orientation_slice) + '_samples_around_slice_' + str(num_sampled_images) +'_num_rotations_' + str(num_rotations) + '_'+ now + '.csv'\n","        df_mri_dataset.to_csv(output_path+reference_file_name,index=False)\n","        print(\"Processed MRI reference file saved at:\",output_path+reference_file_name)\n","    return df_mri_dataset\n","\n","def generate_augmented_slices(orientation_slice,sampling_range,num_sampled_images,preprocessed_images):\n","    random.seed(a=None, version=2)\n","    sampling_population = list(set(range(orientation_slice-sampling_range,orientation_slice+sampling_range+1)) - set([orientation_slice]))\n","    samples = [(img,random.sample(population= sampling_population,k=num_sampled_images)+[orientation_slice]) for img in preprocessed_images]\n","    df_samples  = pd.DataFrame(samples,columns=['IMAGE_DATA_ID','SLICE'])\n","    return df_samples.explode('SLICE').reset_index(drop=True)\n","\n","def generate_augmented_rotations(num_rotations,preprocessed_images):\n","    random.seed(a=None, version=2)\n","    samples = [(img,random.sample(population= list(np.arange(-15,16,2)) ,k=num_rotations) + [0]) for img in preprocessed_images]\n","    df_samples  = pd.DataFrame(samples,columns=['SLICE_ID','ROTATION_ANGLE'])\n","    return df_samples.explode('ROTATION_ANGLE').reset_index(drop=True)\n"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xl9AGinQQQv6","executionInfo":{"status":"ok","timestamp":1634168687970,"user_tz":180,"elapsed":2933,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"c72756fd-b38e-417a-c61f-ef20563f5c73"},"source":["mri_reference = '/content/gdrive/MyDrive/Lucas_Thimoteo/data/reference/PROCESSED_MRI_REFERENCE_ALL_ORIENTATIONS_20211012_0206.csv'\n","output_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/data/reference/mri_experiments/'\n","df = generate_mri_dataset_reference(mri_reference_path = mri_reference,\n","                                output_path = output_path,\n","                                orientation = 'coronal',\n","                                orientation_slice = 50,\n","                                num_sampled_images = 3,\n","                                sampling_range = 3,\n","                                num_rotations = 0,\n","                                save_reference_file = False)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating augmented samples...\n","Creating final reference file for prepared images...\n"]}]},{"cell_type":"code","metadata":{"id":"CYYfcSx9y52J","executionInfo":{"status":"ok","timestamp":1634168700799,"user_tz":180,"elapsed":12834,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}}},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from scipy import ndimage\n","from torch.utils.data import Dataset\n","from torchvision import transforms as T\n","\n","import numpy as np\n","\n","class MRIDataset(Dataset):\n","\n","     '''\n","     Builds a dataset loader component for PyTorch with the MRIs based on the filepath.\n","     '''\n","\n","     def __init__(self, reference_table,target_column = 'MACRO_GROUP'):\n","          \n","          '''\n","          Initialization of the component\n","\n","          Parameters\n","          ----------\n","\n","          reference_table: Pandas DataFrame containing the reference for the subjects, images and their labels\n","\n","          '''\n","          self.target_column = target_column\n","          self.reference_table = reference_table\n","          # self.transform_train = self.T.Compose([\n","          #      transforms.RandomCrop(32, padding=4),\n","          #      transforms.RandomRotation(degrees=15),\n","          #      transforms.ToTensor(),\n","          #      transforms.Normalize(rgb_mean, rgb_std),\n","          # ])\n","     def __len__(self):\n","          'Denotes the total number of samples'\n","          return self.reference_table.shape[0]\n","\n","     def __getitem__(self, index):\n","          'Generates one sample of data'\n","          \n","          # Select sample\n","          sample = self.reference_table.iloc[index]\n","\n","          # Load data and get label\n","          X = np.load(sample['IMAGE_PATH'])['arr_0']\n","\n","          if 'ROTATION_ANGLE' in sample.index and sample['ROTATION_ANGLE'] != 0:\n","               X = ndimage.rotate(X, sample['ROTATION_ANGLE'], reshape=False)\n","                         \n","          X = X/X.max()\n","          y = sample[self.target_column]\n","          return X, y\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"d6FYsl1ltL11","executionInfo":{"status":"ok","timestamp":1634168700800,"user_tz":180,"elapsed":13,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}}},"source":["os.chdir('/content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/src/model_training/')\n","# import mri_metadata_preparation"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"EDsyH9tGxlqq","executionInfo":{"status":"ok","timestamp":1634168700801,"user_tz":180,"elapsed":10,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}}},"source":["import torch\n","# from torch.nn.functional import one_hot\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","from torch.nn import Linear, ReLU, BCEWithLogitsLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, AdaptiveAvgPool2d\n","from torch.optim import Adam, SGD\n","\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda, Compose\n","import torchvision.models as models\n","\n","class SuperShallowCNN(Module):\n","    def __init__(self):\n","        super(SuperShallowCNN, self).__init__()\n","        self.features = Sequential(\n","            Conv2d(in_channels =1, out_channels =8, kernel_size=3, stride=1, padding=1),\n","            BatchNorm2d(num_features=8),\n","            ReLU(inplace=True),\n","            MaxPool2d(2,2),\n","\n","            Conv2d(in_channels =8, out_channels =16, kernel_size=3, stride=1, padding=0),\n","            BatchNorm2d(num_features=16),\n","            ReLU(inplace=True),\n","            MaxPool2d(2,2),\n","            \n","            Conv2d(in_channels =16, out_channels =32, kernel_size=3, stride=1, padding=0),\n","            BatchNorm2d(num_features=32),\n","            ReLU(inplace=True),\n","            MaxPool2d(2,2),\n","            \n","            Conv2d(in_channels =32, out_channels =64, kernel_size=3, stride=1, padding=0),\n","            BatchNorm2d(num_features=64),\n","            ReLU(inplace=True),\n","            MaxPool2d(2,2),\n","\n","            Conv2d(in_channels =64, out_channels =128, kernel_size=3, stride=1, padding=0),\n","            ReLU(inplace=True)\n","        )\n","        self.avgpool = AdaptiveAvgPool2d(output_size=(4, 4))\n","        self.classifier = Sequential(\n","            # Remember changing the x.view() number as well. It needs to be flattenend!\n","            Linear(in_features=128*4*4, out_features=128, bias=True),\n","            ReLU(inplace=True),\n","            # Dropout(p=0.5, inplace=False),\n","            Linear(in_features=128, out_features=64, bias=True),\n","            ReLU(inplace=True),\n","            # Dropout(p=0.5, inplace=False),\n","            # Linear(in_features=64, out_features=64, bias=True),\n","            # ReLU(inplace=True),\n","            # Dropout(p=0.5, inplace=False),\n","            Linear(in_features=64, out_features=1, bias=True)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        # print(x.size())\n","        x = self.avgpool(x)\n","        # print(x.size())\n","\n","        # flattenning \n","        x = x.view(-1,128*4*4)\n","        # print(x.size())\n","        logits = self.classifier(x)\n","        # print(logits.size())\n","        return logits\n","\n","# nnn = SuperShallowCNN()\n","# nnn.forward(x)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"nVTpn03e41Zu","executionInfo":{"status":"ok","timestamp":1634168700802,"user_tz":180,"elapsed":10,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}}},"source":["import torch\n","# from torch.nn.functional import one_hot\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","from torch.nn import Linear, ReLU, BCEWithLogitsLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, AdaptiveAvgPool2d\n","from torch.optim import Adam, SGD\n","\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda, Compose\n","import torchvision.models as models\n","\n","class NeuralNetwork(Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.features = Sequential(\n","            Conv2d(in_channels =1, out_channels =8, kernel_size=3, stride=1, padding=1),\n","            BatchNorm2d(num_features=8),\n","            ReLU(inplace=True),\n","            MaxPool2d(2,2),\n","\n","            Conv2d(in_channels =8, out_channels =16, kernel_size=3, stride=1, padding=0),\n","            BatchNorm2d(num_features=16),\n","            ReLU(inplace=True),\n","            MaxPool2d(2,2),\n","            \n","            Conv2d(in_channels =16, out_channels =32, kernel_size=3, stride=1, padding=0),\n","            BatchNorm2d(num_features=32),\n","            ReLU(inplace=True),\n","            MaxPool2d(2,2),\n","            \n","            Conv2d(in_channels =32, out_channels =64, kernel_size=3, stride=1, padding=0),\n","            ReLU(inplace=True)\n","        )\n","        self.avgpool = AdaptiveAvgPool2d(output_size=(8, 8))\n","        self.classifier = Sequential(\n","            # Remember changing the x.view() number as well. It needs to be flattenend!\n","            Linear(in_features=64*8*8, out_features=512, bias=True),\n","            ReLU(inplace=True),\n","            # Dropout(p=0.5, inplace=False),\n","            Linear(in_features=512, out_features=512, bias=True),\n","            ReLU(inplace=True),\n","            # Dropout(p=0.5, inplace=False),\n","            # Linear(in_features=512, out_features=512, bias=True),\n","            # ReLU(inplace=True),\n","            # Dropout(p=0.5, inplace=False),\n","            Linear(in_features=512, out_features=1, bias=True)\n","\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        # print(x.size())\n","        x = self.avgpool(x)\n","        # print(x.size())\n","        # flattenning \n","        x = x.view(-1,64*8*8)\n","        # print(x.size())\n","        logits = self.classifier(x)\n","        # print(logits.size())\n","        return logits"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jNzzzKUGftf","executionInfo":{"status":"ok","timestamp":1634168704795,"user_tz":180,"elapsed":4002,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"d3d954e6-bc03-439f-af77-056ffaaf99ac"},"source":["import time\n","from datetime import datetime\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n","\n","import torch\n","# from torch.nn.functional import one_hot\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","from torch.nn import Linear, ReLU, BCEWithLogitsLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, AdaptiveAvgPool2d\n","from torch.optim import Adam, SGD,RMSprop\n","\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda, Compose\n","import torchvision.models as models\n","\n","from mri_dataset import MRIDataset\n","from mri_dataset_generation import generate_mri_dataset_reference\n","\n","import sys\n","sys.path.append(\"./../data_preparation\")\n","from train_test_split import train_test_split_by_subject\n","\n","sys.path.append(\"./../models\")\n","from neural_network import NeuralNetwork,create_adapted_vgg11\n","\n","# %load_ext autoreload\n","# %autoreload 2\n","\n","# Defining global variables\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Using {} device\".format(device))\n","\n","def run_mris_experiments(orientation = 'coronal',\n","                          slices = list(range(45,56)),\n","                          num_repeats = 3,\n","                          model='shallow_cnn',\n","                          classes=['AD','CN'],\n","                          save_path = ''):\n","\n","    results = []\n","    for ii in range(1,num_repeats+1):\n","        for slice in slices:\n","            print(\"\\n--------------------------------------------------------------------\")\n","            print(\"--------------------------------------------------------------------\")\n","            print(f\"Running {orientation} - slice:{slice} with no data augmentation.\")\n","            print(\"--------------------------------------------------------------------\")\n","            print(\"--------------------------------------------------------------------\\n\")\n","            mri_config = {\n","            'orientation':orientation,\n","            'slice':slice,\n","            'num_samples':0,\n","            'num_rotations':0,\n","            'sampling_range':3,\n","            'mri_reference':'/content/gdrive/MyDrive/Lucas_Thimoteo/data/reference/PROCESSED_MRI_REFERENCE_ALL_ORIENTATIONS_20211012_2041.csv',\n","            'output_path':'/content/gdrive/MyDrive/Lucas_Thimoteo/data/mri/experiments/',\n","            }\n","            df_ref = generate_mri_dataset_reference(mri_reference_path = mri_config['mri_reference'],\n","                                output_path = mri_config['output_path'],\n","                                orientation = mri_config['orientation'],\n","                                orientation_slice = mri_config['slice'],\n","                                num_sampled_images = mri_config['num_samples'],\n","                                sampling_range = mri_config['sampling_range'],\n","                                num_rotations = mri_config['num_rotations'],\n","                                save_reference_file = False)\n","            run_result = run_cnn_experiment(model = model,\n","                        model_name = 'cnn_'+orientation+'_'+str(slice)+'_'+str(ii),\n","                        classes = classes,\n","                        mri_reference = df_ref,\n","                        run_test = False,\n","                        compute_predictions = False,\n","                        prediction_dataset_path = '',\n","                        model_path = '')\n","            run_result['RUN_ID'] = orientation+'_'+str(slice)+'_'+str(ii)\n","            results.append(run_result)\n","\n","    df_results = pd.concat(results).reset_index(drop=True)\n","    if save_path != '' and save_path is not None:\n","        df_results.to_csv(save_path,index=False)\n","    return df_results\n","\n","def run_cnn_experiment(model = 'vgg11',\n","                       model_name = 'vgg11_2048_2048',\n","                       classes = ['AD','CN'],\n","                       mri_reference = '',\n","                       run_test = False,\n","                       compute_predictions = False,\n","                       prediction_dataset_path = '',\n","                       model_path = '',\n","                       additional_experiment_params = None):\n","    '''\n","    Run the MRI classification for AD or CN.\n","\n","    Parameters\n","    ----------\n","\n","    model: Neural network to be trained. Can be 'vgg11' or 'shallow'.\n","    \n","    model_name: Name to save the trained model.\n","    \n","    classes: classes to filter the dataset. options can be ['AD','CN','MCI']\n","\n","    mri_reference: Path or file of the MRI reference that will be used to filter the validation/test sets and classes. \n","\n","    prediction_dataset_path: '/content/gdrive/MyDrive/Lucas_Thimoteo/mri/processed/',\n","    \n","    model_path: Path to save the trained model.\n","    \n","    additional_experiment_params: dictionary containing some experiments parameters such as lr (learning rate), batch_size and optimizer.\n","\n","    '''\n","\n","    if additional_experiment_params is None:\n","        additional_experiment_params = {'lr':0.0001,\n","                             'batch_size':16,\n","                             'optimizer':'adam',\n","                             'max_epochs':100,\n","                             'early_stop':10,\n","                             'prediction_threshold':0.5}\n","    if type(mri_reference) == str:\n","        df_mri_reference = pd.read_csv(mri_reference)\n","    else:\n","        df_mri_reference = mri_reference\n","    \n","    if type(model) == str:\n","        model = load_model(model)\n","    model_name = model_name + datetime.now().strftime(\"%m%d%Y_%H%M\")\n","    \n","    optimizer,criterion,prepared_data = setup_experiment(model,classes,df_mri_reference,additional_experiment_params)\n","\n","    train_metrics,validation_metrics = train(train_dataloader=prepared_data['train_dataloader'],\n","        validation_dataloader=prepared_data['validation_dataloader'],\n","        model=model,\n","        loss_fn=criterion,\n","        optimizer=optimizer,\n","        max_epochs=additional_experiment_params['max_epochs'],\n","        early_stopping_epochs=additional_experiment_params['early_stop'],\n","        model_name = model_name,\n","        model_path=model_path)\n","    \n","    cols = train_metrics.keys()\n","    train_cols = ['train_'+x for x in cols]\n","    df_results = pd.DataFrame([train_metrics])\n","    df_results.columns = train_cols\n","    \n","    validation_cols = ['validation_'+x for x in cols]\n","    for col,value in zip(validation_cols,validation_metrics.values()):\n","        df_results[col] = [value]\n","\n","    if run_test:\n","        model.load_state_dict(torch.load(model_path + model_name+'.pth'))\n","        model.eval()\n","        test_metrics = test(dataloader=prepared_data['test_dataloader'],\n","            model=model,\n","            loss_fn=criterion,\n","            return_predictions=False,\n","            compute_metrics=True)\n","        test_cols = ['test_'+x for x in cols]\n","        for col,value in zip(test_cols,test_metrics.values()):\n","            df_results[col] = value\n","            \n","    if compute_predictions:\n","        df_predictions = compute_predictions_for_dataset(prepared_data,model,criterion,threshold = additional_experiment_params['prediction_threshold'])\n","        if prediction_dataset_path is not None and prediction_dataset_path != '':\n","            df_predictions.to_csv(prediction_dataset_path + \"PREDICTED_MRI_REFERENCE.csv\",index=False)\n","        return df_predictions,df_results\n","    return df_results\n","\n","def setup_experiment(model,classes,df_mri_reference,additional_experiment_params):\n","\n","    print(\"Setting up experiment parameters...\")\n","\n","    if additional_experiment_params['optimizer'] == 'adam':\n","        optimizer = Adam(model.parameters(), lr=additional_experiment_params['lr'])\n","    elif additional_experiment_params['optimizer'] == 'rmsprop':\n","        optimizer = RMSprop(model.parameters(), lr=additional_experiment_params['lr'])\n","    else:\n","        optimizer = SGD(model.parameters(), lr=additional_experiment_params['lr'])\n","\n","    dataset_params = {'batch_size': additional_experiment_params['batch_size'],\n","            'shuffle': False,\n","            'num_workers': 4,\n","            'pin_memory':True}\n","    \n","    df_train_reference, df_validation_reference, df_test_reference = return_sets(df_mri_reference,classes)\n","\n","    # Defining Dataset Generators\n","    training_set = MRIDataset(reference_table = df_train_reference)\n","    train_dataloader = DataLoader(training_set, **dataset_params)\n","\n","    validation_set = MRIDataset(reference_table = df_validation_reference)\n","    validation_dataloader = DataLoader(validation_set, **dataset_params)\n","\n","    test_set = MRIDataset(reference_table = df_test_reference)\n","    test_dataloader = DataLoader(test_set, **dataset_params)\n","    prepared_data = {\n","        'train_dataloader':train_dataloader,\n","        'validation_dataloader':validation_dataloader,\n","        'test_dataloader':test_dataloader,\n","        'df_train_reference':df_train_reference,\n","        'df_validation_reference':df_validation_reference,\n","        'df_test_reference':df_test_reference\n","    }\n","\n","    # pos_weight = torch.ones([1]) * (neg_class/pos_class)\n","    criterion = BCEWithLogitsLoss()\n","    criterion = criterion.to(device)\n","\n","    return optimizer,criterion,prepared_data\n","\n","def return_sets(df_mri_reference,classes):\n","    if set(classes) == set(['AD','CN']):\n","        df_mri_reference.loc[df_mri_reference['MACRO_GROUP'] == 'CN','MACRO_GROUP'] = 0\n","        df_mri_reference.loc[df_mri_reference['MACRO_GROUP'] == 'AD','MACRO_GROUP'] = 1\n","    elif set(classes) == set(['MCI','CN']):\n","        df_mri_reference.loc[df_mri_reference['MACRO_GROUP'] == 'CN','MACRO_GROUP'] = 0\n","        df_mri_reference.loc[df_mri_reference['MACRO_GROUP'] == 'MCI','MACRO_GROUP'] = 1\n","    elif set(classes) == set(['MCI','AD']):\n","        df_mri_reference.loc[df_mri_reference['MACRO_GROUP'] == 'MCI','MACRO_GROUP'] = 0\n","        df_mri_reference.loc[df_mri_reference['MACRO_GROUP'] == 'AD','MACRO_GROUP'] = 1\n","\n","    df_mri_reference = df_mri_reference.loc[df_mri_reference['MACRO_GROUP'].isin([0,1]),:]\n","\n","    filter_query = \"DATASET == 'set' and SLICE == MAIN_SLICE\"\n","    if 'ROTATION_ANGLE' in df_mri_reference.columns:\n","      filter_query = filter_query + \" and (ROTATION_ANGLE == 0 or ROTATION_ANGLE == '0')\"\n","\n","    df_validation_reference = df_mri_reference.query(filter_query.replace('set','validation'))\n","    df_test_reference = df_mri_reference.query(filter_query.replace('set','test'))\n","    df_train_reference = df_mri_reference.query(\"DATASET not in ('validation','test')\")\n","\n","    print(\"Train size:\",df_train_reference.shape[0])\n","    print(\"Validation size:\",df_validation_reference.shape[0])\n","    print(\"Test size:\",df_test_reference.shape[0])\n","    return df_train_reference, df_validation_reference, df_test_reference\n","\n","def compute_predictions_for_dataset(prepared_data, model,criterion,threshold=0.5):\n","\n","    loaders = [\n","        prepared_data['train_dataloader'],\n","        prepared_data['validation_dataloader'],\n","        prepared_data['test_dataloader']\n","    ]\n","\n","    datasets = [\n","        prepared_data['df_train_reference'],\n","        prepared_data['df_validation_reference'],\n","        prepared_data['df_test_reference'],\n","    ]\n","    dataset_types = ['train','validation','test']\n","\n","    print(\"Saving predictions from trained model...\")\n","    for dataset_type,data_loader,df in zip(dataset_types,loaders,datasets):\n","        print(f'Computing Predictions for {dataset_type} set.')\n","        print('dataset size:',df.shape)\n","        predict_probs = test(dataloader=data_loader,\n","        model=model,\n","        loss_fn=criterion,\n","        skip_compute_metrics=False,\n","        return_predictions=True)\n","        predicted_labels = predict_probs >= threshold\n","        df['CNN_PREDICTION' ] = predicted_labels\n","        df['CNN_PREDICT_PROBA' ] = predict_probs\n","\n","    return pd.concat(datasets)\n","\n","def load_model(model_type='shallow'):\n","    print(\"Loading untrained model...\")\n","    if model_type == 'vgg11':\n","        vgg = create_adapted_vgg11()\n","        model = vgg.to(device)\n","    elif model_type == 'shallow_cnn':\n","        custom_nn = NeuralNetwork()\n","        model = custom_nn.to(device)\n","    else:\n","        custom_nn = SuperShallowCNN()\n","        model = custom_nn.to(device)\n","    print(model)\n","    print('')\n","    count_trainable_parameters(model)\n","    return model\n","\n","def train(train_dataloader,\n","            validation_dataloader, \n","            model, \n","            loss_fn, \n","            optimizer,\n","            max_epochs=100,\n","            early_stopping_epochs = 10,\n","            model_name = 'experiment',\n","            model_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/models/'):\n","\n","    train_losses = []\n","    validation_losses = []\n","    train_aucs = []\n","    validation_aucs = []\n","    best_epoch = 0\n","    best_validation_auc = 0\n","    early_stopping_marker = 0\n","    best_model_params = model.state_dict()\n","    best_validation_metrics = None\n","    best_validation_loss = None\n","    for epoch in range(max_epochs):\n","        t0 = time.time()\n","        \n","        print('\\n---------------------------------------------------------------------')\n","        print(f'Running Epoch {epoch + 1} of  {max_epochs}')\n","        \n","        train_loss,train_metrics = train_one_epoch(train_dataloader, model, loss_fn, optimizer)\n","        validation_loss, validation_metrics = validate_one_epoch(validation_dataloader, model, loss_fn, optimizer)\n","        \n","        print_metrics(train_metrics,train_loss,validation_metrics,validation_loss)\n","        print('\\nEpoch {} took'.format(epoch+1),'%3.2f seconds' % (time.time() - t0))\n","        print('---------------------------------------------------------------------')\n","        \n","        train_losses.append(train_loss)\n","        validation_losses.append(validation_loss)\n","        train_aucs.append(train_metrics['auc'])\n","        validation_aucs.append(validation_metrics['auc'])\n","\n","        if best_validation_auc >= validation_metrics['auc']:\n","            early_stopping_marker += 1\n","        else:\n","            best_epoch = epoch+1\n","            best_validation_auc = validation_metrics['auc']\n","            early_stopping_marker = 0\n","            best_model_params = model.state_dict()\n","            best_validation_metrics = validation_metrics\n","            best_validation_loss = validation_loss\n","            best_train_metrics = train_metrics\n","            best_train_loss = train_loss\n","\n","            print('Best validation AUC so far: %1.4f' % best_validation_metrics['auc'])\n","        \n","        if early_stopping_epochs > 0:\n","            if early_stopping_marker == early_stopping_epochs:\n","                print(\"\\nExiting training... It hit early stopping criteria of:\",early_stopping_epochs,'epochs')\n","                print(\"Saving model at:\",model_path)\n","                torch.save(best_model_params, model_path + model_name + '.pth')\n","                break\n","\n","        if (best_epoch) == max_epochs:\n","            print(\"Saving model at:\",model_path,'\\n')\n","            torch.save(best_model_params, model_path + model_name + '.pth')\n","\n","    plot_metric(metric='Loss',train_metric=train_losses,validation_metric= validation_losses)    \n","    plot_metric(metric='AUC',train_metric=train_aucs,validation_metric= validation_aucs)    \n","    print('\\n-------------------------------')\n","    print(f\"Best metrics for validation set on Epoch {best_epoch}:\")\n","    print_metrics(best_validation_metrics,best_validation_loss)\n","    print('-------------------------------\\n')\n","    \n","    return best_train_metrics,best_validation_metrics\n","\n","def plot_metric(metric,train_metric, validation_metric):\n","    plt.plot(train_metric, label=f'Train {metric}')\n","    plt.plot(validation_metric, label=f'Validation {metric}')\n","    plt.legend()\n","    plt.title(f\"Train vs Validation {metric}\")\n","    plt.show()\n","\n","def test(dataloader,model,loss_fn,compute_metrics = True, return_predictions = False,dataset_type = 'test'):\n","    size = len(dataloader.dataset)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    true_labels = torch.Tensor().to(device)\n","    predicted_labels = torch.Tensor().to(device)\n","    y_predict_probabilities = torch.Tensor().to(device)\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            X = X.view(-1,1, 100,100)\n","            y = y.view(-1,1)\n","            # y = one_hot(y, num_classes)\n","            # y = y.view(-1,num_classes)\n","            y_pred = model(X)\n","            y = y.type_as(y_pred)\n","\n","            test_loss += loss_fn(y_pred, y).item()\n","            true_labels = torch.cat((true_labels,y),0)\n","            predicted_labels = torch.cat((predicted_labels,y_pred),0)\n","            if return_predictions:\n","                y_predict_proba = torch.sigmoid(y_pred)\n","                y_predict_probabilities = torch.cat((y_predict_probabilities,y_predict_proba),0)\n","\n","        if compute_metrics:\n","            test_loss /= size\n","            print(f\"Performance for {dataset_type} set:\")\n","            test_metrics = compute_metrics_binary(y_true = true_labels, y_pred = predicted_labels,threshold = 0.5,verbose=0)\n","            print_metrics(test_metrics,test_loss,validation_metrics = None)\n","\n","        if return_predictions:\n","            return y_predict_probabilities.cpu().detach().numpy().ravel(),test_metrics\n","        return test_metrics\n","\n","def train_one_epoch(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    running_loss = 0.0\n","    true_labels = torch.Tensor().to(device)\n","    predicted_labels = torch.Tensor().to(device)\n","\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","        X = X.view(-1,1, 100,100)\n","        y = y.view(-1,1)\n","        # y = one_hot(y, num_classes)\n","        # y = y.view(-1,num_classes)\n","\n","        # clearing the Gradients of the model parameters\n","        optimizer.zero_grad()\n","\n","        # Compute prediction error\n","        y_pred = model(X)\n","        y = y.type_as(y_pred)\n","        loss = loss_fn(y_pred, y)\n","\n","        # backpropagation \n","        loss.backward()\n","\n","        # update optimizer\n","        optimizer.step()\n","        loss = loss.item() \n","        running_loss += loss \n","        true_labels = torch.cat((true_labels,y),0)\n","        predicted_labels = torch.cat((predicted_labels,y_pred),0)\n","    train_metrics = compute_metrics_binary(y_pred = predicted_labels,y_true = true_labels,threshold = 0.5,verbose=0)\n","    running_loss = running_loss/size\n","    return running_loss, train_metrics\n","\n","def validate_one_epoch(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    running_loss = 0.0\n","    true_labels = torch.Tensor().to(device)\n","    predicted_labels = torch.Tensor().to(device)\n","\n","    with torch.no_grad():\n","        for batch, (X, y) in enumerate(dataloader):\n","\n","            X, y = X.to(device), y.to(device)\n","            X = X.view(-1,1, 100,100)\n","            y = y.view(-1,1)\n","            # y = one_hot(y, num_classes)\n","            # y = y.view(-1,num_classes)\n","\n","            y_pred = model(X)\n","            y = y.type_as(y_pred)\n","            loss = loss_fn(y_pred, y)\n","\n","            optimizer.zero_grad()\n","            loss = loss.item()\n","            \n","            running_loss += loss    \n","            true_labels = torch.cat((true_labels,y),0)\n","            predicted_labels = torch.cat((predicted_labels,y_pred),0)\n","\n","        validation_metrics = compute_metrics_binary(y_pred = predicted_labels,y_true = true_labels,threshold = 0.5,verbose=0)\n","        running_loss = running_loss/size\n","        \n","        return running_loss, validation_metrics\n","\n","def compute_metrics_binary(y_true:torch.Tensor, y_pred:torch.Tensor, y_pred_proba:torch.Tensor = None,threshold = 0.5,verbose=0):\n","    \n","    if y_pred_proba is None:\n","        y_pred_proba = torch.sigmoid(y_pred)\n","    y_pred_label = y_pred_proba\n","    y_pred_label[y_pred_proba >= threshold] = 1\n","    y_pred_label[y_pred_proba < threshold] = 0\n","    \n","    y_true = y_true.cpu().detach().numpy()\n","    y_pred_label = y_pred_label.cpu().detach().numpy()\n","    y_pred_proba = y_pred_proba.cpu().detach().numpy()\n","\n","    auc = roc_auc_score(y_true, y_pred_proba)\n","    accuracy = accuracy_score(y_true, y_pred_label)\n","    f1score = f1_score(y_true, y_pred_label)\n","    recall = recall_score(y_true, y_pred_label)\n","    precision = precision_score(y_true, y_pred_label)\n","    conf_mat = confusion_matrix(y_true, y_pred_label)\n","\n","    if verbose > 0:\n","        print('----------------')\n","        print(\"Total samples in batch:\",y_true.shape)\n","        print(\"AUC:       %1.3f\" % auc)\n","        print(\"Accuracy:  %1.3f\" % accuracy)\n","        print(\"F1:        %1.3f\" % f1score)\n","        print(\"Precision: %1.3f\" % precision)\n","        print(\"Recall:    %1.3f\" % recall)\n","        print(\"Confusion Matrix: \\n\", conf_mat)\n","        print('----------------')\n","    metrics = {\n","        'auc':auc,\n","        'accuracy':accuracy,\n","        'f1score':f1score,\n","        'precision':precision,\n","        'recall':recall,\n","        'conf_mat':conf_mat\n","    }\n","    return metrics\n","\n","def print_metrics(train_metrics,train_loss,validation_metrics = None,validation_loss = None):\n","    \n","    if validation_metrics is not None:\n","\n","        print(f\"Loss::      Train {train_loss:.4f}      Validation {validation_loss:.4f}\")\n","        print(f\"AUC::       Train {train_metrics['auc']:.4f}      Validation {validation_metrics['auc']:.4f}\")\n","        print(f\"Accuracy::  Train {train_metrics['accuracy']:.4f}      Validation {validation_metrics['accuracy']:.4f}\")\n","        print(f\"F1::        Train {train_metrics['f1score']:.4f}      Validation {validation_metrics['f1score']:.4f}\")\n","        print(f\"Precision:: Train {train_metrics['precision']:.4f}      Validation {validation_metrics['precision']:.4f}\")\n","        print(f\"Recall::    Train {train_metrics['recall']:.4f}      Validation {validation_metrics['recall']:.4f}\")\n","        print(\"Validation Confusion Matrix:\\n\", validation_metrics['conf_mat'])\n","    else:\n","        print(f\"Loss::      {train_loss:.4f}\")\n","        print(f\"AUC::       {train_metrics['auc']:.4f}\")\n","        print(f\"Accuracy::  {train_metrics['accuracy']:.4f}\")\n","        print(f\"F1::        {train_metrics['f1score']:.4f}\")\n","        print(f\"Precision:: {train_metrics['precision']:.4f}\")\n","        print(f\"Recall::    {train_metrics['recall']:.4f}\")\n","        print(\"Confusion Matrix:\\n\", train_metrics['conf_mat'])\n","\n","def count_trainable_parameters(model):\n","    pp=0\n","    for p in list(model.parameters()):\n","        nn=1\n","        for s in list(p.size()):\n","            nn = nn*s\n","        pp += nn\n","    print(\"Total number of trainable parameters:\",pp)\n"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w64J7IedDLa0","executionInfo":{"status":"ok","timestamp":1634168716828,"user_tz":180,"elapsed":12039,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"dcaac93b-d44c-43d0-d6df-b6beb410baa7"},"source":["model = load_model('vgg11')"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading untrained model...\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (12): ReLU(inplace=True)\n","    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (14): ReLU(inplace=True)\n","    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (17): ReLU(inplace=True)\n","    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (19): ReLU(inplace=True)\n","    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=2048, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=2048, out_features=2048, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=2048, out_features=1, bias=True)\n","  )\n",")\n","\n","Total number of trainable parameters: 64800001\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oy_ax4fA41Qt","executionInfo":{"status":"ok","timestamp":1634168716829,"user_tz":180,"elapsed":12,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"65f1786c-a4bb-4b27-d6ba-85e9d5977cae"},"source":["model = load_model('shallow_cnn')"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading untrained model...\n","NeuralNetwork(\n","  (features): Sequential(\n","    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n","    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU(inplace=True)\n","    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n","    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): ReLU(inplace=True)\n","    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (12): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (13): ReLU(inplace=True)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(8, 8))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=4096, out_features=512, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU(inplace=True)\n","    (4): Linear(in_features=512, out_features=1, bias=True)\n","  )\n",")\n","\n","Total number of trainable parameters: 2385329\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YBPcMQhtDEY5","executionInfo":{"status":"ok","timestamp":1634168716830,"user_tz":180,"elapsed":10,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"468154f1-1369-4d85-d649-aaedb2c82478"},"source":["model = load_model('super_shallow_cnn')"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading untrained model...\n","SuperShallowCNN(\n","  (features): Sequential(\n","    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n","    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU(inplace=True)\n","    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n","    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): ReLU(inplace=True)\n","    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (12): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (14): ReLU(inplace=True)\n","    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (16): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n","    (17): ReLU(inplace=True)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(4, 4))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=2048, out_features=128, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Linear(in_features=128, out_features=64, bias=True)\n","    (3): ReLU(inplace=True)\n","    (4): Linear(in_features=64, out_features=1, bias=True)\n","  )\n",")\n","\n","Total number of trainable parameters: 369073\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ze1UpiX_M9ll"},"source":["# Training Shallow CNN (GPU) - 12/10/2021"]},{"cell_type":"markdown","metadata":{"id":"69JHv8ext4my"},"source":["## Coronal - 45~55"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"14gCNCc6GReIHmWlvZN3IaI3K95L1pnZm"},"id":"7PjFKZlFt8j5","executionInfo":{"status":"ok","timestamp":1634070280128,"user_tz":180,"elapsed":3490342,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"a34fa4b6-df0c-4c2b-fee4-9c7bb4f89a2f"},"source":["df_results_coronal = run_mris_experiments(orientation = 'coronal',\n","                          slices = list(range(45,56)),\n","                          num_repeats = 3,\n","                          model='shallow_cnn',\n","                          classes=['AD','CN'],\n","                          save_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/data/RESULTS_CORONAL_SHALLOW_CNN.csv')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xr_ZHNITPiTU","executionInfo":{"status":"ok","timestamp":1634089533817,"user_tz":180,"elapsed":54,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"2d1977c4-0c5f-4d51-b909-2a6579861027"},"source":["df_results_coronal = df_results_coronal.reset_index(drop=True)\n","df_results_coronal"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>train_auc</th>\n","      <th>train_accuracy</th>\n","      <th>train_f1score</th>\n","      <th>train_precision</th>\n","      <th>train_recall</th>\n","      <th>train_conf_mat</th>\n","      <th>validation_auc</th>\n","      <th>validation_accuracy</th>\n","      <th>validation_f1score</th>\n","      <th>validation_precision</th>\n","      <th>validation_recall</th>\n","      <th>validation_conf_mat</th>\n","      <th>RUN_ID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.979160</td>\n","      <td>0.983654</td>\n","      <td>0.970894</td>\n","      <td>0.972917</td>\n","      <td>0.968880</td>\n","      <td>[[1218, 13], [15, 467]]</td>\n","      <td>0.822098</td>\n","      <td>0.887955</td>\n","      <td>0.733333</td>\n","      <td>0.763889</td>\n","      <td>0.705128</td>\n","      <td>[[262, 17], [23, 55]]</td>\n","      <td>coronal451</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.918357</td>\n","      <td>0.941623</td>\n","      <td>0.892934</td>\n","      <td>0.922566</td>\n","      <td>0.865145</td>\n","      <td>[[1196, 35], [65, 417]]</td>\n","      <td>0.771574</td>\n","      <td>0.873950</td>\n","      <td>0.671533</td>\n","      <td>0.779661</td>\n","      <td>0.589744</td>\n","      <td>[[266, 13], [32, 46]]</td>\n","      <td>coronal461</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.932023</td>\n","      <td>0.950379</td>\n","      <td>0.909862</td>\n","      <td>0.930586</td>\n","      <td>0.890041</td>\n","      <td>[[1199, 32], [53, 429]]</td>\n","      <td>0.831334</td>\n","      <td>0.887955</td>\n","      <td>0.740260</td>\n","      <td>0.750000</td>\n","      <td>0.730769</td>\n","      <td>[[260, 19], [21, 57]]</td>\n","      <td>coronal471</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.962562</td>\n","      <td>0.974314</td>\n","      <td>0.953488</td>\n","      <td>0.971983</td>\n","      <td>0.935685</td>\n","      <td>[[1218, 13], [31, 451]]</td>\n","      <td>0.790598</td>\n","      <td>0.845938</td>\n","      <td>0.662577</td>\n","      <td>0.635294</td>\n","      <td>0.692308</td>\n","      <td>[[248, 31], [24, 54]]</td>\n","      <td>coronal481</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.978485</td>\n","      <td>0.985406</td>\n","      <td>0.973767</td>\n","      <td>0.985138</td>\n","      <td>0.962656</td>\n","      <td>[[1224, 7], [18, 464]]</td>\n","      <td>0.807761</td>\n","      <td>0.865546</td>\n","      <td>0.696203</td>\n","      <td>0.687500</td>\n","      <td>0.705128</td>\n","      <td>[[254, 25], [23, 55]]</td>\n","      <td>coronal491</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.977447</td>\n","      <td>0.984822</td>\n","      <td>0.972689</td>\n","      <td>0.985106</td>\n","      <td>0.960581</td>\n","      <td>[[1224, 7], [19, 463]]</td>\n","      <td>0.816239</td>\n","      <td>0.857143</td>\n","      <td>0.694611</td>\n","      <td>0.651685</td>\n","      <td>0.743590</td>\n","      <td>[[248, 31], [20, 58]]</td>\n","      <td>coronal501</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.968561</td>\n","      <td>0.978400</td>\n","      <td>0.961012</td>\n","      <td>0.976445</td>\n","      <td>0.946058</td>\n","      <td>[[1220, 11], [26, 456]]</td>\n","      <td>0.809829</td>\n","      <td>0.854342</td>\n","      <td>0.686747</td>\n","      <td>0.647727</td>\n","      <td>0.730769</td>\n","      <td>[[248, 31], [21, 57]]</td>\n","      <td>coronal511</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.951102</td>\n","      <td>0.961471</td>\n","      <td>0.931250</td>\n","      <td>0.935146</td>\n","      <td>0.927386</td>\n","      <td>[[1200, 31], [35, 447]]</td>\n","      <td>0.770058</td>\n","      <td>0.857143</td>\n","      <td>0.653061</td>\n","      <td>0.695652</td>\n","      <td>0.615385</td>\n","      <td>[[258, 21], [30, 48]]</td>\n","      <td>coronal521</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.979116</td>\n","      <td>0.985406</td>\n","      <td>0.973822</td>\n","      <td>0.983087</td>\n","      <td>0.964730</td>\n","      <td>[[1223, 8], [17, 465]]</td>\n","      <td>0.802178</td>\n","      <td>0.820728</td>\n","      <td>0.652174</td>\n","      <td>0.566038</td>\n","      <td>0.769231</td>\n","      <td>[[233, 46], [18, 60]]</td>\n","      <td>coronal531</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.987190</td>\n","      <td>0.990660</td>\n","      <td>0.983333</td>\n","      <td>0.987448</td>\n","      <td>0.979253</td>\n","      <td>[[1225, 6], [10, 472]]</td>\n","      <td>0.810312</td>\n","      <td>0.876751</td>\n","      <td>0.710526</td>\n","      <td>0.729730</td>\n","      <td>0.692308</td>\n","      <td>[[259, 20], [24, 54]]</td>\n","      <td>coronal541</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.932429</td>\n","      <td>0.950963</td>\n","      <td>0.910828</td>\n","      <td>0.932609</td>\n","      <td>0.890041</td>\n","      <td>[[1200, 31], [53, 429]]</td>\n","      <td>0.826027</td>\n","      <td>0.829132</td>\n","      <td>0.677249</td>\n","      <td>0.576577</td>\n","      <td>0.820513</td>\n","      <td>[[232, 47], [14, 64]]</td>\n","      <td>coronal551</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.986152</td>\n","      <td>0.990076</td>\n","      <td>0.982273</td>\n","      <td>0.987421</td>\n","      <td>0.977178</td>\n","      <td>[[1225, 6], [11, 471]]</td>\n","      <td>0.835677</td>\n","      <td>0.901961</td>\n","      <td>0.761905</td>\n","      <td>0.811594</td>\n","      <td>0.717949</td>\n","      <td>[[266, 13], [22, 56]]</td>\n","      <td>coronal452</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.968830</td>\n","      <td>0.976065</td>\n","      <td>0.957247</td>\n","      <td>0.962264</td>\n","      <td>0.952282</td>\n","      <td>[[1213, 18], [23, 459]]</td>\n","      <td>0.807279</td>\n","      <td>0.843137</td>\n","      <td>0.674419</td>\n","      <td>0.617021</td>\n","      <td>0.743590</td>\n","      <td>[[243, 36], [20, 58]]</td>\n","      <td>coronal462</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.954757</td>\n","      <td>0.966725</td>\n","      <td>0.940063</td>\n","      <td>0.953092</td>\n","      <td>0.927386</td>\n","      <td>[[1209, 22], [35, 447]]</td>\n","      <td>0.787772</td>\n","      <td>0.848739</td>\n","      <td>0.662500</td>\n","      <td>0.646341</td>\n","      <td>0.679487</td>\n","      <td>[[250, 29], [25, 53]]</td>\n","      <td>coronal472</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.989852</td>\n","      <td>0.993579</td>\n","      <td>0.988506</td>\n","      <td>0.995789</td>\n","      <td>0.981328</td>\n","      <td>[[1229, 2], [9, 473]]</td>\n","      <td>0.824924</td>\n","      <td>0.885154</td>\n","      <td>0.732026</td>\n","      <td>0.746667</td>\n","      <td>0.717949</td>\n","      <td>[[260, 19], [22, 56]]</td>\n","      <td>coronal482</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.977266</td>\n","      <td>0.983654</td>\n","      <td>0.970711</td>\n","      <td>0.978903</td>\n","      <td>0.962656</td>\n","      <td>[[1221, 10], [18, 464]]</td>\n","      <td>0.818583</td>\n","      <td>0.831933</td>\n","      <td>0.673913</td>\n","      <td>0.584906</td>\n","      <td>0.794872</td>\n","      <td>[[235, 44], [16, 62]]</td>\n","      <td>coronal492</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.962787</td>\n","      <td>0.973730</td>\n","      <td>0.952582</td>\n","      <td>0.967880</td>\n","      <td>0.937759</td>\n","      <td>[[1216, 15], [30, 452]]</td>\n","      <td>0.785222</td>\n","      <td>0.837535</td>\n","      <td>0.650602</td>\n","      <td>0.613636</td>\n","      <td>0.692308</td>\n","      <td>[[245, 34], [24, 54]]</td>\n","      <td>coronal502</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.995444</td>\n","      <td>0.997081</td>\n","      <td>0.994797</td>\n","      <td>0.997912</td>\n","      <td>0.991701</td>\n","      <td>[[1230, 1], [4, 478]]</td>\n","      <td>0.794389</td>\n","      <td>0.887955</td>\n","      <td>0.710145</td>\n","      <td>0.816667</td>\n","      <td>0.628205</td>\n","      <td>[[268, 11], [29, 49]]</td>\n","      <td>coronal512</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.906946</td>\n","      <td>0.935201</td>\n","      <td>0.879740</td>\n","      <td>0.920635</td>\n","      <td>0.842324</td>\n","      <td>[[1196, 35], [76, 406]]</td>\n","      <td>0.811621</td>\n","      <td>0.857143</td>\n","      <td>0.690909</td>\n","      <td>0.655172</td>\n","      <td>0.730769</td>\n","      <td>[[249, 30], [21, 57]]</td>\n","      <td>coronal522</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.940278</td>\n","      <td>0.956801</td>\n","      <td>0.921610</td>\n","      <td>0.941558</td>\n","      <td>0.902490</td>\n","      <td>[[1204, 27], [47, 435]]</td>\n","      <td>0.804728</td>\n","      <td>0.831933</td>\n","      <td>0.662921</td>\n","      <td>0.590000</td>\n","      <td>0.756410</td>\n","      <td>[[238, 41], [19, 59]]</td>\n","      <td>coronal532</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>0.927199</td>\n","      <td>0.949796</td>\n","      <td>0.907527</td>\n","      <td>0.941964</td>\n","      <td>0.875519</td>\n","      <td>[[1205, 26], [60, 422]]</td>\n","      <td>0.798042</td>\n","      <td>0.843137</td>\n","      <td>0.666667</td>\n","      <td>0.622222</td>\n","      <td>0.717949</td>\n","      <td>[[245, 34], [22, 56]]</td>\n","      <td>coronal542</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0.940097</td>\n","      <td>0.955633</td>\n","      <td>0.919831</td>\n","      <td>0.935622</td>\n","      <td>0.904564</td>\n","      <td>[[1201, 30], [46, 436]]</td>\n","      <td>0.814240</td>\n","      <td>0.817927</td>\n","      <td>0.659686</td>\n","      <td>0.557522</td>\n","      <td>0.807692</td>\n","      <td>[[229, 50], [15, 63]]</td>\n","      <td>coronal552</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0.957688</td>\n","      <td>0.967309</td>\n","      <td>0.941545</td>\n","      <td>0.947479</td>\n","      <td>0.935685</td>\n","      <td>[[1206, 25], [31, 451]]</td>\n","      <td>0.830576</td>\n","      <td>0.879552</td>\n","      <td>0.729560</td>\n","      <td>0.716049</td>\n","      <td>0.743590</td>\n","      <td>[[256, 23], [20, 58]]</td>\n","      <td>coronal453</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0.988633</td>\n","      <td>0.991827</td>\n","      <td>0.985417</td>\n","      <td>0.989540</td>\n","      <td>0.981328</td>\n","      <td>[[1226, 5], [9, 473]]</td>\n","      <td>0.813413</td>\n","      <td>0.859944</td>\n","      <td>0.695122</td>\n","      <td>0.662791</td>\n","      <td>0.730769</td>\n","      <td>[[250, 29], [21, 57]]</td>\n","      <td>coronal463</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0.946908</td>\n","      <td>0.960887</td>\n","      <td>0.929399</td>\n","      <td>0.944325</td>\n","      <td>0.914938</td>\n","      <td>[[1205, 26], [41, 441]]</td>\n","      <td>0.802867</td>\n","      <td>0.879552</td>\n","      <td>0.707483</td>\n","      <td>0.753623</td>\n","      <td>0.666667</td>\n","      <td>[[262, 17], [26, 52]]</td>\n","      <td>coronal473</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0.956382</td>\n","      <td>0.969060</td>\n","      <td>0.944034</td>\n","      <td>0.961290</td>\n","      <td>0.927386</td>\n","      <td>[[1213, 18], [35, 447]]</td>\n","      <td>0.801075</td>\n","      <td>0.876751</td>\n","      <td>0.702703</td>\n","      <td>0.742857</td>\n","      <td>0.666667</td>\n","      <td>[[261, 18], [26, 52]]</td>\n","      <td>coronal483</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0.962200</td>\n","      <td>0.971979</td>\n","      <td>0.949686</td>\n","      <td>0.959746</td>\n","      <td>0.939834</td>\n","      <td>[[1212, 19], [29, 453]]</td>\n","      <td>0.799835</td>\n","      <td>0.845938</td>\n","      <td>0.670659</td>\n","      <td>0.629213</td>\n","      <td>0.717949</td>\n","      <td>[[246, 33], [22, 56]]</td>\n","      <td>coronal493</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>0.957419</td>\n","      <td>0.969644</td>\n","      <td>0.945148</td>\n","      <td>0.961373</td>\n","      <td>0.929461</td>\n","      <td>[[1213, 18], [34, 448]]</td>\n","      <td>0.827061</td>\n","      <td>0.823529</td>\n","      <td>0.673575</td>\n","      <td>0.565217</td>\n","      <td>0.833333</td>\n","      <td>[[229, 50], [13, 65]]</td>\n","      <td>coronal503</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0.974785</td>\n","      <td>0.981903</td>\n","      <td>0.967539</td>\n","      <td>0.976744</td>\n","      <td>0.958506</td>\n","      <td>[[1220, 11], [20, 462]]</td>\n","      <td>0.791356</td>\n","      <td>0.854342</td>\n","      <td>0.670886</td>\n","      <td>0.662500</td>\n","      <td>0.679487</td>\n","      <td>[[252, 27], [25, 53]]</td>\n","      <td>coronal513</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>0.997925</td>\n","      <td>0.998832</td>\n","      <td>0.997921</td>\n","      <td>1.000000</td>\n","      <td>0.995851</td>\n","      <td>[[1231, 0], [2, 480]]</td>\n","      <td>0.784946</td>\n","      <td>0.851541</td>\n","      <td>0.662420</td>\n","      <td>0.658228</td>\n","      <td>0.666667</td>\n","      <td>[[252, 27], [26, 52]]</td>\n","      <td>coronal523</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>0.945646</td>\n","      <td>0.960887</td>\n","      <td>0.929101</td>\n","      <td>0.948164</td>\n","      <td>0.910788</td>\n","      <td>[[1207, 24], [43, 439]]</td>\n","      <td>0.806314</td>\n","      <td>0.798319</td>\n","      <td>0.640000</td>\n","      <td>0.524590</td>\n","      <td>0.820513</td>\n","      <td>[[221, 58], [14, 64]]</td>\n","      <td>coronal533</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>0.958275</td>\n","      <td>0.969060</td>\n","      <td>0.944386</td>\n","      <td>0.955414</td>\n","      <td>0.933610</td>\n","      <td>[[1210, 21], [32, 450]]</td>\n","      <td>0.775503</td>\n","      <td>0.815126</td>\n","      <td>0.625000</td>\n","      <td>0.561224</td>\n","      <td>0.705128</td>\n","      <td>[[236, 43], [23, 55]]</td>\n","      <td>coronal543</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>0.938878</td>\n","      <td>0.953882</td>\n","      <td>0.916930</td>\n","      <td>0.929638</td>\n","      <td>0.904564</td>\n","      <td>[[1198, 33], [46, 436]]</td>\n","      <td>0.820582</td>\n","      <td>0.871148</td>\n","      <td>0.712500</td>\n","      <td>0.695122</td>\n","      <td>0.730769</td>\n","      <td>[[254, 25], [21, 57]]</td>\n","      <td>coronal553</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    train_auc  train_accuracy  train_f1score  train_precision  train_recall  \\\n","0    0.979160        0.983654       0.970894         0.972917      0.968880   \n","1    0.918357        0.941623       0.892934         0.922566      0.865145   \n","2    0.932023        0.950379       0.909862         0.930586      0.890041   \n","3    0.962562        0.974314       0.953488         0.971983      0.935685   \n","4    0.978485        0.985406       0.973767         0.985138      0.962656   \n","5    0.977447        0.984822       0.972689         0.985106      0.960581   \n","6    0.968561        0.978400       0.961012         0.976445      0.946058   \n","7    0.951102        0.961471       0.931250         0.935146      0.927386   \n","8    0.979116        0.985406       0.973822         0.983087      0.964730   \n","9    0.987190        0.990660       0.983333         0.987448      0.979253   \n","10   0.932429        0.950963       0.910828         0.932609      0.890041   \n","11   0.986152        0.990076       0.982273         0.987421      0.977178   \n","12   0.968830        0.976065       0.957247         0.962264      0.952282   \n","13   0.954757        0.966725       0.940063         0.953092      0.927386   \n","14   0.989852        0.993579       0.988506         0.995789      0.981328   \n","15   0.977266        0.983654       0.970711         0.978903      0.962656   \n","16   0.962787        0.973730       0.952582         0.967880      0.937759   \n","17   0.995444        0.997081       0.994797         0.997912      0.991701   \n","18   0.906946        0.935201       0.879740         0.920635      0.842324   \n","19   0.940278        0.956801       0.921610         0.941558      0.902490   \n","20   0.927199        0.949796       0.907527         0.941964      0.875519   \n","21   0.940097        0.955633       0.919831         0.935622      0.904564   \n","22   0.957688        0.967309       0.941545         0.947479      0.935685   \n","23   0.988633        0.991827       0.985417         0.989540      0.981328   \n","24   0.946908        0.960887       0.929399         0.944325      0.914938   \n","25   0.956382        0.969060       0.944034         0.961290      0.927386   \n","26   0.962200        0.971979       0.949686         0.959746      0.939834   \n","27   0.957419        0.969644       0.945148         0.961373      0.929461   \n","28   0.974785        0.981903       0.967539         0.976744      0.958506   \n","29   0.997925        0.998832       0.997921         1.000000      0.995851   \n","30   0.945646        0.960887       0.929101         0.948164      0.910788   \n","31   0.958275        0.969060       0.944386         0.955414      0.933610   \n","32   0.938878        0.953882       0.916930         0.929638      0.904564   \n","\n","             train_conf_mat  validation_auc  validation_accuracy  \\\n","0   [[1218, 13], [15, 467]]        0.822098             0.887955   \n","1   [[1196, 35], [65, 417]]        0.771574             0.873950   \n","2   [[1199, 32], [53, 429]]        0.831334             0.887955   \n","3   [[1218, 13], [31, 451]]        0.790598             0.845938   \n","4    [[1224, 7], [18, 464]]        0.807761             0.865546   \n","5    [[1224, 7], [19, 463]]        0.816239             0.857143   \n","6   [[1220, 11], [26, 456]]        0.809829             0.854342   \n","7   [[1200, 31], [35, 447]]        0.770058             0.857143   \n","8    [[1223, 8], [17, 465]]        0.802178             0.820728   \n","9    [[1225, 6], [10, 472]]        0.810312             0.876751   \n","10  [[1200, 31], [53, 429]]        0.826027             0.829132   \n","11   [[1225, 6], [11, 471]]        0.835677             0.901961   \n","12  [[1213, 18], [23, 459]]        0.807279             0.843137   \n","13  [[1209, 22], [35, 447]]        0.787772             0.848739   \n","14    [[1229, 2], [9, 473]]        0.824924             0.885154   \n","15  [[1221, 10], [18, 464]]        0.818583             0.831933   \n","16  [[1216, 15], [30, 452]]        0.785222             0.837535   \n","17    [[1230, 1], [4, 478]]        0.794389             0.887955   \n","18  [[1196, 35], [76, 406]]        0.811621             0.857143   \n","19  [[1204, 27], [47, 435]]        0.804728             0.831933   \n","20  [[1205, 26], [60, 422]]        0.798042             0.843137   \n","21  [[1201, 30], [46, 436]]        0.814240             0.817927   \n","22  [[1206, 25], [31, 451]]        0.830576             0.879552   \n","23    [[1226, 5], [9, 473]]        0.813413             0.859944   \n","24  [[1205, 26], [41, 441]]        0.802867             0.879552   \n","25  [[1213, 18], [35, 447]]        0.801075             0.876751   \n","26  [[1212, 19], [29, 453]]        0.799835             0.845938   \n","27  [[1213, 18], [34, 448]]        0.827061             0.823529   \n","28  [[1220, 11], [20, 462]]        0.791356             0.854342   \n","29    [[1231, 0], [2, 480]]        0.784946             0.851541   \n","30  [[1207, 24], [43, 439]]        0.806314             0.798319   \n","31  [[1210, 21], [32, 450]]        0.775503             0.815126   \n","32  [[1198, 33], [46, 436]]        0.820582             0.871148   \n","\n","    validation_f1score  validation_precision  validation_recall  \\\n","0             0.733333              0.763889           0.705128   \n","1             0.671533              0.779661           0.589744   \n","2             0.740260              0.750000           0.730769   \n","3             0.662577              0.635294           0.692308   \n","4             0.696203              0.687500           0.705128   \n","5             0.694611              0.651685           0.743590   \n","6             0.686747              0.647727           0.730769   \n","7             0.653061              0.695652           0.615385   \n","8             0.652174              0.566038           0.769231   \n","9             0.710526              0.729730           0.692308   \n","10            0.677249              0.576577           0.820513   \n","11            0.761905              0.811594           0.717949   \n","12            0.674419              0.617021           0.743590   \n","13            0.662500              0.646341           0.679487   \n","14            0.732026              0.746667           0.717949   \n","15            0.673913              0.584906           0.794872   \n","16            0.650602              0.613636           0.692308   \n","17            0.710145              0.816667           0.628205   \n","18            0.690909              0.655172           0.730769   \n","19            0.662921              0.590000           0.756410   \n","20            0.666667              0.622222           0.717949   \n","21            0.659686              0.557522           0.807692   \n","22            0.729560              0.716049           0.743590   \n","23            0.695122              0.662791           0.730769   \n","24            0.707483              0.753623           0.666667   \n","25            0.702703              0.742857           0.666667   \n","26            0.670659              0.629213           0.717949   \n","27            0.673575              0.565217           0.833333   \n","28            0.670886              0.662500           0.679487   \n","29            0.662420              0.658228           0.666667   \n","30            0.640000              0.524590           0.820513   \n","31            0.625000              0.561224           0.705128   \n","32            0.712500              0.695122           0.730769   \n","\n","      validation_conf_mat      RUN_ID  \n","0   [[262, 17], [23, 55]]  coronal451  \n","1   [[266, 13], [32, 46]]  coronal461  \n","2   [[260, 19], [21, 57]]  coronal471  \n","3   [[248, 31], [24, 54]]  coronal481  \n","4   [[254, 25], [23, 55]]  coronal491  \n","5   [[248, 31], [20, 58]]  coronal501  \n","6   [[248, 31], [21, 57]]  coronal511  \n","7   [[258, 21], [30, 48]]  coronal521  \n","8   [[233, 46], [18, 60]]  coronal531  \n","9   [[259, 20], [24, 54]]  coronal541  \n","10  [[232, 47], [14, 64]]  coronal551  \n","11  [[266, 13], [22, 56]]  coronal452  \n","12  [[243, 36], [20, 58]]  coronal462  \n","13  [[250, 29], [25, 53]]  coronal472  \n","14  [[260, 19], [22, 56]]  coronal482  \n","15  [[235, 44], [16, 62]]  coronal492  \n","16  [[245, 34], [24, 54]]  coronal502  \n","17  [[268, 11], [29, 49]]  coronal512  \n","18  [[249, 30], [21, 57]]  coronal522  \n","19  [[238, 41], [19, 59]]  coronal532  \n","20  [[245, 34], [22, 56]]  coronal542  \n","21  [[229, 50], [15, 63]]  coronal552  \n","22  [[256, 23], [20, 58]]  coronal453  \n","23  [[250, 29], [21, 57]]  coronal463  \n","24  [[262, 17], [26, 52]]  coronal473  \n","25  [[261, 18], [26, 52]]  coronal483  \n","26  [[246, 33], [22, 56]]  coronal493  \n","27  [[229, 50], [13, 65]]  coronal503  \n","28  [[252, 27], [25, 53]]  coronal513  \n","29  [[252, 27], [26, 52]]  coronal523  \n","30  [[221, 58], [14, 64]]  coronal533  \n","31  [[236, 43], [23, 55]]  coronal543  \n","32  [[254, 25], [21, 57]]  coronal553  "]},"metadata":{},"execution_count":132}]},{"cell_type":"markdown","metadata":{"id":"zRnkoVqUMPLy"},"source":["## Axial 20-30 + 70-80"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1sjTAWHCKjShQDgKCHDTX0xMA5psFOpP1"},"id":"5rpYY71OMOVx","executionInfo":{"status":"ok","timestamp":1634081019059,"user_tz":180,"elapsed":9689793,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"b7342500-8722-41b9-e855-9b4d6e362d85"},"source":["df_results_axial = run_mris_experiments(orientation = 'axial',\n","                          slices = list(range(20,31)) + list(range(70,81)),\n","                          num_repeats = 3,\n","                          model='shallow_cnn',\n","                          classes=['AD','CN'],\n","                          save_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/data/RESULTS_AXIAL_SHALLOW_CNN.csv')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"v1wXOszxMg2j","executionInfo":{"status":"ok","timestamp":1634081019062,"user_tz":180,"elapsed":33,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"d1ad06d0-eed0-4379-fa28-45914b87e264"},"source":["df_results_axial"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>train_auc</th>\n","      <th>train_accuracy</th>\n","      <th>train_f1score</th>\n","      <th>train_precision</th>\n","      <th>train_recall</th>\n","      <th>train_conf_mat</th>\n","      <th>validation_auc</th>\n","      <th>validation_accuracy</th>\n","      <th>validation_f1score</th>\n","      <th>validation_precision</th>\n","      <th>validation_recall</th>\n","      <th>validation_conf_mat</th>\n","      <th>RUN_ID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.973342</td>\n","      <td>0.980736</td>\n","      <td>0.965445</td>\n","      <td>0.974630</td>\n","      <td>0.956432</td>\n","      <td>[[1219, 12], [21, 461]]</td>\n","      <td>0.861318</td>\n","      <td>0.913165</td>\n","      <td>0.794702</td>\n","      <td>0.821918</td>\n","      <td>0.769231</td>\n","      <td>[[266, 13], [18, 60]]</td>\n","      <td>axial_20_1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.994226</td>\n","      <td>0.995330</td>\n","      <td>0.991701</td>\n","      <td>0.991701</td>\n","      <td>0.991701</td>\n","      <td>[[1227, 4], [4, 478]]</td>\n","      <td>0.775710</td>\n","      <td>0.851541</td>\n","      <td>0.653595</td>\n","      <td>0.666667</td>\n","      <td>0.641026</td>\n","      <td>[[254, 25], [28, 50]]</td>\n","      <td>axial_21_1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.945196</td>\n","      <td>0.962055</td>\n","      <td>0.930777</td>\n","      <td>0.956236</td>\n","      <td>0.906639</td>\n","      <td>[[1211, 20], [45, 437]]</td>\n","      <td>0.814930</td>\n","      <td>0.876751</td>\n","      <td>0.714286</td>\n","      <td>0.723684</td>\n","      <td>0.705128</td>\n","      <td>[[258, 21], [23, 55]]</td>\n","      <td>axial_22_1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.973523</td>\n","      <td>0.981903</td>\n","      <td>0.967403</td>\n","      <td>0.980810</td>\n","      <td>0.954357</td>\n","      <td>[[1222, 9], [22, 460]]</td>\n","      <td>0.884409</td>\n","      <td>0.913165</td>\n","      <td>0.807453</td>\n","      <td>0.783133</td>\n","      <td>0.833333</td>\n","      <td>[[261, 18], [13, 65]]</td>\n","      <td>axial_23_1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.953451</td>\n","      <td>0.968476</td>\n","      <td>0.942553</td>\n","      <td>0.967249</td>\n","      <td>0.919087</td>\n","      <td>[[1216, 15], [39, 443]]</td>\n","      <td>0.823683</td>\n","      <td>0.854342</td>\n","      <td>0.697674</td>\n","      <td>0.638298</td>\n","      <td>0.769231</td>\n","      <td>[[245, 34], [18, 60]]</td>\n","      <td>axial_24_1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.956969</td>\n","      <td>0.970811</td>\n","      <td>0.946921</td>\n","      <td>0.969565</td>\n","      <td>0.925311</td>\n","      <td>[[1217, 14], [36, 446]]</td>\n","      <td>0.785980</td>\n","      <td>0.845938</td>\n","      <td>0.658385</td>\n","      <td>0.638554</td>\n","      <td>0.679487</td>\n","      <td>[[249, 30], [25, 53]]</td>\n","      <td>axial_25_1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.969823</td>\n","      <td>0.978400</td>\n","      <td>0.961175</td>\n","      <td>0.972399</td>\n","      <td>0.950207</td>\n","      <td>[[1218, 13], [24, 458]]</td>\n","      <td>0.838296</td>\n","      <td>0.862745</td>\n","      <td>0.716763</td>\n","      <td>0.652632</td>\n","      <td>0.794872</td>\n","      <td>[[246, 33], [16, 62]]</td>\n","      <td>axial_26_1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1231, 0], [0, 482]]</td>\n","      <td>0.794183</td>\n","      <td>0.851541</td>\n","      <td>0.670807</td>\n","      <td>0.650602</td>\n","      <td>0.692308</td>\n","      <td>[[250, 29], [24, 54]]</td>\n","      <td>axial_27_1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.948533</td>\n","      <td>0.963222</td>\n","      <td>0.933333</td>\n","      <td>0.952484</td>\n","      <td>0.914938</td>\n","      <td>[[1209, 22], [41, 441]]</td>\n","      <td>0.789564</td>\n","      <td>0.851541</td>\n","      <td>0.666667</td>\n","      <td>0.654321</td>\n","      <td>0.679487</td>\n","      <td>[[251, 28], [25, 53]]</td>\n","      <td>axial_28_1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.966711</td>\n","      <td>0.976649</td>\n","      <td>0.957895</td>\n","      <td>0.972222</td>\n","      <td>0.943983</td>\n","      <td>[[1218, 13], [27, 455]]</td>\n","      <td>0.776055</td>\n","      <td>0.787115</td>\n","      <td>0.608247</td>\n","      <td>0.508621</td>\n","      <td>0.756410</td>\n","      <td>[[222, 57], [19, 59]]</td>\n","      <td>axial_29_1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.964862</td>\n","      <td>0.974898</td>\n","      <td>0.954784</td>\n","      <td>0.968017</td>\n","      <td>0.941909</td>\n","      <td>[[1216, 15], [28, 454]]</td>\n","      <td>0.819065</td>\n","      <td>0.854342</td>\n","      <td>0.694118</td>\n","      <td>0.641304</td>\n","      <td>0.756410</td>\n","      <td>[[246, 33], [19, 59]]</td>\n","      <td>axial_30_1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.980333</td>\n","      <td>0.987150</td>\n","      <td>0.976891</td>\n","      <td>0.989362</td>\n","      <td>0.964730</td>\n","      <td>[[1225, 5], [17, 465]]</td>\n","      <td>0.602633</td>\n","      <td>0.775910</td>\n","      <td>0.365079</td>\n","      <td>0.479167</td>\n","      <td>0.294872</td>\n","      <td>[[254, 25], [55, 23]]</td>\n","      <td>axial_70_1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.969371</td>\n","      <td>0.979556</td>\n","      <td>0.963041</td>\n","      <td>0.980645</td>\n","      <td>0.946058</td>\n","      <td>[[1221, 9], [26, 456]]</td>\n","      <td>0.600634</td>\n","      <td>0.736695</td>\n","      <td>0.373333</td>\n","      <td>0.388889</td>\n","      <td>0.358974</td>\n","      <td>[[235, 44], [50, 28]]</td>\n","      <td>axial_71_1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.979926</td>\n","      <td>0.986565</td>\n","      <td>0.975866</td>\n","      <td>0.987261</td>\n","      <td>0.964730</td>\n","      <td>[[1224, 6], [17, 465]]</td>\n","      <td>0.593741</td>\n","      <td>0.711485</td>\n","      <td>0.368098</td>\n","      <td>0.352941</td>\n","      <td>0.384615</td>\n","      <td>[[224, 55], [48, 30]]</td>\n","      <td>axial_72_1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.981776</td>\n","      <td>0.988318</td>\n","      <td>0.978992</td>\n","      <td>0.991489</td>\n","      <td>0.966805</td>\n","      <td>[[1226, 4], [16, 466]]</td>\n","      <td>0.627860</td>\n","      <td>0.714286</td>\n","      <td>0.420455</td>\n","      <td>0.377551</td>\n","      <td>0.474359</td>\n","      <td>[[218, 61], [41, 37]]</td>\n","      <td>axial_73_1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.950740</td>\n","      <td>0.967290</td>\n","      <td>0.940171</td>\n","      <td>0.969163</td>\n","      <td>0.912863</td>\n","      <td>[[1216, 14], [42, 440]]</td>\n","      <td>0.572925</td>\n","      <td>0.736695</td>\n","      <td>0.318841</td>\n","      <td>0.366667</td>\n","      <td>0.282051</td>\n","      <td>[[241, 38], [56, 22]]</td>\n","      <td>axial_74_1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.913523</td>\n","      <td>0.941005</td>\n","      <td>0.890337</td>\n","      <td>0.933941</td>\n","      <td>0.850622</td>\n","      <td>[[1201, 29], [72, 410]]</td>\n","      <td>0.573959</td>\n","      <td>0.731092</td>\n","      <td>0.323944</td>\n","      <td>0.359375</td>\n","      <td>0.294872</td>\n","      <td>[[238, 41], [55, 23]]</td>\n","      <td>axial_75_1</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.906710</td>\n","      <td>0.935748</td>\n","      <td>0.880435</td>\n","      <td>0.924658</td>\n","      <td>0.840249</td>\n","      <td>[[1197, 33], [77, 405]]</td>\n","      <td>0.581403</td>\n","      <td>0.540616</td>\n","      <td>0.383459</td>\n","      <td>0.271277</td>\n","      <td>0.653846</td>\n","      <td>[[142, 137], [27, 51]]</td>\n","      <td>axial_76_1</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.915317</td>\n","      <td>0.936332</td>\n","      <td>0.884656</td>\n","      <td>0.902808</td>\n","      <td>0.867220</td>\n","      <td>[[1185, 45], [64, 418]]</td>\n","      <td>0.559347</td>\n","      <td>0.722689</td>\n","      <td>0.297872</td>\n","      <td>0.333333</td>\n","      <td>0.269231</td>\n","      <td>[[237, 42], [57, 21]]</td>\n","      <td>axial_77_1</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.926153</td>\n","      <td>0.949182</td>\n","      <td>0.906351</td>\n","      <td>0.941834</td>\n","      <td>0.873444</td>\n","      <td>[[1204, 26], [61, 421]]</td>\n","      <td>0.580301</td>\n","      <td>0.784314</td>\n","      <td>0.306306</td>\n","      <td>0.515152</td>\n","      <td>0.217949</td>\n","      <td>[[263, 16], [61, 17]]</td>\n","      <td>axial_78_1</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>0.812747</td>\n","      <td>0.873248</td>\n","      <td>0.749712</td>\n","      <td>0.844156</td>\n","      <td>0.674274</td>\n","      <td>[[1170, 60], [157, 325]]</td>\n","      <td>0.536463</td>\n","      <td>0.759104</td>\n","      <td>0.203704</td>\n","      <td>0.366667</td>\n","      <td>0.141026</td>\n","      <td>[[260, 19], [67, 11]]</td>\n","      <td>axial_79_1</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0.932517</td>\n","      <td>0.955607</td>\n","      <td>0.917749</td>\n","      <td>0.959276</td>\n","      <td>0.879668</td>\n","      <td>[[1212, 18], [58, 424]]</td>\n","      <td>0.550179</td>\n","      <td>0.672269</td>\n","      <td>0.307692</td>\n","      <td>0.285714</td>\n","      <td>0.333333</td>\n","      <td>[[214, 65], [52, 26]]</td>\n","      <td>axial_80_1</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0.867246</td>\n","      <td>0.899008</td>\n","      <td>0.815761</td>\n","      <td>0.838074</td>\n","      <td>0.794606</td>\n","      <td>[[1157, 74], [99, 383]]</td>\n","      <td>0.757720</td>\n","      <td>0.873950</td>\n","      <td>0.656489</td>\n","      <td>0.811321</td>\n","      <td>0.551282</td>\n","      <td>[[269, 10], [35, 43]]</td>\n","      <td>axial_20_2</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0.914520</td>\n","      <td>0.935201</td>\n","      <td>0.882788</td>\n","      <td>0.898925</td>\n","      <td>0.867220</td>\n","      <td>[[1184, 47], [64, 418]]</td>\n","      <td>0.769024</td>\n","      <td>0.862745</td>\n","      <td>0.657343</td>\n","      <td>0.723077</td>\n","      <td>0.602564</td>\n","      <td>[[261, 18], [31, 47]]</td>\n","      <td>axial_21_2</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0.997113</td>\n","      <td>0.997665</td>\n","      <td>0.995851</td>\n","      <td>0.995851</td>\n","      <td>0.995851</td>\n","      <td>[[1229, 2], [2, 480]]</td>\n","      <td>0.810587</td>\n","      <td>0.862745</td>\n","      <td>0.695652</td>\n","      <td>0.674699</td>\n","      <td>0.717949</td>\n","      <td>[[252, 27], [22, 56]]</td>\n","      <td>axial_22_2</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0.942265</td>\n","      <td>0.961471</td>\n","      <td>0.929185</td>\n","      <td>0.962222</td>\n","      <td>0.898340</td>\n","      <td>[[1214, 17], [49, 433]]</td>\n","      <td>0.839813</td>\n","      <td>0.879552</td>\n","      <td>0.736196</td>\n","      <td>0.705882</td>\n","      <td>0.769231</td>\n","      <td>[[254, 25], [18, 60]]</td>\n","      <td>axial_23_2</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0.856785</td>\n","      <td>0.896673</td>\n","      <td>0.806557</td>\n","      <td>0.852194</td>\n","      <td>0.765560</td>\n","      <td>[[1167, 64], [113, 369]]</td>\n","      <td>0.814930</td>\n","      <td>0.876751</td>\n","      <td>0.714286</td>\n","      <td>0.723684</td>\n","      <td>0.705128</td>\n","      <td>[[258, 21], [23, 55]]</td>\n","      <td>axial_24_2</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>0.965043</td>\n","      <td>0.976065</td>\n","      <td>0.956705</td>\n","      <td>0.974194</td>\n","      <td>0.939834</td>\n","      <td>[[1219, 12], [29, 453]]</td>\n","      <td>0.794389</td>\n","      <td>0.887955</td>\n","      <td>0.710145</td>\n","      <td>0.816667</td>\n","      <td>0.628205</td>\n","      <td>[[268, 11], [29, 49]]</td>\n","      <td>axial_25_2</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0.955076</td>\n","      <td>0.970811</td>\n","      <td>0.946581</td>\n","      <td>0.975771</td>\n","      <td>0.919087</td>\n","      <td>[[1220, 11], [39, 443]]</td>\n","      <td>0.816722</td>\n","      <td>0.879552</td>\n","      <td>0.718954</td>\n","      <td>0.733333</td>\n","      <td>0.705128</td>\n","      <td>[[259, 20], [23, 55]]</td>\n","      <td>axial_26_2</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>0.960937</td>\n","      <td>0.971979</td>\n","      <td>0.949474</td>\n","      <td>0.963675</td>\n","      <td>0.935685</td>\n","      <td>[[1214, 17], [31, 451]]</td>\n","      <td>0.809347</td>\n","      <td>0.831933</td>\n","      <td>0.666667</td>\n","      <td>0.588235</td>\n","      <td>0.769231</td>\n","      <td>[[237, 42], [18, 60]]</td>\n","      <td>axial_27_2</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>0.945377</td>\n","      <td>0.963222</td>\n","      <td>0.932620</td>\n","      <td>0.962472</td>\n","      <td>0.904564</td>\n","      <td>[[1214, 17], [46, 436]]</td>\n","      <td>0.794941</td>\n","      <td>0.859944</td>\n","      <td>0.679487</td>\n","      <td>0.679487</td>\n","      <td>0.679487</td>\n","      <td>[[254, 25], [25, 53]]</td>\n","      <td>axial_28_2</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>0.974966</td>\n","      <td>0.983071</td>\n","      <td>0.969506</td>\n","      <td>0.982942</td>\n","      <td>0.956432</td>\n","      <td>[[1223, 8], [21, 461]]</td>\n","      <td>0.833402</td>\n","      <td>0.876751</td>\n","      <td>0.728395</td>\n","      <td>0.702381</td>\n","      <td>0.756410</td>\n","      <td>[[254, 25], [19, 59]]</td>\n","      <td>axial_29_2</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>0.990483</td>\n","      <td>0.993579</td>\n","      <td>0.988530</td>\n","      <td>0.993711</td>\n","      <td>0.983402</td>\n","      <td>[[1228, 3], [8, 474]]</td>\n","      <td>0.825751</td>\n","      <td>0.843137</td>\n","      <td>0.688889</td>\n","      <td>0.607843</td>\n","      <td>0.794872</td>\n","      <td>[[239, 40], [16, 62]]</td>\n","      <td>axial_30_2</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>0.998556</td>\n","      <td>0.998832</td>\n","      <td>0.997925</td>\n","      <td>0.997925</td>\n","      <td>0.997925</td>\n","      <td>[[1229, 1], [1, 481]]</td>\n","      <td>0.616970</td>\n","      <td>0.798319</td>\n","      <td>0.389831</td>\n","      <td>0.575000</td>\n","      <td>0.294872</td>\n","      <td>[[262, 17], [55, 23]]</td>\n","      <td>axial_70_2</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>0.941040</td>\n","      <td>0.959696</td>\n","      <td>0.926203</td>\n","      <td>0.955850</td>\n","      <td>0.898340</td>\n","      <td>[[1210, 20], [49, 433]]</td>\n","      <td>0.565757</td>\n","      <td>0.725490</td>\n","      <td>0.309859</td>\n","      <td>0.343750</td>\n","      <td>0.282051</td>\n","      <td>[[237, 42], [56, 22]]</td>\n","      <td>axial_71_2</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>0.914518</td>\n","      <td>0.943341</td>\n","      <td>0.893989</td>\n","      <td>0.944573</td>\n","      <td>0.848548</td>\n","      <td>[[1206, 24], [73, 409]]</td>\n","      <td>0.615316</td>\n","      <td>0.694678</td>\n","      <td>0.404372</td>\n","      <td>0.352381</td>\n","      <td>0.474359</td>\n","      <td>[[211, 68], [41, 37]]</td>\n","      <td>axial_72_2</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>0.953222</td>\n","      <td>0.969042</td>\n","      <td>0.943436</td>\n","      <td>0.971429</td>\n","      <td>0.917012</td>\n","      <td>[[1217, 13], [40, 442]]</td>\n","      <td>0.604563</td>\n","      <td>0.677871</td>\n","      <td>0.391534</td>\n","      <td>0.333333</td>\n","      <td>0.474359</td>\n","      <td>[[205, 74], [41, 37]]</td>\n","      <td>axial_73_2</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1230, 0], [0, 482]]</td>\n","      <td>0.565274</td>\n","      <td>0.703081</td>\n","      <td>0.320513</td>\n","      <td>0.320513</td>\n","      <td>0.320513</td>\n","      <td>[[226, 53], [53, 25]]</td>\n","      <td>axial_74_2</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>0.959488</td>\n","      <td>0.970794</td>\n","      <td>0.947368</td>\n","      <td>0.961538</td>\n","      <td>0.933610</td>\n","      <td>[[1212, 18], [32, 450]]</td>\n","      <td>0.540323</td>\n","      <td>0.750700</td>\n","      <td>0.226087</td>\n","      <td>0.351351</td>\n","      <td>0.166667</td>\n","      <td>[[255, 24], [65, 13]]</td>\n","      <td>axial_75_2</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>0.500000</td>\n","      <td>0.718458</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[1230, 0], [482, 0]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_76_2</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>0.983038</td>\n","      <td>0.988318</td>\n","      <td>0.979079</td>\n","      <td>0.987342</td>\n","      <td>0.970954</td>\n","      <td>[[1224, 6], [14, 468]]</td>\n","      <td>0.577061</td>\n","      <td>0.714286</td>\n","      <td>0.337662</td>\n","      <td>0.342105</td>\n","      <td>0.333333</td>\n","      <td>[[229, 50], [52, 26]]</td>\n","      <td>axial_77_2</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1230, 0], [0, 482]]</td>\n","      <td>0.558313</td>\n","      <td>0.728291</td>\n","      <td>0.291971</td>\n","      <td>0.338983</td>\n","      <td>0.256410</td>\n","      <td>[[240, 39], [58, 20]]</td>\n","      <td>axial_78_2</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>0.897374</td>\n","      <td>0.930491</td>\n","      <td>0.869374</td>\n","      <td>0.923077</td>\n","      <td>0.821577</td>\n","      <td>[[1197, 33], [86, 396]]</td>\n","      <td>0.556383</td>\n","      <td>0.638655</td>\n","      <td>0.331606</td>\n","      <td>0.278261</td>\n","      <td>0.410256</td>\n","      <td>[[196, 83], [46, 32]]</td>\n","      <td>axial_79_2</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>0.951413</td>\n","      <td>0.965537</td>\n","      <td>0.937566</td>\n","      <td>0.956803</td>\n","      <td>0.919087</td>\n","      <td>[[1210, 20], [39, 443]]</td>\n","      <td>0.595671</td>\n","      <td>0.613445</td>\n","      <td>0.389381</td>\n","      <td>0.297297</td>\n","      <td>0.564103</td>\n","      <td>[[175, 104], [34, 44]]</td>\n","      <td>axial_80_2</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1231, 0], [0, 482]]</td>\n","      <td>0.825958</td>\n","      <td>0.879552</td>\n","      <td>0.726115</td>\n","      <td>0.721519</td>\n","      <td>0.730769</td>\n","      <td>[[257, 22], [21, 57]]</td>\n","      <td>axial_20_3</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>0.917857</td>\n","      <td>0.936369</td>\n","      <td>0.885624</td>\n","      <td>0.895966</td>\n","      <td>0.875519</td>\n","      <td>[[1182, 49], [60, 422]]</td>\n","      <td>0.781569</td>\n","      <td>0.882353</td>\n","      <td>0.691176</td>\n","      <td>0.810345</td>\n","      <td>0.602564</td>\n","      <td>[[268, 11], [31, 47]]</td>\n","      <td>axial_21_3</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>0.944203</td>\n","      <td>0.959720</td>\n","      <td>0.926984</td>\n","      <td>0.946004</td>\n","      <td>0.908714</td>\n","      <td>[[1206, 25], [44, 438]]</td>\n","      <td>0.859801</td>\n","      <td>0.896359</td>\n","      <td>0.770186</td>\n","      <td>0.746988</td>\n","      <td>0.794872</td>\n","      <td>[[258, 21], [16, 62]]</td>\n","      <td>axial_22_3</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>0.998556</td>\n","      <td>0.998832</td>\n","      <td>0.997925</td>\n","      <td>0.997925</td>\n","      <td>0.997925</td>\n","      <td>[[1230, 1], [1, 481]]</td>\n","      <td>0.801351</td>\n","      <td>0.862745</td>\n","      <td>0.687898</td>\n","      <td>0.683544</td>\n","      <td>0.692308</td>\n","      <td>[[254, 25], [24, 54]]</td>\n","      <td>axial_23_3</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>0.947090</td>\n","      <td>0.962055</td>\n","      <td>0.931217</td>\n","      <td>0.950324</td>\n","      <td>0.912863</td>\n","      <td>[[1208, 23], [42, 440]]</td>\n","      <td>0.837055</td>\n","      <td>0.831933</td>\n","      <td>0.687500</td>\n","      <td>0.578947</td>\n","      <td>0.846154</td>\n","      <td>[[231, 48], [12, 66]]</td>\n","      <td>axial_24_3</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>0.961344</td>\n","      <td>0.972563</td>\n","      <td>0.950474</td>\n","      <td>0.965739</td>\n","      <td>0.935685</td>\n","      <td>[[1215, 16], [31, 451]]</td>\n","      <td>0.798525</td>\n","      <td>0.865546</td>\n","      <td>0.688312</td>\n","      <td>0.697368</td>\n","      <td>0.679487</td>\n","      <td>[[256, 23], [25, 53]]</td>\n","      <td>axial_25_3</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>0.969598</td>\n","      <td>0.978984</td>\n","      <td>0.962105</td>\n","      <td>0.976496</td>\n","      <td>0.948133</td>\n","      <td>[[1220, 11], [25, 457]]</td>\n","      <td>0.809278</td>\n","      <td>0.882353</td>\n","      <td>0.716216</td>\n","      <td>0.757143</td>\n","      <td>0.679487</td>\n","      <td>[[262, 17], [25, 53]]</td>\n","      <td>axial_26_3</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>0.972486</td>\n","      <td>0.981319</td>\n","      <td>0.966316</td>\n","      <td>0.980769</td>\n","      <td>0.952282</td>\n","      <td>[[1222, 9], [23, 459]]</td>\n","      <td>0.765440</td>\n","      <td>0.857143</td>\n","      <td>0.648276</td>\n","      <td>0.701493</td>\n","      <td>0.602564</td>\n","      <td>[[259, 20], [31, 47]]</td>\n","      <td>axial_27_3</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>0.954757</td>\n","      <td>0.966725</td>\n","      <td>0.940063</td>\n","      <td>0.953092</td>\n","      <td>0.927386</td>\n","      <td>[[1209, 22], [35, 447]]</td>\n","      <td>0.760063</td>\n","      <td>0.848739</td>\n","      <td>0.635135</td>\n","      <td>0.671429</td>\n","      <td>0.602564</td>\n","      <td>[[256, 23], [31, 47]]</td>\n","      <td>axial_28_3</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>0.965312</td>\n","      <td>0.973730</td>\n","      <td>0.952978</td>\n","      <td>0.960000</td>\n","      <td>0.946058</td>\n","      <td>[[1212, 19], [26, 456]]</td>\n","      <td>0.820651</td>\n","      <td>0.820728</td>\n","      <td>0.666667</td>\n","      <td>0.561404</td>\n","      <td>0.820513</td>\n","      <td>[[229, 50], [14, 64]]</td>\n","      <td>axial_29_3</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>0.965312</td>\n","      <td>0.973730</td>\n","      <td>0.952978</td>\n","      <td>0.960000</td>\n","      <td>0.946058</td>\n","      <td>[[1212, 19], [26, 456]]</td>\n","      <td>0.809829</td>\n","      <td>0.854342</td>\n","      <td>0.686747</td>\n","      <td>0.647727</td>\n","      <td>0.730769</td>\n","      <td>[[248, 31], [21, 57]]</td>\n","      <td>axial_30_3</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>0.868552</td>\n","      <td>0.913551</td>\n","      <td>0.832957</td>\n","      <td>0.913366</td>\n","      <td>0.765560</td>\n","      <td>[[1195, 35], [113, 369]]</td>\n","      <td>0.530052</td>\n","      <td>0.756303</td>\n","      <td>0.186916</td>\n","      <td>0.344828</td>\n","      <td>0.128205</td>\n","      <td>[[260, 19], [68, 10]]</td>\n","      <td>axial_70_3</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>0.953222</td>\n","      <td>0.969042</td>\n","      <td>0.943436</td>\n","      <td>0.971429</td>\n","      <td>0.917012</td>\n","      <td>[[1217, 13], [40, 442]]</td>\n","      <td>0.581472</td>\n","      <td>0.677871</td>\n","      <td>0.357542</td>\n","      <td>0.316832</td>\n","      <td>0.410256</td>\n","      <td>[[210, 69], [46, 32]]</td>\n","      <td>axial_71_3</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>0.962922</td>\n","      <td>0.976636</td>\n","      <td>0.957356</td>\n","      <td>0.984649</td>\n","      <td>0.931535</td>\n","      <td>[[1223, 7], [33, 449]]</td>\n","      <td>0.593259</td>\n","      <td>0.689076</td>\n","      <td>0.372881</td>\n","      <td>0.333333</td>\n","      <td>0.423077</td>\n","      <td>[[213, 66], [45, 33]]</td>\n","      <td>axial_72_3</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>0.950740</td>\n","      <td>0.967290</td>\n","      <td>0.940171</td>\n","      <td>0.969163</td>\n","      <td>0.912863</td>\n","      <td>[[1216, 14], [42, 440]]</td>\n","      <td>0.572994</td>\n","      <td>0.686275</td>\n","      <td>0.341176</td>\n","      <td>0.315217</td>\n","      <td>0.371795</td>\n","      <td>[[216, 63], [49, 29]]</td>\n","      <td>axial_73_3</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>0.956782</td>\n","      <td>0.969626</td>\n","      <td>0.945032</td>\n","      <td>0.963362</td>\n","      <td>0.927386</td>\n","      <td>[[1213, 17], [35, 447]]</td>\n","      <td>0.563207</td>\n","      <td>0.714286</td>\n","      <td>0.310811</td>\n","      <td>0.328571</td>\n","      <td>0.294872</td>\n","      <td>[[232, 47], [55, 23]]</td>\n","      <td>axial_74_3</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>0.995444</td>\n","      <td>0.997079</td>\n","      <td>0.994797</td>\n","      <td>0.997912</td>\n","      <td>0.991701</td>\n","      <td>[[1229, 1], [4, 478]]</td>\n","      <td>0.541356</td>\n","      <td>0.745098</td>\n","      <td>0.235294</td>\n","      <td>0.341463</td>\n","      <td>0.179487</td>\n","      <td>[[252, 27], [64, 14]]</td>\n","      <td>axial_75_3</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1230, 0], [0, 482]]</td>\n","      <td>0.558037</td>\n","      <td>0.742297</td>\n","      <td>0.281250</td>\n","      <td>0.360000</td>\n","      <td>0.230769</td>\n","      <td>[[247, 32], [60, 18]]</td>\n","      <td>axial_76_3</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>0.965670</td>\n","      <td>0.976051</td>\n","      <td>0.956797</td>\n","      <td>0.972163</td>\n","      <td>0.941909</td>\n","      <td>[[1217, 13], [28, 454]]</td>\n","      <td>0.577268</td>\n","      <td>0.750700</td>\n","      <td>0.320611</td>\n","      <td>0.396226</td>\n","      <td>0.269231</td>\n","      <td>[[247, 32], [57, 21]]</td>\n","      <td>axial_77_3</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>0.930891</td>\n","      <td>0.953271</td>\n","      <td>0.913793</td>\n","      <td>0.950673</td>\n","      <td>0.879668</td>\n","      <td>[[1208, 22], [58, 424]]</td>\n","      <td>0.569203</td>\n","      <td>0.644258</td>\n","      <td>0.348718</td>\n","      <td>0.290598</td>\n","      <td>0.435897</td>\n","      <td>[[196, 83], [44, 34]]</td>\n","      <td>axial_78_3</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>0.503336</td>\n","      <td>0.719626</td>\n","      <td>0.016393</td>\n","      <td>0.666667</td>\n","      <td>0.008299</td>\n","      <td>[[1228, 2], [478, 4]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_79_3</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>0.929671</td>\n","      <td>0.951519</td>\n","      <td>0.910849</td>\n","      <td>0.944321</td>\n","      <td>0.879668</td>\n","      <td>[[1205, 25], [58, 424]]</td>\n","      <td>0.584850</td>\n","      <td>0.647059</td>\n","      <td>0.370000</td>\n","      <td>0.303279</td>\n","      <td>0.474359</td>\n","      <td>[[194, 85], [41, 37]]</td>\n","      <td>axial_80_3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    train_auc  train_accuracy  train_f1score  train_precision  train_recall  \\\n","0    0.973342        0.980736       0.965445         0.974630      0.956432   \n","1    0.994226        0.995330       0.991701         0.991701      0.991701   \n","2    0.945196        0.962055       0.930777         0.956236      0.906639   \n","3    0.973523        0.981903       0.967403         0.980810      0.954357   \n","4    0.953451        0.968476       0.942553         0.967249      0.919087   \n","5    0.956969        0.970811       0.946921         0.969565      0.925311   \n","6    0.969823        0.978400       0.961175         0.972399      0.950207   \n","7    1.000000        1.000000       1.000000         1.000000      1.000000   \n","8    0.948533        0.963222       0.933333         0.952484      0.914938   \n","9    0.966711        0.976649       0.957895         0.972222      0.943983   \n","10   0.964862        0.974898       0.954784         0.968017      0.941909   \n","11   0.980333        0.987150       0.976891         0.989362      0.964730   \n","12   0.969371        0.979556       0.963041         0.980645      0.946058   \n","13   0.979926        0.986565       0.975866         0.987261      0.964730   \n","14   0.981776        0.988318       0.978992         0.991489      0.966805   \n","15   0.950740        0.967290       0.940171         0.969163      0.912863   \n","16   0.913523        0.941005       0.890337         0.933941      0.850622   \n","17   0.906710        0.935748       0.880435         0.924658      0.840249   \n","18   0.915317        0.936332       0.884656         0.902808      0.867220   \n","19   0.926153        0.949182       0.906351         0.941834      0.873444   \n","20   0.812747        0.873248       0.749712         0.844156      0.674274   \n","21   0.932517        0.955607       0.917749         0.959276      0.879668   \n","22   0.867246        0.899008       0.815761         0.838074      0.794606   \n","23   0.914520        0.935201       0.882788         0.898925      0.867220   \n","24   0.997113        0.997665       0.995851         0.995851      0.995851   \n","25   0.942265        0.961471       0.929185         0.962222      0.898340   \n","26   0.856785        0.896673       0.806557         0.852194      0.765560   \n","27   0.965043        0.976065       0.956705         0.974194      0.939834   \n","28   0.955076        0.970811       0.946581         0.975771      0.919087   \n","29   0.960937        0.971979       0.949474         0.963675      0.935685   \n","30   0.945377        0.963222       0.932620         0.962472      0.904564   \n","31   0.974966        0.983071       0.969506         0.982942      0.956432   \n","32   0.990483        0.993579       0.988530         0.993711      0.983402   \n","33   0.998556        0.998832       0.997925         0.997925      0.997925   \n","34   0.941040        0.959696       0.926203         0.955850      0.898340   \n","35   0.914518        0.943341       0.893989         0.944573      0.848548   \n","36   0.953222        0.969042       0.943436         0.971429      0.917012   \n","37   1.000000        1.000000       1.000000         1.000000      1.000000   \n","38   0.959488        0.970794       0.947368         0.961538      0.933610   \n","39   0.500000        0.718458       0.000000         0.000000      0.000000   \n","40   0.983038        0.988318       0.979079         0.987342      0.970954   \n","41   1.000000        1.000000       1.000000         1.000000      1.000000   \n","42   0.897374        0.930491       0.869374         0.923077      0.821577   \n","43   0.951413        0.965537       0.937566         0.956803      0.919087   \n","44   1.000000        1.000000       1.000000         1.000000      1.000000   \n","45   0.917857        0.936369       0.885624         0.895966      0.875519   \n","46   0.944203        0.959720       0.926984         0.946004      0.908714   \n","47   0.998556        0.998832       0.997925         0.997925      0.997925   \n","48   0.947090        0.962055       0.931217         0.950324      0.912863   \n","49   0.961344        0.972563       0.950474         0.965739      0.935685   \n","50   0.969598        0.978984       0.962105         0.976496      0.948133   \n","51   0.972486        0.981319       0.966316         0.980769      0.952282   \n","52   0.954757        0.966725       0.940063         0.953092      0.927386   \n","53   0.965312        0.973730       0.952978         0.960000      0.946058   \n","54   0.965312        0.973730       0.952978         0.960000      0.946058   \n","55   0.868552        0.913551       0.832957         0.913366      0.765560   \n","56   0.953222        0.969042       0.943436         0.971429      0.917012   \n","57   0.962922        0.976636       0.957356         0.984649      0.931535   \n","58   0.950740        0.967290       0.940171         0.969163      0.912863   \n","59   0.956782        0.969626       0.945032         0.963362      0.927386   \n","60   0.995444        0.997079       0.994797         0.997912      0.991701   \n","61   1.000000        1.000000       1.000000         1.000000      1.000000   \n","62   0.965670        0.976051       0.956797         0.972163      0.941909   \n","63   0.930891        0.953271       0.913793         0.950673      0.879668   \n","64   0.503336        0.719626       0.016393         0.666667      0.008299   \n","65   0.929671        0.951519       0.910849         0.944321      0.879668   \n","\n","              train_conf_mat  validation_auc  validation_accuracy  \\\n","0    [[1219, 12], [21, 461]]        0.861318             0.913165   \n","1      [[1227, 4], [4, 478]]        0.775710             0.851541   \n","2    [[1211, 20], [45, 437]]        0.814930             0.876751   \n","3     [[1222, 9], [22, 460]]        0.884409             0.913165   \n","4    [[1216, 15], [39, 443]]        0.823683             0.854342   \n","5    [[1217, 14], [36, 446]]        0.785980             0.845938   \n","6    [[1218, 13], [24, 458]]        0.838296             0.862745   \n","7      [[1231, 0], [0, 482]]        0.794183             0.851541   \n","8    [[1209, 22], [41, 441]]        0.789564             0.851541   \n","9    [[1218, 13], [27, 455]]        0.776055             0.787115   \n","10   [[1216, 15], [28, 454]]        0.819065             0.854342   \n","11    [[1225, 5], [17, 465]]        0.602633             0.775910   \n","12    [[1221, 9], [26, 456]]        0.600634             0.736695   \n","13    [[1224, 6], [17, 465]]        0.593741             0.711485   \n","14    [[1226, 4], [16, 466]]        0.627860             0.714286   \n","15   [[1216, 14], [42, 440]]        0.572925             0.736695   \n","16   [[1201, 29], [72, 410]]        0.573959             0.731092   \n","17   [[1197, 33], [77, 405]]        0.581403             0.540616   \n","18   [[1185, 45], [64, 418]]        0.559347             0.722689   \n","19   [[1204, 26], [61, 421]]        0.580301             0.784314   \n","20  [[1170, 60], [157, 325]]        0.536463             0.759104   \n","21   [[1212, 18], [58, 424]]        0.550179             0.672269   \n","22   [[1157, 74], [99, 383]]        0.757720             0.873950   \n","23   [[1184, 47], [64, 418]]        0.769024             0.862745   \n","24     [[1229, 2], [2, 480]]        0.810587             0.862745   \n","25   [[1214, 17], [49, 433]]        0.839813             0.879552   \n","26  [[1167, 64], [113, 369]]        0.814930             0.876751   \n","27   [[1219, 12], [29, 453]]        0.794389             0.887955   \n","28   [[1220, 11], [39, 443]]        0.816722             0.879552   \n","29   [[1214, 17], [31, 451]]        0.809347             0.831933   \n","30   [[1214, 17], [46, 436]]        0.794941             0.859944   \n","31    [[1223, 8], [21, 461]]        0.833402             0.876751   \n","32     [[1228, 3], [8, 474]]        0.825751             0.843137   \n","33     [[1229, 1], [1, 481]]        0.616970             0.798319   \n","34   [[1210, 20], [49, 433]]        0.565757             0.725490   \n","35   [[1206, 24], [73, 409]]        0.615316             0.694678   \n","36   [[1217, 13], [40, 442]]        0.604563             0.677871   \n","37     [[1230, 0], [0, 482]]        0.565274             0.703081   \n","38   [[1212, 18], [32, 450]]        0.540323             0.750700   \n","39     [[1230, 0], [482, 0]]        0.500000             0.781513   \n","40    [[1224, 6], [14, 468]]        0.577061             0.714286   \n","41     [[1230, 0], [0, 482]]        0.558313             0.728291   \n","42   [[1197, 33], [86, 396]]        0.556383             0.638655   \n","43   [[1210, 20], [39, 443]]        0.595671             0.613445   \n","44     [[1231, 0], [0, 482]]        0.825958             0.879552   \n","45   [[1182, 49], [60, 422]]        0.781569             0.882353   \n","46   [[1206, 25], [44, 438]]        0.859801             0.896359   \n","47     [[1230, 1], [1, 481]]        0.801351             0.862745   \n","48   [[1208, 23], [42, 440]]        0.837055             0.831933   \n","49   [[1215, 16], [31, 451]]        0.798525             0.865546   \n","50   [[1220, 11], [25, 457]]        0.809278             0.882353   \n","51    [[1222, 9], [23, 459]]        0.765440             0.857143   \n","52   [[1209, 22], [35, 447]]        0.760063             0.848739   \n","53   [[1212, 19], [26, 456]]        0.820651             0.820728   \n","54   [[1212, 19], [26, 456]]        0.809829             0.854342   \n","55  [[1195, 35], [113, 369]]        0.530052             0.756303   \n","56   [[1217, 13], [40, 442]]        0.581472             0.677871   \n","57    [[1223, 7], [33, 449]]        0.593259             0.689076   \n","58   [[1216, 14], [42, 440]]        0.572994             0.686275   \n","59   [[1213, 17], [35, 447]]        0.563207             0.714286   \n","60     [[1229, 1], [4, 478]]        0.541356             0.745098   \n","61     [[1230, 0], [0, 482]]        0.558037             0.742297   \n","62   [[1217, 13], [28, 454]]        0.577268             0.750700   \n","63   [[1208, 22], [58, 424]]        0.569203             0.644258   \n","64     [[1228, 2], [478, 4]]        0.500000             0.781513   \n","65   [[1205, 25], [58, 424]]        0.584850             0.647059   \n","\n","    validation_f1score  validation_precision  validation_recall  \\\n","0             0.794702              0.821918           0.769231   \n","1             0.653595              0.666667           0.641026   \n","2             0.714286              0.723684           0.705128   \n","3             0.807453              0.783133           0.833333   \n","4             0.697674              0.638298           0.769231   \n","5             0.658385              0.638554           0.679487   \n","6             0.716763              0.652632           0.794872   \n","7             0.670807              0.650602           0.692308   \n","8             0.666667              0.654321           0.679487   \n","9             0.608247              0.508621           0.756410   \n","10            0.694118              0.641304           0.756410   \n","11            0.365079              0.479167           0.294872   \n","12            0.373333              0.388889           0.358974   \n","13            0.368098              0.352941           0.384615   \n","14            0.420455              0.377551           0.474359   \n","15            0.318841              0.366667           0.282051   \n","16            0.323944              0.359375           0.294872   \n","17            0.383459              0.271277           0.653846   \n","18            0.297872              0.333333           0.269231   \n","19            0.306306              0.515152           0.217949   \n","20            0.203704              0.366667           0.141026   \n","21            0.307692              0.285714           0.333333   \n","22            0.656489              0.811321           0.551282   \n","23            0.657343              0.723077           0.602564   \n","24            0.695652              0.674699           0.717949   \n","25            0.736196              0.705882           0.769231   \n","26            0.714286              0.723684           0.705128   \n","27            0.710145              0.816667           0.628205   \n","28            0.718954              0.733333           0.705128   \n","29            0.666667              0.588235           0.769231   \n","30            0.679487              0.679487           0.679487   \n","31            0.728395              0.702381           0.756410   \n","32            0.688889              0.607843           0.794872   \n","33            0.389831              0.575000           0.294872   \n","34            0.309859              0.343750           0.282051   \n","35            0.404372              0.352381           0.474359   \n","36            0.391534              0.333333           0.474359   \n","37            0.320513              0.320513           0.320513   \n","38            0.226087              0.351351           0.166667   \n","39            0.000000              0.000000           0.000000   \n","40            0.337662              0.342105           0.333333   \n","41            0.291971              0.338983           0.256410   \n","42            0.331606              0.278261           0.410256   \n","43            0.389381              0.297297           0.564103   \n","44            0.726115              0.721519           0.730769   \n","45            0.691176              0.810345           0.602564   \n","46            0.770186              0.746988           0.794872   \n","47            0.687898              0.683544           0.692308   \n","48            0.687500              0.578947           0.846154   \n","49            0.688312              0.697368           0.679487   \n","50            0.716216              0.757143           0.679487   \n","51            0.648276              0.701493           0.602564   \n","52            0.635135              0.671429           0.602564   \n","53            0.666667              0.561404           0.820513   \n","54            0.686747              0.647727           0.730769   \n","55            0.186916              0.344828           0.128205   \n","56            0.357542              0.316832           0.410256   \n","57            0.372881              0.333333           0.423077   \n","58            0.341176              0.315217           0.371795   \n","59            0.310811              0.328571           0.294872   \n","60            0.235294              0.341463           0.179487   \n","61            0.281250              0.360000           0.230769   \n","62            0.320611              0.396226           0.269231   \n","63            0.348718              0.290598           0.435897   \n","64            0.000000              0.000000           0.000000   \n","65            0.370000              0.303279           0.474359   \n","\n","       validation_conf_mat      RUN_ID  \n","0    [[266, 13], [18, 60]]  axial_20_1  \n","1    [[254, 25], [28, 50]]  axial_21_1  \n","2    [[258, 21], [23, 55]]  axial_22_1  \n","3    [[261, 18], [13, 65]]  axial_23_1  \n","4    [[245, 34], [18, 60]]  axial_24_1  \n","5    [[249, 30], [25, 53]]  axial_25_1  \n","6    [[246, 33], [16, 62]]  axial_26_1  \n","7    [[250, 29], [24, 54]]  axial_27_1  \n","8    [[251, 28], [25, 53]]  axial_28_1  \n","9    [[222, 57], [19, 59]]  axial_29_1  \n","10   [[246, 33], [19, 59]]  axial_30_1  \n","11   [[254, 25], [55, 23]]  axial_70_1  \n","12   [[235, 44], [50, 28]]  axial_71_1  \n","13   [[224, 55], [48, 30]]  axial_72_1  \n","14   [[218, 61], [41, 37]]  axial_73_1  \n","15   [[241, 38], [56, 22]]  axial_74_1  \n","16   [[238, 41], [55, 23]]  axial_75_1  \n","17  [[142, 137], [27, 51]]  axial_76_1  \n","18   [[237, 42], [57, 21]]  axial_77_1  \n","19   [[263, 16], [61, 17]]  axial_78_1  \n","20   [[260, 19], [67, 11]]  axial_79_1  \n","21   [[214, 65], [52, 26]]  axial_80_1  \n","22   [[269, 10], [35, 43]]  axial_20_2  \n","23   [[261, 18], [31, 47]]  axial_21_2  \n","24   [[252, 27], [22, 56]]  axial_22_2  \n","25   [[254, 25], [18, 60]]  axial_23_2  \n","26   [[258, 21], [23, 55]]  axial_24_2  \n","27   [[268, 11], [29, 49]]  axial_25_2  \n","28   [[259, 20], [23, 55]]  axial_26_2  \n","29   [[237, 42], [18, 60]]  axial_27_2  \n","30   [[254, 25], [25, 53]]  axial_28_2  \n","31   [[254, 25], [19, 59]]  axial_29_2  \n","32   [[239, 40], [16, 62]]  axial_30_2  \n","33   [[262, 17], [55, 23]]  axial_70_2  \n","34   [[237, 42], [56, 22]]  axial_71_2  \n","35   [[211, 68], [41, 37]]  axial_72_2  \n","36   [[205, 74], [41, 37]]  axial_73_2  \n","37   [[226, 53], [53, 25]]  axial_74_2  \n","38   [[255, 24], [65, 13]]  axial_75_2  \n","39     [[279, 0], [78, 0]]  axial_76_2  \n","40   [[229, 50], [52, 26]]  axial_77_2  \n","41   [[240, 39], [58, 20]]  axial_78_2  \n","42   [[196, 83], [46, 32]]  axial_79_2  \n","43  [[175, 104], [34, 44]]  axial_80_2  \n","44   [[257, 22], [21, 57]]  axial_20_3  \n","45   [[268, 11], [31, 47]]  axial_21_3  \n","46   [[258, 21], [16, 62]]  axial_22_3  \n","47   [[254, 25], [24, 54]]  axial_23_3  \n","48   [[231, 48], [12, 66]]  axial_24_3  \n","49   [[256, 23], [25, 53]]  axial_25_3  \n","50   [[262, 17], [25, 53]]  axial_26_3  \n","51   [[259, 20], [31, 47]]  axial_27_3  \n","52   [[256, 23], [31, 47]]  axial_28_3  \n","53   [[229, 50], [14, 64]]  axial_29_3  \n","54   [[248, 31], [21, 57]]  axial_30_3  \n","55   [[260, 19], [68, 10]]  axial_70_3  \n","56   [[210, 69], [46, 32]]  axial_71_3  \n","57   [[213, 66], [45, 33]]  axial_72_3  \n","58   [[216, 63], [49, 29]]  axial_73_3  \n","59   [[232, 47], [55, 23]]  axial_74_3  \n","60   [[252, 27], [64, 14]]  axial_75_3  \n","61   [[247, 32], [60, 18]]  axial_76_3  \n","62   [[247, 32], [57, 21]]  axial_77_3  \n","63   [[196, 83], [44, 34]]  axial_78_3  \n","64     [[279, 0], [78, 0]]  axial_79_3  \n","65   [[194, 85], [41, 37]]  axial_80_3  "]},"metadata":{},"execution_count":129}]},{"cell_type":"markdown","metadata":{"id":"rtjqRuDhMm_w"},"source":["## Sagittal 20-30 + 70-80"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1tLHiaAt0IoBfriw0BaQQGnTMp0T84lbs"},"id":"SxRr2OBOMoCC","executionInfo":{"status":"ok","timestamp":1634134028288,"user_tz":180,"elapsed":3347414,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"f1f29449-c355-4e43-b6f0-b4d7b0b4ebd6"},"source":["df_results_sagittal = run_mris_experiments(orientation = 'sagittal',\n","                          slices = list(range(20,31)) + list(range(70,81)),\n","                          num_repeats = 3,\n","                          model='shallow_cnn',\n","                          classes=['AD','CN'],\n","                          save_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/data/RESULTS_SAGITTAL_SHALLOW_CNN.csv')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"MhE3bK44Mnpv","executionInfo":{"status":"ok","timestamp":1634134028320,"user_tz":180,"elapsed":82,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"3d968c7d-cf1b-417e-fde1-66b90b444371"},"source":["df_results_sagittal"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>train_auc</th>\n","      <th>train_accuracy</th>\n","      <th>train_f1score</th>\n","      <th>train_precision</th>\n","      <th>train_recall</th>\n","      <th>train_conf_mat</th>\n","      <th>validation_auc</th>\n","      <th>validation_accuracy</th>\n","      <th>validation_f1score</th>\n","      <th>validation_precision</th>\n","      <th>validation_recall</th>\n","      <th>validation_conf_mat</th>\n","      <th>RUN_ID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.966711</td>\n","      <td>0.976649</td>\n","      <td>0.957895</td>\n","      <td>0.972222</td>\n","      <td>0.943983</td>\n","      <td>[[1218, 13], [27, 455]]</td>\n","      <td>0.776330</td>\n","      <td>0.773109</td>\n","      <td>0.600985</td>\n","      <td>0.488000</td>\n","      <td>0.782051</td>\n","      <td>[[215, 64], [17, 61]]</td>\n","      <td>sagittal_20_1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.977041</td>\n","      <td>0.984238</td>\n","      <td>0.971668</td>\n","      <td>0.983015</td>\n","      <td>0.960581</td>\n","      <td>[[1223, 8], [19, 463]]</td>\n","      <td>0.824993</td>\n","      <td>0.834734</td>\n","      <td>0.681081</td>\n","      <td>0.588785</td>\n","      <td>0.807692</td>\n","      <td>[[235, 44], [15, 63]]</td>\n","      <td>sagittal_21_1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.983671</td>\n","      <td>0.988325</td>\n","      <td>0.979123</td>\n","      <td>0.985294</td>\n","      <td>0.973029</td>\n","      <td>[[1224, 7], [13, 469]]</td>\n","      <td>0.774194</td>\n","      <td>0.834734</td>\n","      <td>0.638037</td>\n","      <td>0.611765</td>\n","      <td>0.666667</td>\n","      <td>[[246, 33], [26, 52]]</td>\n","      <td>sagittal_22_1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.985340</td>\n","      <td>0.988908</td>\n","      <td>0.980229</td>\n","      <td>0.983299</td>\n","      <td>0.977178</td>\n","      <td>[[1223, 8], [11, 471]]</td>\n","      <td>0.778605</td>\n","      <td>0.798319</td>\n","      <td>0.617021</td>\n","      <td>0.527273</td>\n","      <td>0.743590</td>\n","      <td>[[227, 52], [20, 58]]</td>\n","      <td>sagittal_23_1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.938878</td>\n","      <td>0.953882</td>\n","      <td>0.916930</td>\n","      <td>0.929638</td>\n","      <td>0.904564</td>\n","      <td>[[1198, 33], [46, 436]]</td>\n","      <td>0.782672</td>\n","      <td>0.826331</td>\n","      <td>0.639535</td>\n","      <td>0.585106</td>\n","      <td>0.705128</td>\n","      <td>[[240, 39], [23, 55]]</td>\n","      <td>sagittal_24_1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.945783</td>\n","      <td>0.963806</td>\n","      <td>0.933619</td>\n","      <td>0.964602</td>\n","      <td>0.904564</td>\n","      <td>[[1215, 16], [46, 436]]</td>\n","      <td>0.780397</td>\n","      <td>0.801120</td>\n","      <td>0.620321</td>\n","      <td>0.532110</td>\n","      <td>0.743590</td>\n","      <td>[[228, 51], [20, 58]]</td>\n","      <td>sagittal_25_1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.917950</td>\n","      <td>0.941039</td>\n","      <td>0.891979</td>\n","      <td>0.920530</td>\n","      <td>0.865145</td>\n","      <td>[[1195, 36], [65, 417]]</td>\n","      <td>0.832989</td>\n","      <td>0.803922</td>\n","      <td>0.663462</td>\n","      <td>0.530769</td>\n","      <td>0.884615</td>\n","      <td>[[218, 61], [9, 69]]</td>\n","      <td>sagittal_26_1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.876901</td>\n","      <td>0.908348</td>\n","      <td>0.831726</td>\n","      <td>0.860310</td>\n","      <td>0.804979</td>\n","      <td>[[1168, 63], [94, 388]]</td>\n","      <td>0.821409</td>\n","      <td>0.829132</td>\n","      <td>0.673797</td>\n","      <td>0.577982</td>\n","      <td>0.807692</td>\n","      <td>[[233, 46], [15, 63]]</td>\n","      <td>sagittal_27_1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.931523</td>\n","      <td>0.945126</td>\n","      <td>0.902287</td>\n","      <td>0.904167</td>\n","      <td>0.900415</td>\n","      <td>[[1185, 46], [48, 434]]</td>\n","      <td>0.803419</td>\n","      <td>0.851541</td>\n","      <td>0.678788</td>\n","      <td>0.643678</td>\n","      <td>0.717949</td>\n","      <td>[[248, 31], [22, 56]]</td>\n","      <td>sagittal_28_1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.983490</td>\n","      <td>0.987157</td>\n","      <td>0.977131</td>\n","      <td>0.979167</td>\n","      <td>0.975104</td>\n","      <td>[[1221, 10], [12, 470]]</td>\n","      <td>0.827819</td>\n","      <td>0.831933</td>\n","      <td>0.680851</td>\n","      <td>0.581818</td>\n","      <td>0.820513</td>\n","      <td>[[233, 46], [14, 64]]</td>\n","      <td>sagittal_29_1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.941722</td>\n","      <td>0.957968</td>\n","      <td>0.923729</td>\n","      <td>0.943723</td>\n","      <td>0.904564</td>\n","      <td>[[1205, 26], [46, 436]]</td>\n","      <td>0.808037</td>\n","      <td>0.851541</td>\n","      <td>0.682635</td>\n","      <td>0.640449</td>\n","      <td>0.730769</td>\n","      <td>[[247, 32], [21, 57]]</td>\n","      <td>sagittal_30_1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.961975</td>\n","      <td>0.972563</td>\n","      <td>0.950578</td>\n","      <td>0.963753</td>\n","      <td>0.937759</td>\n","      <td>[[1214, 17], [30, 452]]</td>\n","      <td>0.786738</td>\n","      <td>0.854342</td>\n","      <td>0.666667</td>\n","      <td>0.666667</td>\n","      <td>0.666667</td>\n","      <td>[[253, 26], [26, 52]]</td>\n","      <td>sagittal_70_1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.973523</td>\n","      <td>0.981903</td>\n","      <td>0.967403</td>\n","      <td>0.980810</td>\n","      <td>0.954357</td>\n","      <td>[[1222, 9], [22, 460]]</td>\n","      <td>0.749655</td>\n","      <td>0.767507</td>\n","      <td>0.574359</td>\n","      <td>0.478632</td>\n","      <td>0.717949</td>\n","      <td>[[218, 61], [22, 56]]</td>\n","      <td>sagittal_71_1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.978710</td>\n","      <td>0.984822</td>\n","      <td>0.972803</td>\n","      <td>0.981013</td>\n","      <td>0.964730</td>\n","      <td>[[1222, 9], [17, 465]]</td>\n","      <td>0.815205</td>\n","      <td>0.862745</td>\n","      <td>0.699387</td>\n","      <td>0.670588</td>\n","      <td>0.730769</td>\n","      <td>[[251, 28], [21, 57]]</td>\n","      <td>sagittal_72_1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.910733</td>\n","      <td>0.935201</td>\n","      <td>0.881283</td>\n","      <td>0.909492</td>\n","      <td>0.854772</td>\n","      <td>[[1190, 41], [70, 412]]</td>\n","      <td>0.830094</td>\n","      <td>0.857143</td>\n","      <td>0.705202</td>\n","      <td>0.642105</td>\n","      <td>0.782051</td>\n","      <td>[[245, 34], [17, 61]]</td>\n","      <td>sagittal_73_1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.847943</td>\n","      <td>0.888500</td>\n","      <td>0.792165</td>\n","      <td>0.832952</td>\n","      <td>0.755187</td>\n","      <td>[[1158, 73], [118, 364]]</td>\n","      <td>0.855735</td>\n","      <td>0.868347</td>\n","      <td>0.734463</td>\n","      <td>0.656566</td>\n","      <td>0.833333</td>\n","      <td>[[245, 34], [13, 65]]</td>\n","      <td>sagittal_74_1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.892642</td>\n","      <td>0.918272</td>\n","      <td>0.851695</td>\n","      <td>0.870130</td>\n","      <td>0.834025</td>\n","      <td>[[1171, 60], [80, 402]]</td>\n","      <td>0.811414</td>\n","      <td>0.820728</td>\n","      <td>0.659574</td>\n","      <td>0.563636</td>\n","      <td>0.794872</td>\n","      <td>[[231, 48], [16, 62]]</td>\n","      <td>sagittal_75_1</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.923906</td>\n","      <td>0.946877</td>\n","      <td>0.902256</td>\n","      <td>0.935412</td>\n","      <td>0.871369</td>\n","      <td>[[1202, 29], [62, 420]]</td>\n","      <td>0.760891</td>\n","      <td>0.806723</td>\n","      <td>0.605714</td>\n","      <td>0.546392</td>\n","      <td>0.679487</td>\n","      <td>[[235, 44], [25, 53]]</td>\n","      <td>sagittal_76_1</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.950608</td>\n","      <td>0.964390</td>\n","      <td>0.935586</td>\n","      <td>0.952688</td>\n","      <td>0.919087</td>\n","      <td>[[1209, 22], [39, 443]]</td>\n","      <td>0.810174</td>\n","      <td>0.789916</td>\n","      <td>0.637681</td>\n","      <td>0.511628</td>\n","      <td>0.846154</td>\n","      <td>[[216, 63], [12, 66]]</td>\n","      <td>sagittal_77_1</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.964456</td>\n","      <td>0.974314</td>\n","      <td>0.953782</td>\n","      <td>0.965957</td>\n","      <td>0.941909</td>\n","      <td>[[1215, 16], [28, 454]]</td>\n","      <td>0.772677</td>\n","      <td>0.817927</td>\n","      <td>0.624277</td>\n","      <td>0.568421</td>\n","      <td>0.692308</td>\n","      <td>[[238, 41], [24, 54]]</td>\n","      <td>sagittal_78_1</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>0.981190</td>\n","      <td>0.986573</td>\n","      <td>0.975967</td>\n","      <td>0.983158</td>\n","      <td>0.968880</td>\n","      <td>[[1223, 8], [15, 467]]</td>\n","      <td>0.800868</td>\n","      <td>0.840336</td>\n","      <td>0.666667</td>\n","      <td>0.612903</td>\n","      <td>0.730769</td>\n","      <td>[[243, 36], [21, 57]]</td>\n","      <td>sagittal_79_1</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0.989264</td>\n","      <td>0.991827</td>\n","      <td>0.985447</td>\n","      <td>0.987500</td>\n","      <td>0.983402</td>\n","      <td>[[1225, 6], [8, 474]]</td>\n","      <td>0.824924</td>\n","      <td>0.885154</td>\n","      <td>0.732026</td>\n","      <td>0.746667</td>\n","      <td>0.717949</td>\n","      <td>[[260, 19], [22, 56]]</td>\n","      <td>sagittal_80_1</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0.953451</td>\n","      <td>0.968476</td>\n","      <td>0.942553</td>\n","      <td>0.967249</td>\n","      <td>0.919087</td>\n","      <td>[[1216, 15], [39, 443]]</td>\n","      <td>0.780880</td>\n","      <td>0.823529</td>\n","      <td>0.635838</td>\n","      <td>0.578947</td>\n","      <td>0.705128</td>\n","      <td>[[239, 40], [23, 55]]</td>\n","      <td>sagittal_20_2</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0.976004</td>\n","      <td>0.983654</td>\n","      <td>0.970588</td>\n","      <td>0.982979</td>\n","      <td>0.958506</td>\n","      <td>[[1223, 8], [20, 462]]</td>\n","      <td>0.811690</td>\n","      <td>0.806723</td>\n","      <td>0.649746</td>\n","      <td>0.537815</td>\n","      <td>0.820513</td>\n","      <td>[[224, 55], [14, 64]]</td>\n","      <td>sagittal_21_2</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0.965224</td>\n","      <td>0.977233</td>\n","      <td>0.958643</td>\n","      <td>0.980477</td>\n","      <td>0.937759</td>\n","      <td>[[1222, 9], [30, 452]]</td>\n","      <td>0.811414</td>\n","      <td>0.820728</td>\n","      <td>0.659574</td>\n","      <td>0.563636</td>\n","      <td>0.794872</td>\n","      <td>[[231, 48], [16, 62]]</td>\n","      <td>sagittal_22_2</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0.967930</td>\n","      <td>0.978400</td>\n","      <td>0.960929</td>\n","      <td>0.978495</td>\n","      <td>0.943983</td>\n","      <td>[[1221, 10], [27, 455]]</td>\n","      <td>0.801420</td>\n","      <td>0.812325</td>\n","      <td>0.645503</td>\n","      <td>0.549550</td>\n","      <td>0.782051</td>\n","      <td>[[229, 50], [17, 61]]</td>\n","      <td>sagittal_23_2</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0.959856</td>\n","      <td>0.973147</td>\n","      <td>0.951168</td>\n","      <td>0.973913</td>\n","      <td>0.929461</td>\n","      <td>[[1219, 12], [34, 448]]</td>\n","      <td>0.795010</td>\n","      <td>0.809524</td>\n","      <td>0.638298</td>\n","      <td>0.545455</td>\n","      <td>0.769231</td>\n","      <td>[[229, 50], [18, 60]]</td>\n","      <td>sagittal_24_2</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>0.948308</td>\n","      <td>0.963806</td>\n","      <td>0.934183</td>\n","      <td>0.956522</td>\n","      <td>0.912863</td>\n","      <td>[[1211, 20], [42, 440]]</td>\n","      <td>0.850358</td>\n","      <td>0.859944</td>\n","      <td>0.722222</td>\n","      <td>0.637255</td>\n","      <td>0.833333</td>\n","      <td>[[242, 37], [13, 65]]</td>\n","      <td>sagittal_25_2</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0.949977</td>\n","      <td>0.964390</td>\n","      <td>0.935450</td>\n","      <td>0.954644</td>\n","      <td>0.917012</td>\n","      <td>[[1210, 21], [40, 442]]</td>\n","      <td>0.821202</td>\n","      <td>0.792717</td>\n","      <td>0.647619</td>\n","      <td>0.515152</td>\n","      <td>0.871795</td>\n","      <td>[[215, 64], [10, 68]]</td>\n","      <td>sagittal_26_2</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>0.969598</td>\n","      <td>0.978984</td>\n","      <td>0.962105</td>\n","      <td>0.976496</td>\n","      <td>0.948133</td>\n","      <td>[[1220, 11], [25, 457]]</td>\n","      <td>0.814309</td>\n","      <td>0.767507</td>\n","      <td>0.627803</td>\n","      <td>0.482759</td>\n","      <td>0.897436</td>\n","      <td>[[204, 75], [8, 70]]</td>\n","      <td>sagittal_27_2</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>0.979116</td>\n","      <td>0.985406</td>\n","      <td>0.973822</td>\n","      <td>0.983087</td>\n","      <td>0.964730</td>\n","      <td>[[1223, 8], [17, 465]]</td>\n","      <td>0.859388</td>\n","      <td>0.823529</td>\n","      <td>0.695652</td>\n","      <td>0.558140</td>\n","      <td>0.923077</td>\n","      <td>[[222, 57], [6, 72]]</td>\n","      <td>sagittal_28_2</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>0.949164</td>\n","      <td>0.963222</td>\n","      <td>0.933474</td>\n","      <td>0.950538</td>\n","      <td>0.917012</td>\n","      <td>[[1208, 23], [40, 442]]</td>\n","      <td>0.813689</td>\n","      <td>0.845938</td>\n","      <td>0.682081</td>\n","      <td>0.621053</td>\n","      <td>0.756410</td>\n","      <td>[[243, 36], [19, 59]]</td>\n","      <td>sagittal_29_2</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>0.971673</td>\n","      <td>0.980152</td>\n","      <td>0.964286</td>\n","      <td>0.976596</td>\n","      <td>0.952282</td>\n","      <td>[[1220, 11], [23, 459]]</td>\n","      <td>0.868280</td>\n","      <td>0.887955</td>\n","      <td>0.764706</td>\n","      <td>0.706522</td>\n","      <td>0.833333</td>\n","      <td>[[252, 27], [13, 65]]</td>\n","      <td>sagittal_30_2</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>0.942759</td>\n","      <td>0.958552</td>\n","      <td>0.924868</td>\n","      <td>0.943844</td>\n","      <td>0.906639</td>\n","      <td>[[1205, 26], [45, 437]]</td>\n","      <td>0.770609</td>\n","      <td>0.829132</td>\n","      <td>0.630303</td>\n","      <td>0.597701</td>\n","      <td>0.666667</td>\n","      <td>[[244, 35], [26, 52]]</td>\n","      <td>sagittal_70_2</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>0.953720</td>\n","      <td>0.966141</td>\n","      <td>0.938947</td>\n","      <td>0.952991</td>\n","      <td>0.925311</td>\n","      <td>[[1209, 22], [36, 446]]</td>\n","      <td>0.784188</td>\n","      <td>0.843137</td>\n","      <td>0.654321</td>\n","      <td>0.630952</td>\n","      <td>0.679487</td>\n","      <td>[[248, 31], [25, 53]]</td>\n","      <td>sagittal_71_2</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>0.992557</td>\n","      <td>0.994746</td>\n","      <td>0.990635</td>\n","      <td>0.993737</td>\n","      <td>0.987552</td>\n","      <td>[[1228, 3], [6, 476]]</td>\n","      <td>0.859526</td>\n","      <td>0.910364</td>\n","      <td>0.789474</td>\n","      <td>0.810811</td>\n","      <td>0.769231</td>\n","      <td>[[265, 14], [18, 60]]</td>\n","      <td>sagittal_72_2</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>0.959088</td>\n","      <td>0.970228</td>\n","      <td>0.946372</td>\n","      <td>0.959488</td>\n","      <td>0.933610</td>\n","      <td>[[1212, 19], [32, 450]]</td>\n","      <td>0.853391</td>\n","      <td>0.893557</td>\n","      <td>0.762500</td>\n","      <td>0.743902</td>\n","      <td>0.782051</td>\n","      <td>[[258, 21], [17, 61]]</td>\n","      <td>sagittal_73_2</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>0.979116</td>\n","      <td>0.985406</td>\n","      <td>0.973822</td>\n","      <td>0.983087</td>\n","      <td>0.964730</td>\n","      <td>[[1223, 8], [17, 465]]</td>\n","      <td>0.841398</td>\n","      <td>0.845938</td>\n","      <td>0.702703</td>\n","      <td>0.607477</td>\n","      <td>0.833333</td>\n","      <td>[[237, 42], [13, 65]]</td>\n","      <td>sagittal_74_2</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>0.987008</td>\n","      <td>0.989492</td>\n","      <td>0.981328</td>\n","      <td>0.981328</td>\n","      <td>0.981328</td>\n","      <td>[[1222, 9], [9, 473]]</td>\n","      <td>0.828302</td>\n","      <td>0.854342</td>\n","      <td>0.701149</td>\n","      <td>0.635417</td>\n","      <td>0.782051</td>\n","      <td>[[244, 35], [17, 61]]</td>\n","      <td>sagittal_75_2</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>0.983896</td>\n","      <td>0.987741</td>\n","      <td>0.978148</td>\n","      <td>0.981211</td>\n","      <td>0.975104</td>\n","      <td>[[1222, 9], [12, 470]]</td>\n","      <td>0.832437</td>\n","      <td>0.831933</td>\n","      <td>0.684211</td>\n","      <td>0.580357</td>\n","      <td>0.833333</td>\n","      <td>[[232, 47], [13, 65]]</td>\n","      <td>sagittal_76_2</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>0.980965</td>\n","      <td>0.987157</td>\n","      <td>0.976939</td>\n","      <td>0.987288</td>\n","      <td>0.966805</td>\n","      <td>[[1225, 6], [16, 466]]</td>\n","      <td>0.840571</td>\n","      <td>0.887955</td>\n","      <td>0.746835</td>\n","      <td>0.737500</td>\n","      <td>0.756410</td>\n","      <td>[[258, 21], [19, 59]]</td>\n","      <td>sagittal_77_2</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>0.895666</td>\n","      <td>0.923526</td>\n","      <td>0.859593</td>\n","      <td>0.889135</td>\n","      <td>0.831950</td>\n","      <td>[[1181, 50], [81, 401]]</td>\n","      <td>0.799835</td>\n","      <td>0.845938</td>\n","      <td>0.670659</td>\n","      <td>0.629213</td>\n","      <td>0.717949</td>\n","      <td>[[246, 33], [22, 56]]</td>\n","      <td>sagittal_78_2</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>0.953945</td>\n","      <td>0.965558</td>\n","      <td>0.938090</td>\n","      <td>0.949045</td>\n","      <td>0.927386</td>\n","      <td>[[1207, 24], [35, 447]]</td>\n","      <td>0.773642</td>\n","      <td>0.862745</td>\n","      <td>0.662069</td>\n","      <td>0.716418</td>\n","      <td>0.615385</td>\n","      <td>[[260, 19], [30, 48]]</td>\n","      <td>sagittal_79_2</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>0.955569</td>\n","      <td>0.967893</td>\n","      <td>0.942044</td>\n","      <td>0.957173</td>\n","      <td>0.927386</td>\n","      <td>[[1211, 20], [35, 447]]</td>\n","      <td>0.775503</td>\n","      <td>0.815126</td>\n","      <td>0.625000</td>\n","      <td>0.561224</td>\n","      <td>0.705128</td>\n","      <td>[[236, 43], [23, 55]]</td>\n","      <td>sagittal_80_2</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>0.966711</td>\n","      <td>0.976649</td>\n","      <td>0.957895</td>\n","      <td>0.972222</td>\n","      <td>0.943983</td>\n","      <td>[[1218, 13], [27, 455]]</td>\n","      <td>0.802454</td>\n","      <td>0.806723</td>\n","      <td>0.642487</td>\n","      <td>0.539130</td>\n","      <td>0.794872</td>\n","      <td>[[226, 53], [16, 62]]</td>\n","      <td>sagittal_20_3</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>0.963599</td>\n","      <td>0.974898</td>\n","      <td>0.954593</td>\n","      <td>0.972043</td>\n","      <td>0.937759</td>\n","      <td>[[1218, 13], [30, 452]]</td>\n","      <td>0.747519</td>\n","      <td>0.829132</td>\n","      <td>0.606452</td>\n","      <td>0.610390</td>\n","      <td>0.602564</td>\n","      <td>[[249, 30], [31, 47]]</td>\n","      <td>sagittal_21_3</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>0.986152</td>\n","      <td>0.990076</td>\n","      <td>0.982273</td>\n","      <td>0.987421</td>\n","      <td>0.977178</td>\n","      <td>[[1225, 6], [11, 471]]</td>\n","      <td>0.798042</td>\n","      <td>0.843137</td>\n","      <td>0.666667</td>\n","      <td>0.622222</td>\n","      <td>0.717949</td>\n","      <td>[[245, 34], [22, 56]]</td>\n","      <td>sagittal_22_3</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>0.844156</td>\n","      <td>0.888500</td>\n","      <td>0.789416</td>\n","      <td>0.842353</td>\n","      <td>0.742739</td>\n","      <td>[[1164, 67], [124, 358]]</td>\n","      <td>0.802936</td>\n","      <td>0.829132</td>\n","      <td>0.659218</td>\n","      <td>0.584158</td>\n","      <td>0.756410</td>\n","      <td>[[237, 42], [19, 59]]</td>\n","      <td>sagittal_23_3</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>0.976410</td>\n","      <td>0.984238</td>\n","      <td>0.971609</td>\n","      <td>0.985075</td>\n","      <td>0.958506</td>\n","      <td>[[1224, 7], [20, 462]]</td>\n","      <td>0.798594</td>\n","      <td>0.815126</td>\n","      <td>0.645161</td>\n","      <td>0.555556</td>\n","      <td>0.769231</td>\n","      <td>[[231, 48], [18, 60]]</td>\n","      <td>sagittal_24_3</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>0.982815</td>\n","      <td>0.988908</td>\n","      <td>0.980063</td>\n","      <td>0.991507</td>\n","      <td>0.968880</td>\n","      <td>[[1227, 4], [15, 467]]</td>\n","      <td>0.804728</td>\n","      <td>0.831933</td>\n","      <td>0.662921</td>\n","      <td>0.590000</td>\n","      <td>0.756410</td>\n","      <td>[[238, 41], [19, 59]]</td>\n","      <td>sagittal_25_3</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>0.974560</td>\n","      <td>0.982487</td>\n","      <td>0.968487</td>\n","      <td>0.980851</td>\n","      <td>0.956432</td>\n","      <td>[[1222, 9], [21, 461]]</td>\n","      <td>0.814999</td>\n","      <td>0.826331</td>\n","      <td>0.666667</td>\n","      <td>0.574074</td>\n","      <td>0.794872</td>\n","      <td>[[233, 46], [16, 62]]</td>\n","      <td>sagittal_26_3</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>0.906446</td>\n","      <td>0.929947</td>\n","      <td>0.872611</td>\n","      <td>0.893478</td>\n","      <td>0.852697</td>\n","      <td>[[1182, 49], [71, 411]]</td>\n","      <td>0.844982</td>\n","      <td>0.851541</td>\n","      <td>0.710383</td>\n","      <td>0.619048</td>\n","      <td>0.833333</td>\n","      <td>[[239, 40], [13, 65]]</td>\n","      <td>sagittal_27_3</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>0.907846</td>\n","      <td>0.932866</td>\n","      <td>0.877005</td>\n","      <td>0.905077</td>\n","      <td>0.850622</td>\n","      <td>[[1188, 43], [72, 410]]</td>\n","      <td>0.831128</td>\n","      <td>0.851541</td>\n","      <td>0.700565</td>\n","      <td>0.626263</td>\n","      <td>0.794872</td>\n","      <td>[[242, 37], [16, 62]]</td>\n","      <td>sagittal_28_3</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>0.853267</td>\n","      <td>0.894337</td>\n","      <td>0.801752</td>\n","      <td>0.849188</td>\n","      <td>0.759336</td>\n","      <td>[[1166, 65], [116, 366]]</td>\n","      <td>0.807003</td>\n","      <td>0.857143</td>\n","      <td>0.687117</td>\n","      <td>0.658824</td>\n","      <td>0.717949</td>\n","      <td>[[250, 29], [22, 56]]</td>\n","      <td>sagittal_29_3</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>0.923543</td>\n","      <td>0.944542</td>\n","      <td>0.898829</td>\n","      <td>0.923414</td>\n","      <td>0.875519</td>\n","      <td>[[1196, 35], [60, 422]]</td>\n","      <td>0.812104</td>\n","      <td>0.879552</td>\n","      <td>0.715232</td>\n","      <td>0.739726</td>\n","      <td>0.692308</td>\n","      <td>[[260, 19], [24, 54]]</td>\n","      <td>sagittal_30_3</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>0.985971</td>\n","      <td>0.988908</td>\n","      <td>0.980270</td>\n","      <td>0.981289</td>\n","      <td>0.979253</td>\n","      <td>[[1222, 9], [10, 472]]</td>\n","      <td>0.781569</td>\n","      <td>0.882353</td>\n","      <td>0.691176</td>\n","      <td>0.810345</td>\n","      <td>0.602564</td>\n","      <td>[[268, 11], [31, 47]]</td>\n","      <td>sagittal_70_3</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>0.986783</td>\n","      <td>0.990076</td>\n","      <td>0.982310</td>\n","      <td>0.985386</td>\n","      <td>0.979253</td>\n","      <td>[[1224, 7], [10, 472]]</td>\n","      <td>0.784671</td>\n","      <td>0.865546</td>\n","      <td>0.675676</td>\n","      <td>0.714286</td>\n","      <td>0.641026</td>\n","      <td>[[259, 20], [28, 50]]</td>\n","      <td>sagittal_71_3</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>0.941722</td>\n","      <td>0.957968</td>\n","      <td>0.923729</td>\n","      <td>0.943723</td>\n","      <td>0.904564</td>\n","      <td>[[1205, 26], [46, 436]]</td>\n","      <td>0.809553</td>\n","      <td>0.868347</td>\n","      <td>0.700637</td>\n","      <td>0.696203</td>\n","      <td>0.705128</td>\n","      <td>[[255, 24], [23, 55]]</td>\n","      <td>sagittal_72_3</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>0.965899</td>\n","      <td>0.975482</td>\n","      <td>0.955882</td>\n","      <td>0.968085</td>\n","      <td>0.943983</td>\n","      <td>[[1216, 15], [27, 455]]</td>\n","      <td>0.811690</td>\n","      <td>0.806723</td>\n","      <td>0.649746</td>\n","      <td>0.537815</td>\n","      <td>0.820513</td>\n","      <td>[[224, 55], [14, 64]]</td>\n","      <td>sagittal_73_3</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>0.935360</td>\n","      <td>0.951547</td>\n","      <td>0.912540</td>\n","      <td>0.927195</td>\n","      <td>0.898340</td>\n","      <td>[[1197, 34], [49, 433]]</td>\n","      <td>0.834436</td>\n","      <td>0.871148</td>\n","      <td>0.722892</td>\n","      <td>0.681818</td>\n","      <td>0.769231</td>\n","      <td>[[251, 28], [18, 60]]</td>\n","      <td>sagittal_74_3</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>0.979116</td>\n","      <td>0.985406</td>\n","      <td>0.973822</td>\n","      <td>0.983087</td>\n","      <td>0.964730</td>\n","      <td>[[1223, 8], [17, 465]]</td>\n","      <td>0.856493</td>\n","      <td>0.876751</td>\n","      <td>0.744186</td>\n","      <td>0.680851</td>\n","      <td>0.820513</td>\n","      <td>[[249, 30], [14, 64]]</td>\n","      <td>sagittal_75_3</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>0.983265</td>\n","      <td>0.987741</td>\n","      <td>0.978102</td>\n","      <td>0.983229</td>\n","      <td>0.973029</td>\n","      <td>[[1223, 8], [13, 469]]</td>\n","      <td>0.833747</td>\n","      <td>0.812325</td>\n","      <td>0.669951</td>\n","      <td>0.544000</td>\n","      <td>0.871795</td>\n","      <td>[[222, 57], [10, 68]]</td>\n","      <td>sagittal_76_3</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>0.955344</td>\n","      <td>0.968476</td>\n","      <td>0.942918</td>\n","      <td>0.961207</td>\n","      <td>0.925311</td>\n","      <td>[[1213, 18], [36, 446]]</td>\n","      <td>0.814171</td>\n","      <td>0.868347</td>\n","      <td>0.704403</td>\n","      <td>0.691358</td>\n","      <td>0.717949</td>\n","      <td>[[254, 25], [22, 56]]</td>\n","      <td>sagittal_77_3</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>0.908252</td>\n","      <td>0.933450</td>\n","      <td>0.877944</td>\n","      <td>0.907080</td>\n","      <td>0.850622</td>\n","      <td>[[1189, 42], [72, 410]]</td>\n","      <td>0.744486</td>\n","      <td>0.795518</td>\n","      <td>0.582857</td>\n","      <td>0.525773</td>\n","      <td>0.653846</td>\n","      <td>[[233, 46], [27, 51]]</td>\n","      <td>sagittal_78_3</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>0.970498</td>\n","      <td>0.976649</td>\n","      <td>0.958420</td>\n","      <td>0.960417</td>\n","      <td>0.956432</td>\n","      <td>[[1212, 19], [21, 461]]</td>\n","      <td>0.752344</td>\n","      <td>0.865546</td>\n","      <td>0.641791</td>\n","      <td>0.767857</td>\n","      <td>0.551282</td>\n","      <td>[[266, 13], [35, 43]]</td>\n","      <td>sagittal_79_3</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>0.853042</td>\n","      <td>0.894921</td>\n","      <td>0.802198</td>\n","      <td>0.852804</td>\n","      <td>0.757261</td>\n","      <td>[[1168, 63], [117, 365]]</td>\n","      <td>0.763165</td>\n","      <td>0.831933</td>\n","      <td>0.625000</td>\n","      <td>0.609756</td>\n","      <td>0.641026</td>\n","      <td>[[247, 32], [28, 50]]</td>\n","      <td>sagittal_80_3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    train_auc  train_accuracy  train_f1score  train_precision  train_recall  \\\n","0    0.966711        0.976649       0.957895         0.972222      0.943983   \n","1    0.977041        0.984238       0.971668         0.983015      0.960581   \n","2    0.983671        0.988325       0.979123         0.985294      0.973029   \n","3    0.985340        0.988908       0.980229         0.983299      0.977178   \n","4    0.938878        0.953882       0.916930         0.929638      0.904564   \n","5    0.945783        0.963806       0.933619         0.964602      0.904564   \n","6    0.917950        0.941039       0.891979         0.920530      0.865145   \n","7    0.876901        0.908348       0.831726         0.860310      0.804979   \n","8    0.931523        0.945126       0.902287         0.904167      0.900415   \n","9    0.983490        0.987157       0.977131         0.979167      0.975104   \n","10   0.941722        0.957968       0.923729         0.943723      0.904564   \n","11   0.961975        0.972563       0.950578         0.963753      0.937759   \n","12   0.973523        0.981903       0.967403         0.980810      0.954357   \n","13   0.978710        0.984822       0.972803         0.981013      0.964730   \n","14   0.910733        0.935201       0.881283         0.909492      0.854772   \n","15   0.847943        0.888500       0.792165         0.832952      0.755187   \n","16   0.892642        0.918272       0.851695         0.870130      0.834025   \n","17   0.923906        0.946877       0.902256         0.935412      0.871369   \n","18   0.950608        0.964390       0.935586         0.952688      0.919087   \n","19   0.964456        0.974314       0.953782         0.965957      0.941909   \n","20   0.981190        0.986573       0.975967         0.983158      0.968880   \n","21   0.989264        0.991827       0.985447         0.987500      0.983402   \n","22   0.953451        0.968476       0.942553         0.967249      0.919087   \n","23   0.976004        0.983654       0.970588         0.982979      0.958506   \n","24   0.965224        0.977233       0.958643         0.980477      0.937759   \n","25   0.967930        0.978400       0.960929         0.978495      0.943983   \n","26   0.959856        0.973147       0.951168         0.973913      0.929461   \n","27   0.948308        0.963806       0.934183         0.956522      0.912863   \n","28   0.949977        0.964390       0.935450         0.954644      0.917012   \n","29   0.969598        0.978984       0.962105         0.976496      0.948133   \n","30   0.979116        0.985406       0.973822         0.983087      0.964730   \n","31   0.949164        0.963222       0.933474         0.950538      0.917012   \n","32   0.971673        0.980152       0.964286         0.976596      0.952282   \n","33   0.942759        0.958552       0.924868         0.943844      0.906639   \n","34   0.953720        0.966141       0.938947         0.952991      0.925311   \n","35   0.992557        0.994746       0.990635         0.993737      0.987552   \n","36   0.959088        0.970228       0.946372         0.959488      0.933610   \n","37   0.979116        0.985406       0.973822         0.983087      0.964730   \n","38   0.987008        0.989492       0.981328         0.981328      0.981328   \n","39   0.983896        0.987741       0.978148         0.981211      0.975104   \n","40   0.980965        0.987157       0.976939         0.987288      0.966805   \n","41   0.895666        0.923526       0.859593         0.889135      0.831950   \n","42   0.953945        0.965558       0.938090         0.949045      0.927386   \n","43   0.955569        0.967893       0.942044         0.957173      0.927386   \n","44   0.966711        0.976649       0.957895         0.972222      0.943983   \n","45   0.963599        0.974898       0.954593         0.972043      0.937759   \n","46   0.986152        0.990076       0.982273         0.987421      0.977178   \n","47   0.844156        0.888500       0.789416         0.842353      0.742739   \n","48   0.976410        0.984238       0.971609         0.985075      0.958506   \n","49   0.982815        0.988908       0.980063         0.991507      0.968880   \n","50   0.974560        0.982487       0.968487         0.980851      0.956432   \n","51   0.906446        0.929947       0.872611         0.893478      0.852697   \n","52   0.907846        0.932866       0.877005         0.905077      0.850622   \n","53   0.853267        0.894337       0.801752         0.849188      0.759336   \n","54   0.923543        0.944542       0.898829         0.923414      0.875519   \n","55   0.985971        0.988908       0.980270         0.981289      0.979253   \n","56   0.986783        0.990076       0.982310         0.985386      0.979253   \n","57   0.941722        0.957968       0.923729         0.943723      0.904564   \n","58   0.965899        0.975482       0.955882         0.968085      0.943983   \n","59   0.935360        0.951547       0.912540         0.927195      0.898340   \n","60   0.979116        0.985406       0.973822         0.983087      0.964730   \n","61   0.983265        0.987741       0.978102         0.983229      0.973029   \n","62   0.955344        0.968476       0.942918         0.961207      0.925311   \n","63   0.908252        0.933450       0.877944         0.907080      0.850622   \n","64   0.970498        0.976649       0.958420         0.960417      0.956432   \n","65   0.853042        0.894921       0.802198         0.852804      0.757261   \n","\n","              train_conf_mat  validation_auc  validation_accuracy  \\\n","0    [[1218, 13], [27, 455]]        0.776330             0.773109   \n","1     [[1223, 8], [19, 463]]        0.824993             0.834734   \n","2     [[1224, 7], [13, 469]]        0.774194             0.834734   \n","3     [[1223, 8], [11, 471]]        0.778605             0.798319   \n","4    [[1198, 33], [46, 436]]        0.782672             0.826331   \n","5    [[1215, 16], [46, 436]]        0.780397             0.801120   \n","6    [[1195, 36], [65, 417]]        0.832989             0.803922   \n","7    [[1168, 63], [94, 388]]        0.821409             0.829132   \n","8    [[1185, 46], [48, 434]]        0.803419             0.851541   \n","9    [[1221, 10], [12, 470]]        0.827819             0.831933   \n","10   [[1205, 26], [46, 436]]        0.808037             0.851541   \n","11   [[1214, 17], [30, 452]]        0.786738             0.854342   \n","12    [[1222, 9], [22, 460]]        0.749655             0.767507   \n","13    [[1222, 9], [17, 465]]        0.815205             0.862745   \n","14   [[1190, 41], [70, 412]]        0.830094             0.857143   \n","15  [[1158, 73], [118, 364]]        0.855735             0.868347   \n","16   [[1171, 60], [80, 402]]        0.811414             0.820728   \n","17   [[1202, 29], [62, 420]]        0.760891             0.806723   \n","18   [[1209, 22], [39, 443]]        0.810174             0.789916   \n","19   [[1215, 16], [28, 454]]        0.772677             0.817927   \n","20    [[1223, 8], [15, 467]]        0.800868             0.840336   \n","21     [[1225, 6], [8, 474]]        0.824924             0.885154   \n","22   [[1216, 15], [39, 443]]        0.780880             0.823529   \n","23    [[1223, 8], [20, 462]]        0.811690             0.806723   \n","24    [[1222, 9], [30, 452]]        0.811414             0.820728   \n","25   [[1221, 10], [27, 455]]        0.801420             0.812325   \n","26   [[1219, 12], [34, 448]]        0.795010             0.809524   \n","27   [[1211, 20], [42, 440]]        0.850358             0.859944   \n","28   [[1210, 21], [40, 442]]        0.821202             0.792717   \n","29   [[1220, 11], [25, 457]]        0.814309             0.767507   \n","30    [[1223, 8], [17, 465]]        0.859388             0.823529   \n","31   [[1208, 23], [40, 442]]        0.813689             0.845938   \n","32   [[1220, 11], [23, 459]]        0.868280             0.887955   \n","33   [[1205, 26], [45, 437]]        0.770609             0.829132   \n","34   [[1209, 22], [36, 446]]        0.784188             0.843137   \n","35     [[1228, 3], [6, 476]]        0.859526             0.910364   \n","36   [[1212, 19], [32, 450]]        0.853391             0.893557   \n","37    [[1223, 8], [17, 465]]        0.841398             0.845938   \n","38     [[1222, 9], [9, 473]]        0.828302             0.854342   \n","39    [[1222, 9], [12, 470]]        0.832437             0.831933   \n","40    [[1225, 6], [16, 466]]        0.840571             0.887955   \n","41   [[1181, 50], [81, 401]]        0.799835             0.845938   \n","42   [[1207, 24], [35, 447]]        0.773642             0.862745   \n","43   [[1211, 20], [35, 447]]        0.775503             0.815126   \n","44   [[1218, 13], [27, 455]]        0.802454             0.806723   \n","45   [[1218, 13], [30, 452]]        0.747519             0.829132   \n","46    [[1225, 6], [11, 471]]        0.798042             0.843137   \n","47  [[1164, 67], [124, 358]]        0.802936             0.829132   \n","48    [[1224, 7], [20, 462]]        0.798594             0.815126   \n","49    [[1227, 4], [15, 467]]        0.804728             0.831933   \n","50    [[1222, 9], [21, 461]]        0.814999             0.826331   \n","51   [[1182, 49], [71, 411]]        0.844982             0.851541   \n","52   [[1188, 43], [72, 410]]        0.831128             0.851541   \n","53  [[1166, 65], [116, 366]]        0.807003             0.857143   \n","54   [[1196, 35], [60, 422]]        0.812104             0.879552   \n","55    [[1222, 9], [10, 472]]        0.781569             0.882353   \n","56    [[1224, 7], [10, 472]]        0.784671             0.865546   \n","57   [[1205, 26], [46, 436]]        0.809553             0.868347   \n","58   [[1216, 15], [27, 455]]        0.811690             0.806723   \n","59   [[1197, 34], [49, 433]]        0.834436             0.871148   \n","60    [[1223, 8], [17, 465]]        0.856493             0.876751   \n","61    [[1223, 8], [13, 469]]        0.833747             0.812325   \n","62   [[1213, 18], [36, 446]]        0.814171             0.868347   \n","63   [[1189, 42], [72, 410]]        0.744486             0.795518   \n","64   [[1212, 19], [21, 461]]        0.752344             0.865546   \n","65  [[1168, 63], [117, 365]]        0.763165             0.831933   \n","\n","    validation_f1score  validation_precision  validation_recall  \\\n","0             0.600985              0.488000           0.782051   \n","1             0.681081              0.588785           0.807692   \n","2             0.638037              0.611765           0.666667   \n","3             0.617021              0.527273           0.743590   \n","4             0.639535              0.585106           0.705128   \n","5             0.620321              0.532110           0.743590   \n","6             0.663462              0.530769           0.884615   \n","7             0.673797              0.577982           0.807692   \n","8             0.678788              0.643678           0.717949   \n","9             0.680851              0.581818           0.820513   \n","10            0.682635              0.640449           0.730769   \n","11            0.666667              0.666667           0.666667   \n","12            0.574359              0.478632           0.717949   \n","13            0.699387              0.670588           0.730769   \n","14            0.705202              0.642105           0.782051   \n","15            0.734463              0.656566           0.833333   \n","16            0.659574              0.563636           0.794872   \n","17            0.605714              0.546392           0.679487   \n","18            0.637681              0.511628           0.846154   \n","19            0.624277              0.568421           0.692308   \n","20            0.666667              0.612903           0.730769   \n","21            0.732026              0.746667           0.717949   \n","22            0.635838              0.578947           0.705128   \n","23            0.649746              0.537815           0.820513   \n","24            0.659574              0.563636           0.794872   \n","25            0.645503              0.549550           0.782051   \n","26            0.638298              0.545455           0.769231   \n","27            0.722222              0.637255           0.833333   \n","28            0.647619              0.515152           0.871795   \n","29            0.627803              0.482759           0.897436   \n","30            0.695652              0.558140           0.923077   \n","31            0.682081              0.621053           0.756410   \n","32            0.764706              0.706522           0.833333   \n","33            0.630303              0.597701           0.666667   \n","34            0.654321              0.630952           0.679487   \n","35            0.789474              0.810811           0.769231   \n","36            0.762500              0.743902           0.782051   \n","37            0.702703              0.607477           0.833333   \n","38            0.701149              0.635417           0.782051   \n","39            0.684211              0.580357           0.833333   \n","40            0.746835              0.737500           0.756410   \n","41            0.670659              0.629213           0.717949   \n","42            0.662069              0.716418           0.615385   \n","43            0.625000              0.561224           0.705128   \n","44            0.642487              0.539130           0.794872   \n","45            0.606452              0.610390           0.602564   \n","46            0.666667              0.622222           0.717949   \n","47            0.659218              0.584158           0.756410   \n","48            0.645161              0.555556           0.769231   \n","49            0.662921              0.590000           0.756410   \n","50            0.666667              0.574074           0.794872   \n","51            0.710383              0.619048           0.833333   \n","52            0.700565              0.626263           0.794872   \n","53            0.687117              0.658824           0.717949   \n","54            0.715232              0.739726           0.692308   \n","55            0.691176              0.810345           0.602564   \n","56            0.675676              0.714286           0.641026   \n","57            0.700637              0.696203           0.705128   \n","58            0.649746              0.537815           0.820513   \n","59            0.722892              0.681818           0.769231   \n","60            0.744186              0.680851           0.820513   \n","61            0.669951              0.544000           0.871795   \n","62            0.704403              0.691358           0.717949   \n","63            0.582857              0.525773           0.653846   \n","64            0.641791              0.767857           0.551282   \n","65            0.625000              0.609756           0.641026   \n","\n","      validation_conf_mat         RUN_ID  \n","0   [[215, 64], [17, 61]]  sagittal_20_1  \n","1   [[235, 44], [15, 63]]  sagittal_21_1  \n","2   [[246, 33], [26, 52]]  sagittal_22_1  \n","3   [[227, 52], [20, 58]]  sagittal_23_1  \n","4   [[240, 39], [23, 55]]  sagittal_24_1  \n","5   [[228, 51], [20, 58]]  sagittal_25_1  \n","6    [[218, 61], [9, 69]]  sagittal_26_1  \n","7   [[233, 46], [15, 63]]  sagittal_27_1  \n","8   [[248, 31], [22, 56]]  sagittal_28_1  \n","9   [[233, 46], [14, 64]]  sagittal_29_1  \n","10  [[247, 32], [21, 57]]  sagittal_30_1  \n","11  [[253, 26], [26, 52]]  sagittal_70_1  \n","12  [[218, 61], [22, 56]]  sagittal_71_1  \n","13  [[251, 28], [21, 57]]  sagittal_72_1  \n","14  [[245, 34], [17, 61]]  sagittal_73_1  \n","15  [[245, 34], [13, 65]]  sagittal_74_1  \n","16  [[231, 48], [16, 62]]  sagittal_75_1  \n","17  [[235, 44], [25, 53]]  sagittal_76_1  \n","18  [[216, 63], [12, 66]]  sagittal_77_1  \n","19  [[238, 41], [24, 54]]  sagittal_78_1  \n","20  [[243, 36], [21, 57]]  sagittal_79_1  \n","21  [[260, 19], [22, 56]]  sagittal_80_1  \n","22  [[239, 40], [23, 55]]  sagittal_20_2  \n","23  [[224, 55], [14, 64]]  sagittal_21_2  \n","24  [[231, 48], [16, 62]]  sagittal_22_2  \n","25  [[229, 50], [17, 61]]  sagittal_23_2  \n","26  [[229, 50], [18, 60]]  sagittal_24_2  \n","27  [[242, 37], [13, 65]]  sagittal_25_2  \n","28  [[215, 64], [10, 68]]  sagittal_26_2  \n","29   [[204, 75], [8, 70]]  sagittal_27_2  \n","30   [[222, 57], [6, 72]]  sagittal_28_2  \n","31  [[243, 36], [19, 59]]  sagittal_29_2  \n","32  [[252, 27], [13, 65]]  sagittal_30_2  \n","33  [[244, 35], [26, 52]]  sagittal_70_2  \n","34  [[248, 31], [25, 53]]  sagittal_71_2  \n","35  [[265, 14], [18, 60]]  sagittal_72_2  \n","36  [[258, 21], [17, 61]]  sagittal_73_2  \n","37  [[237, 42], [13, 65]]  sagittal_74_2  \n","38  [[244, 35], [17, 61]]  sagittal_75_2  \n","39  [[232, 47], [13, 65]]  sagittal_76_2  \n","40  [[258, 21], [19, 59]]  sagittal_77_2  \n","41  [[246, 33], [22, 56]]  sagittal_78_2  \n","42  [[260, 19], [30, 48]]  sagittal_79_2  \n","43  [[236, 43], [23, 55]]  sagittal_80_2  \n","44  [[226, 53], [16, 62]]  sagittal_20_3  \n","45  [[249, 30], [31, 47]]  sagittal_21_3  \n","46  [[245, 34], [22, 56]]  sagittal_22_3  \n","47  [[237, 42], [19, 59]]  sagittal_23_3  \n","48  [[231, 48], [18, 60]]  sagittal_24_3  \n","49  [[238, 41], [19, 59]]  sagittal_25_3  \n","50  [[233, 46], [16, 62]]  sagittal_26_3  \n","51  [[239, 40], [13, 65]]  sagittal_27_3  \n","52  [[242, 37], [16, 62]]  sagittal_28_3  \n","53  [[250, 29], [22, 56]]  sagittal_29_3  \n","54  [[260, 19], [24, 54]]  sagittal_30_3  \n","55  [[268, 11], [31, 47]]  sagittal_70_3  \n","56  [[259, 20], [28, 50]]  sagittal_71_3  \n","57  [[255, 24], [23, 55]]  sagittal_72_3  \n","58  [[224, 55], [14, 64]]  sagittal_73_3  \n","59  [[251, 28], [18, 60]]  sagittal_74_3  \n","60  [[249, 30], [14, 64]]  sagittal_75_3  \n","61  [[222, 57], [10, 68]]  sagittal_76_3  \n","62  [[254, 25], [22, 56]]  sagittal_77_3  \n","63  [[233, 46], [27, 51]]  sagittal_78_3  \n","64  [[266, 13], [35, 43]]  sagittal_79_3  \n","65  [[247, 32], [28, 50]]  sagittal_80_3  "]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"-N0N5unJwRLu"},"source":["# Training Adapted VGG11 (GPU) - 12/10/2021"]},{"cell_type":"markdown","metadata":{"id":"2nYka2QtwRLu"},"source":["## Coronal - 45~55"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1sF1sF8NteyZUWtH_tO9h14nHoA1tq6oM"},"id":"6mZVjs7WwRLu","executionInfo":{"status":"ok","timestamp":1634103060763,"user_tz":180,"elapsed":6270957,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"0929f7bc-5369-4ed0-e26e-59730f19e6cb"},"source":["df_results_coronal = run_mris_experiments(orientation = 'coronal',\n","                          slices = list(range(45,56)),\n","                          num_repeats = 3,\n","                          model='vgg11',\n","                          classes=['AD','CN'],\n","                          save_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/data/RESULTS_CORONAL_VGG11.csv')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6GZGC80bwRLw","executionInfo":{"status":"ok","timestamp":1634103061962,"user_tz":180,"elapsed":970,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"c1e96cfc-46ed-4e84-b7df-fde89731fbec"},"source":["df_results_coronal"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>train_auc</th>\n","      <th>train_accuracy</th>\n","      <th>train_f1score</th>\n","      <th>train_precision</th>\n","      <th>train_recall</th>\n","      <th>train_conf_mat</th>\n","      <th>validation_auc</th>\n","      <th>validation_accuracy</th>\n","      <th>validation_f1score</th>\n","      <th>validation_precision</th>\n","      <th>validation_recall</th>\n","      <th>validation_conf_mat</th>\n","      <th>RUN_ID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.949977</td>\n","      <td>0.964390</td>\n","      <td>0.935450</td>\n","      <td>0.954644</td>\n","      <td>0.917012</td>\n","      <td>[[1210, 21], [40, 442]]</td>\n","      <td>0.794183</td>\n","      <td>0.851541</td>\n","      <td>0.670807</td>\n","      <td>0.650602</td>\n","      <td>0.692308</td>\n","      <td>[[250, 29], [24, 54]]</td>\n","      <td>coronal_45_1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.834413</td>\n","      <td>0.882662</td>\n","      <td>0.776418</td>\n","      <td>0.836930</td>\n","      <td>0.724066</td>\n","      <td>[[1163, 68], [133, 349]]</td>\n","      <td>0.773642</td>\n","      <td>0.862745</td>\n","      <td>0.662069</td>\n","      <td>0.716418</td>\n","      <td>0.615385</td>\n","      <td>[[260, 19], [30, 48]]</td>\n","      <td>coronal_46_1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.971898</td>\n","      <td>0.979568</td>\n","      <td>0.963351</td>\n","      <td>0.972516</td>\n","      <td>0.954357</td>\n","      <td>[[1218, 13], [22, 460]]</td>\n","      <td>0.810794</td>\n","      <td>0.899160</td>\n","      <td>0.739130</td>\n","      <td>0.850000</td>\n","      <td>0.653846</td>\n","      <td>[[270, 9], [27, 51]]</td>\n","      <td>coronal_47_1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.904284</td>\n","      <td>0.932283</td>\n","      <td>0.874730</td>\n","      <td>0.912162</td>\n","      <td>0.840249</td>\n","      <td>[[1192, 39], [77, 405]]</td>\n","      <td>0.769575</td>\n","      <td>0.834734</td>\n","      <td>0.633540</td>\n","      <td>0.614458</td>\n","      <td>0.653846</td>\n","      <td>[[247, 32], [27, 51]]</td>\n","      <td>coronal_48_1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.910914</td>\n","      <td>0.936369</td>\n","      <td>0.882922</td>\n","      <td>0.915367</td>\n","      <td>0.852697</td>\n","      <td>[[1193, 38], [71, 411]]</td>\n","      <td>0.796457</td>\n","      <td>0.876751</td>\n","      <td>0.698630</td>\n","      <td>0.750000</td>\n","      <td>0.653846</td>\n","      <td>[[262, 17], [27, 51]]</td>\n","      <td>coronal_49_1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.877088</td>\n","      <td>0.917688</td>\n","      <td>0.842809</td>\n","      <td>0.910843</td>\n","      <td>0.784232</td>\n","      <td>[[1194, 37], [104, 378]]</td>\n","      <td>0.795148</td>\n","      <td>0.896359</td>\n","      <td>0.721805</td>\n","      <td>0.872727</td>\n","      <td>0.615385</td>\n","      <td>[[272, 7], [30, 48]]</td>\n","      <td>coronal_50_1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.913757</td>\n","      <td>0.940455</td>\n","      <td>0.889610</td>\n","      <td>0.929864</td>\n","      <td>0.852697</td>\n","      <td>[[1200, 31], [71, 411]]</td>\n","      <td>0.791839</td>\n","      <td>0.876751</td>\n","      <td>0.694444</td>\n","      <td>0.757576</td>\n","      <td>0.641026</td>\n","      <td>[[263, 16], [28, 50]]</td>\n","      <td>coronal_51_1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.913263</td>\n","      <td>0.943374</td>\n","      <td>0.893524</td>\n","      <td>0.948718</td>\n","      <td>0.844398</td>\n","      <td>[[1209, 22], [75, 407]]</td>\n","      <td>0.782878</td>\n","      <td>0.862745</td>\n","      <td>0.671141</td>\n","      <td>0.704225</td>\n","      <td>0.641026</td>\n","      <td>[[258, 21], [28, 50]]</td>\n","      <td>coronal_52_1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1231, 0], [0, 482]]</td>\n","      <td>0.844913</td>\n","      <td>0.901961</td>\n","      <td>0.768212</td>\n","      <td>0.794521</td>\n","      <td>0.743590</td>\n","      <td>[[264, 15], [20, 58]]</td>\n","      <td>coronal_53_1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.984709</td>\n","      <td>0.988908</td>\n","      <td>0.980188</td>\n","      <td>0.985325</td>\n","      <td>0.975104</td>\n","      <td>[[1224, 7], [12, 470]]</td>\n","      <td>0.818514</td>\n","      <td>0.882353</td>\n","      <td>0.723684</td>\n","      <td>0.743243</td>\n","      <td>0.705128</td>\n","      <td>[[260, 19], [23, 55]]</td>\n","      <td>coronal_54_1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.937528</td>\n","      <td>0.957385</td>\n","      <td>0.921758</td>\n","      <td>0.953437</td>\n","      <td>0.892116</td>\n","      <td>[[1210, 21], [52, 430]]</td>\n","      <td>0.792666</td>\n","      <td>0.834734</td>\n","      <td>0.654971</td>\n","      <td>0.602151</td>\n","      <td>0.717949</td>\n","      <td>[[242, 37], [22, 56]]</td>\n","      <td>coronal_55_1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.978753</td>\n","      <td>0.983071</td>\n","      <td>0.969886</td>\n","      <td>0.970894</td>\n","      <td>0.968880</td>\n","      <td>[[1217, 14], [15, 467]]</td>\n","      <td>0.776675</td>\n","      <td>0.896359</td>\n","      <td>0.704000</td>\n","      <td>0.936170</td>\n","      <td>0.564103</td>\n","      <td>[[276, 3], [34, 44]]</td>\n","      <td>coronal_45_2</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.993189</td>\n","      <td>0.994746</td>\n","      <td>0.990654</td>\n","      <td>0.991684</td>\n","      <td>0.989627</td>\n","      <td>[[1227, 4], [5, 477]]</td>\n","      <td>0.795699</td>\n","      <td>0.868347</td>\n","      <td>0.688742</td>\n","      <td>0.712329</td>\n","      <td>0.666667</td>\n","      <td>[[258, 21], [26, 52]]</td>\n","      <td>coronal_46_2</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.963643</td>\n","      <td>0.973147</td>\n","      <td>0.951782</td>\n","      <td>0.961864</td>\n","      <td>0.941909</td>\n","      <td>[[1213, 18], [28, 454]]</td>\n","      <td>0.777226</td>\n","      <td>0.868347</td>\n","      <td>0.671329</td>\n","      <td>0.738462</td>\n","      <td>0.615385</td>\n","      <td>[[262, 17], [30, 48]]</td>\n","      <td>coronal_47_2</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.926793</td>\n","      <td>0.949212</td>\n","      <td>0.906552</td>\n","      <td>0.939866</td>\n","      <td>0.875519</td>\n","      <td>[[1204, 27], [60, 422]]</td>\n","      <td>0.784671</td>\n","      <td>0.865546</td>\n","      <td>0.675676</td>\n","      <td>0.714286</td>\n","      <td>0.641026</td>\n","      <td>[[259, 20], [28, 50]]</td>\n","      <td>coronal_48_2</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.841137</td>\n","      <td>0.891419</td>\n","      <td>0.790068</td>\n","      <td>0.866337</td>\n","      <td>0.726141</td>\n","      <td>[[1177, 54], [132, 350]]</td>\n","      <td>0.817756</td>\n","      <td>0.873950</td>\n","      <td>0.713376</td>\n","      <td>0.708861</td>\n","      <td>0.717949</td>\n","      <td>[[256, 23], [22, 56]]</td>\n","      <td>coronal_49_2</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.942534</td>\n","      <td>0.959136</td>\n","      <td>0.925690</td>\n","      <td>0.947826</td>\n","      <td>0.904564</td>\n","      <td>[[1207, 24], [46, 436]]</td>\n","      <td>0.792597</td>\n","      <td>0.885154</td>\n","      <td>0.705036</td>\n","      <td>0.803279</td>\n","      <td>0.628205</td>\n","      <td>[[267, 12], [29, 49]]</td>\n","      <td>coronal_50_2</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.890667</td>\n","      <td>0.929947</td>\n","      <td>0.865471</td>\n","      <td>0.941463</td>\n","      <td>0.800830</td>\n","      <td>[[1207, 24], [96, 386]]</td>\n","      <td>0.794389</td>\n","      <td>0.887955</td>\n","      <td>0.710145</td>\n","      <td>0.816667</td>\n","      <td>0.628205</td>\n","      <td>[[268, 11], [29, 49]]</td>\n","      <td>coronal_51_2</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.992782</td>\n","      <td>0.994162</td>\n","      <td>0.989627</td>\n","      <td>0.989627</td>\n","      <td>0.989627</td>\n","      <td>[[1226, 5], [5, 477]]</td>\n","      <td>0.825682</td>\n","      <td>0.893557</td>\n","      <td>0.743243</td>\n","      <td>0.785714</td>\n","      <td>0.705128</td>\n","      <td>[[264, 15], [23, 55]]</td>\n","      <td>coronal_52_2</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.928824</td>\n","      <td>0.952131</td>\n","      <td>0.911447</td>\n","      <td>0.950450</td>\n","      <td>0.875519</td>\n","      <td>[[1209, 22], [60, 422]]</td>\n","      <td>0.789840</td>\n","      <td>0.837535</td>\n","      <td>0.654762</td>\n","      <td>0.611111</td>\n","      <td>0.705128</td>\n","      <td>[[244, 35], [23, 55]]</td>\n","      <td>coronal_53_2</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>0.936623</td>\n","      <td>0.951547</td>\n","      <td>0.912907</td>\n","      <td>0.923567</td>\n","      <td>0.902490</td>\n","      <td>[[1195, 36], [47, 435]]</td>\n","      <td>0.819065</td>\n","      <td>0.854342</td>\n","      <td>0.694118</td>\n","      <td>0.641304</td>\n","      <td>0.756410</td>\n","      <td>[[246, 33], [19, 59]]</td>\n","      <td>coronal_54_2</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0.948939</td>\n","      <td>0.963806</td>\n","      <td>0.934322</td>\n","      <td>0.954545</td>\n","      <td>0.914938</td>\n","      <td>[[1210, 21], [41, 441]]</td>\n","      <td>0.796250</td>\n","      <td>0.840336</td>\n","      <td>0.662722</td>\n","      <td>0.615385</td>\n","      <td>0.717949</td>\n","      <td>[[244, 35], [22, 56]]</td>\n","      <td>coronal_55_2</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0.954126</td>\n","      <td>0.966725</td>\n","      <td>0.939937</td>\n","      <td>0.955032</td>\n","      <td>0.925311</td>\n","      <td>[[1210, 21], [36, 446]]</td>\n","      <td>0.784946</td>\n","      <td>0.851541</td>\n","      <td>0.662420</td>\n","      <td>0.658228</td>\n","      <td>0.666667</td>\n","      <td>[[252, 27], [26, 52]]</td>\n","      <td>coronal_45_3</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0.875282</td>\n","      <td>0.914186</td>\n","      <td>0.837569</td>\n","      <td>0.895981</td>\n","      <td>0.786307</td>\n","      <td>[[1187, 44], [103, 379]]</td>\n","      <td>0.779570</td>\n","      <td>0.843137</td>\n","      <td>0.650000</td>\n","      <td>0.634146</td>\n","      <td>0.666667</td>\n","      <td>[[249, 30], [26, 52]]</td>\n","      <td>coronal_46_3</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0.909202</td>\n","      <td>0.937536</td>\n","      <td>0.883822</td>\n","      <td>0.927107</td>\n","      <td>0.844398</td>\n","      <td>[[1199, 32], [75, 407]]</td>\n","      <td>0.789082</td>\n","      <td>0.829132</td>\n","      <td>0.647399</td>\n","      <td>0.589474</td>\n","      <td>0.717949</td>\n","      <td>[[240, 39], [22, 56]]</td>\n","      <td>coronal_47_3</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0.830358</td>\n","      <td>0.884997</td>\n","      <td>0.775371</td>\n","      <td>0.860759</td>\n","      <td>0.705394</td>\n","      <td>[[1176, 55], [142, 340]]</td>\n","      <td>0.790323</td>\n","      <td>0.859944</td>\n","      <td>0.675325</td>\n","      <td>0.684211</td>\n","      <td>0.666667</td>\n","      <td>[[255, 24], [26, 52]]</td>\n","      <td>coronal_48_3</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0.904015</td>\n","      <td>0.934618</td>\n","      <td>0.877729</td>\n","      <td>0.926267</td>\n","      <td>0.834025</td>\n","      <td>[[1199, 32], [80, 402]]</td>\n","      <td>0.794665</td>\n","      <td>0.873950</td>\n","      <td>0.693878</td>\n","      <td>0.739130</td>\n","      <td>0.653846</td>\n","      <td>[[261, 18], [27, 51]]</td>\n","      <td>coronal_49_3</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>0.859771</td>\n","      <td>0.911851</td>\n","      <td>0.825434</td>\n","      <td>0.932115</td>\n","      <td>0.740664</td>\n","      <td>[[1205, 26], [125, 357]]</td>\n","      <td>0.792390</td>\n","      <td>0.848739</td>\n","      <td>0.666667</td>\n","      <td>0.642857</td>\n","      <td>0.692308</td>\n","      <td>[[249, 30], [24, 54]]</td>\n","      <td>coronal_50_3</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0.860084</td>\n","      <td>0.907764</td>\n","      <td>0.820862</td>\n","      <td>0.905000</td>\n","      <td>0.751037</td>\n","      <td>[[1193, 38], [120, 362]]</td>\n","      <td>0.803419</td>\n","      <td>0.851541</td>\n","      <td>0.678788</td>\n","      <td>0.643678</td>\n","      <td>0.717949</td>\n","      <td>[[248, 31], [22, 56]]</td>\n","      <td>coronal_51_3</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>0.859815</td>\n","      <td>0.910099</td>\n","      <td>0.823394</td>\n","      <td>0.920513</td>\n","      <td>0.744813</td>\n","      <td>[[1200, 31], [123, 359]]</td>\n","      <td>0.789289</td>\n","      <td>0.865546</td>\n","      <td>0.680000</td>\n","      <td>0.708333</td>\n","      <td>0.653846</td>\n","      <td>[[258, 21], [27, 51]]</td>\n","      <td>coronal_52_3</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>0.866939</td>\n","      <td>0.911267</td>\n","      <td>0.829213</td>\n","      <td>0.904412</td>\n","      <td>0.765560</td>\n","      <td>[[1192, 39], [113, 369]]</td>\n","      <td>0.791081</td>\n","      <td>0.868347</td>\n","      <td>0.684564</td>\n","      <td>0.718310</td>\n","      <td>0.653846</td>\n","      <td>[[259, 20], [27, 51]]</td>\n","      <td>coronal_53_3</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>0.942309</td>\n","      <td>0.959720</td>\n","      <td>0.926518</td>\n","      <td>0.951860</td>\n","      <td>0.902490</td>\n","      <td>[[1209, 22], [47, 435]]</td>\n","      <td>0.801627</td>\n","      <td>0.848739</td>\n","      <td>0.674699</td>\n","      <td>0.636364</td>\n","      <td>0.717949</td>\n","      <td>[[247, 32], [22, 56]]</td>\n","      <td>coronal_54_3</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>0.799412</td>\n","      <td>0.860479</td>\n","      <td>0.726857</td>\n","      <td>0.809160</td>\n","      <td>0.659751</td>\n","      <td>[[1156, 75], [164, 318]]</td>\n","      <td>0.793907</td>\n","      <td>0.865546</td>\n","      <td>0.684211</td>\n","      <td>0.702703</td>\n","      <td>0.666667</td>\n","      <td>[[257, 22], [26, 52]]</td>\n","      <td>coronal_55_3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    train_auc  train_accuracy  train_f1score  train_precision  train_recall  \\\n","0    0.949977        0.964390       0.935450         0.954644      0.917012   \n","1    0.834413        0.882662       0.776418         0.836930      0.724066   \n","2    0.971898        0.979568       0.963351         0.972516      0.954357   \n","3    0.904284        0.932283       0.874730         0.912162      0.840249   \n","4    0.910914        0.936369       0.882922         0.915367      0.852697   \n","5    0.877088        0.917688       0.842809         0.910843      0.784232   \n","6    0.913757        0.940455       0.889610         0.929864      0.852697   \n","7    0.913263        0.943374       0.893524         0.948718      0.844398   \n","8    1.000000        1.000000       1.000000         1.000000      1.000000   \n","9    0.984709        0.988908       0.980188         0.985325      0.975104   \n","10   0.937528        0.957385       0.921758         0.953437      0.892116   \n","11   0.978753        0.983071       0.969886         0.970894      0.968880   \n","12   0.993189        0.994746       0.990654         0.991684      0.989627   \n","13   0.963643        0.973147       0.951782         0.961864      0.941909   \n","14   0.926793        0.949212       0.906552         0.939866      0.875519   \n","15   0.841137        0.891419       0.790068         0.866337      0.726141   \n","16   0.942534        0.959136       0.925690         0.947826      0.904564   \n","17   0.890667        0.929947       0.865471         0.941463      0.800830   \n","18   0.992782        0.994162       0.989627         0.989627      0.989627   \n","19   0.928824        0.952131       0.911447         0.950450      0.875519   \n","20   0.936623        0.951547       0.912907         0.923567      0.902490   \n","21   0.948939        0.963806       0.934322         0.954545      0.914938   \n","22   0.954126        0.966725       0.939937         0.955032      0.925311   \n","23   0.875282        0.914186       0.837569         0.895981      0.786307   \n","24   0.909202        0.937536       0.883822         0.927107      0.844398   \n","25   0.830358        0.884997       0.775371         0.860759      0.705394   \n","26   0.904015        0.934618       0.877729         0.926267      0.834025   \n","27   0.859771        0.911851       0.825434         0.932115      0.740664   \n","28   0.860084        0.907764       0.820862         0.905000      0.751037   \n","29   0.859815        0.910099       0.823394         0.920513      0.744813   \n","30   0.866939        0.911267       0.829213         0.904412      0.765560   \n","31   0.942309        0.959720       0.926518         0.951860      0.902490   \n","32   0.799412        0.860479       0.726857         0.809160      0.659751   \n","\n","              train_conf_mat  validation_auc  validation_accuracy  \\\n","0    [[1210, 21], [40, 442]]        0.794183             0.851541   \n","1   [[1163, 68], [133, 349]]        0.773642             0.862745   \n","2    [[1218, 13], [22, 460]]        0.810794             0.899160   \n","3    [[1192, 39], [77, 405]]        0.769575             0.834734   \n","4    [[1193, 38], [71, 411]]        0.796457             0.876751   \n","5   [[1194, 37], [104, 378]]        0.795148             0.896359   \n","6    [[1200, 31], [71, 411]]        0.791839             0.876751   \n","7    [[1209, 22], [75, 407]]        0.782878             0.862745   \n","8      [[1231, 0], [0, 482]]        0.844913             0.901961   \n","9     [[1224, 7], [12, 470]]        0.818514             0.882353   \n","10   [[1210, 21], [52, 430]]        0.792666             0.834734   \n","11   [[1217, 14], [15, 467]]        0.776675             0.896359   \n","12     [[1227, 4], [5, 477]]        0.795699             0.868347   \n","13   [[1213, 18], [28, 454]]        0.777226             0.868347   \n","14   [[1204, 27], [60, 422]]        0.784671             0.865546   \n","15  [[1177, 54], [132, 350]]        0.817756             0.873950   \n","16   [[1207, 24], [46, 436]]        0.792597             0.885154   \n","17   [[1207, 24], [96, 386]]        0.794389             0.887955   \n","18     [[1226, 5], [5, 477]]        0.825682             0.893557   \n","19   [[1209, 22], [60, 422]]        0.789840             0.837535   \n","20   [[1195, 36], [47, 435]]        0.819065             0.854342   \n","21   [[1210, 21], [41, 441]]        0.796250             0.840336   \n","22   [[1210, 21], [36, 446]]        0.784946             0.851541   \n","23  [[1187, 44], [103, 379]]        0.779570             0.843137   \n","24   [[1199, 32], [75, 407]]        0.789082             0.829132   \n","25  [[1176, 55], [142, 340]]        0.790323             0.859944   \n","26   [[1199, 32], [80, 402]]        0.794665             0.873950   \n","27  [[1205, 26], [125, 357]]        0.792390             0.848739   \n","28  [[1193, 38], [120, 362]]        0.803419             0.851541   \n","29  [[1200, 31], [123, 359]]        0.789289             0.865546   \n","30  [[1192, 39], [113, 369]]        0.791081             0.868347   \n","31   [[1209, 22], [47, 435]]        0.801627             0.848739   \n","32  [[1156, 75], [164, 318]]        0.793907             0.865546   \n","\n","    validation_f1score  validation_precision  validation_recall  \\\n","0             0.670807              0.650602           0.692308   \n","1             0.662069              0.716418           0.615385   \n","2             0.739130              0.850000           0.653846   \n","3             0.633540              0.614458           0.653846   \n","4             0.698630              0.750000           0.653846   \n","5             0.721805              0.872727           0.615385   \n","6             0.694444              0.757576           0.641026   \n","7             0.671141              0.704225           0.641026   \n","8             0.768212              0.794521           0.743590   \n","9             0.723684              0.743243           0.705128   \n","10            0.654971              0.602151           0.717949   \n","11            0.704000              0.936170           0.564103   \n","12            0.688742              0.712329           0.666667   \n","13            0.671329              0.738462           0.615385   \n","14            0.675676              0.714286           0.641026   \n","15            0.713376              0.708861           0.717949   \n","16            0.705036              0.803279           0.628205   \n","17            0.710145              0.816667           0.628205   \n","18            0.743243              0.785714           0.705128   \n","19            0.654762              0.611111           0.705128   \n","20            0.694118              0.641304           0.756410   \n","21            0.662722              0.615385           0.717949   \n","22            0.662420              0.658228           0.666667   \n","23            0.650000              0.634146           0.666667   \n","24            0.647399              0.589474           0.717949   \n","25            0.675325              0.684211           0.666667   \n","26            0.693878              0.739130           0.653846   \n","27            0.666667              0.642857           0.692308   \n","28            0.678788              0.643678           0.717949   \n","29            0.680000              0.708333           0.653846   \n","30            0.684564              0.718310           0.653846   \n","31            0.674699              0.636364           0.717949   \n","32            0.684211              0.702703           0.666667   \n","\n","      validation_conf_mat        RUN_ID  \n","0   [[250, 29], [24, 54]]  coronal_45_1  \n","1   [[260, 19], [30, 48]]  coronal_46_1  \n","2    [[270, 9], [27, 51]]  coronal_47_1  \n","3   [[247, 32], [27, 51]]  coronal_48_1  \n","4   [[262, 17], [27, 51]]  coronal_49_1  \n","5    [[272, 7], [30, 48]]  coronal_50_1  \n","6   [[263, 16], [28, 50]]  coronal_51_1  \n","7   [[258, 21], [28, 50]]  coronal_52_1  \n","8   [[264, 15], [20, 58]]  coronal_53_1  \n","9   [[260, 19], [23, 55]]  coronal_54_1  \n","10  [[242, 37], [22, 56]]  coronal_55_1  \n","11   [[276, 3], [34, 44]]  coronal_45_2  \n","12  [[258, 21], [26, 52]]  coronal_46_2  \n","13  [[262, 17], [30, 48]]  coronal_47_2  \n","14  [[259, 20], [28, 50]]  coronal_48_2  \n","15  [[256, 23], [22, 56]]  coronal_49_2  \n","16  [[267, 12], [29, 49]]  coronal_50_2  \n","17  [[268, 11], [29, 49]]  coronal_51_2  \n","18  [[264, 15], [23, 55]]  coronal_52_2  \n","19  [[244, 35], [23, 55]]  coronal_53_2  \n","20  [[246, 33], [19, 59]]  coronal_54_2  \n","21  [[244, 35], [22, 56]]  coronal_55_2  \n","22  [[252, 27], [26, 52]]  coronal_45_3  \n","23  [[249, 30], [26, 52]]  coronal_46_3  \n","24  [[240, 39], [22, 56]]  coronal_47_3  \n","25  [[255, 24], [26, 52]]  coronal_48_3  \n","26  [[261, 18], [27, 51]]  coronal_49_3  \n","27  [[249, 30], [24, 54]]  coronal_50_3  \n","28  [[248, 31], [22, 56]]  coronal_51_3  \n","29  [[258, 21], [27, 51]]  coronal_52_3  \n","30  [[259, 20], [27, 51]]  coronal_53_3  \n","31  [[247, 32], [22, 56]]  coronal_54_3  \n","32  [[257, 22], [26, 52]]  coronal_55_3  "]},"metadata":{},"execution_count":140}]},{"cell_type":"markdown","metadata":{"id":"tXnUL-amwRLw"},"source":["## Axial 20-30 + 70-80"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1FWhcnbP2-ZLSfN0MApqB4Yzksnjy_ATc"},"id":"LiNe37wCwRLx","executionInfo":{"status":"ok","timestamp":1634114717672,"user_tz":180,"elapsed":11654899,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"3be4abba-ee4e-4ba0-a58d-30fac3969662"},"source":["df_results_axial = run_mris_experiments(orientation = 'axial',\n","                          slices = list(range(20,31)) + list(range(70,81)),\n","                          num_repeats = 3,\n","                          model='vgg11',\n","                          classes=['AD','CN'],\n","                          save_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/data/RESULTS_AXIAL_VGG11.csv')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"S1g521SHwRLx","executionInfo":{"status":"ok","timestamp":1634114717676,"user_tz":180,"elapsed":27,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"3e5219e2-4e31-440d-ae31-64132f0a65d3"},"source":["df_results_axial"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>train_auc</th>\n","      <th>train_accuracy</th>\n","      <th>train_f1score</th>\n","      <th>train_precision</th>\n","      <th>train_recall</th>\n","      <th>train_conf_mat</th>\n","      <th>validation_auc</th>\n","      <th>validation_accuracy</th>\n","      <th>validation_f1score</th>\n","      <th>validation_precision</th>\n","      <th>validation_recall</th>\n","      <th>validation_conf_mat</th>\n","      <th>RUN_ID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.909783</td>\n","      <td>0.931115</td>\n","      <td>0.875527</td>\n","      <td>0.890558</td>\n","      <td>0.860996</td>\n","      <td>[[1180, 51], [67, 415]]</td>\n","      <td>0.828026</td>\n","      <td>0.868347</td>\n","      <td>0.715152</td>\n","      <td>0.678161</td>\n","      <td>0.756410</td>\n","      <td>[[251, 28], [19, 59]]</td>\n","      <td>axial_20_1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.855654</td>\n","      <td>0.891419</td>\n","      <td>0.800429</td>\n","      <td>0.828889</td>\n","      <td>0.773859</td>\n","      <td>[[1154, 77], [109, 373]]</td>\n","      <td>0.812862</td>\n","      <td>0.887955</td>\n","      <td>0.726027</td>\n","      <td>0.779412</td>\n","      <td>0.679487</td>\n","      <td>[[264, 15], [25, 53]]</td>\n","      <td>axial_21_1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.955207</td>\n","      <td>0.965558</td>\n","      <td>0.938349</td>\n","      <td>0.945263</td>\n","      <td>0.931535</td>\n","      <td>[[1205, 26], [33, 449]]</td>\n","      <td>0.800110</td>\n","      <td>0.831933</td>\n","      <td>0.659091</td>\n","      <td>0.591837</td>\n","      <td>0.743590</td>\n","      <td>[[239, 40], [20, 58]]</td>\n","      <td>axial_22_1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.903696</td>\n","      <td>0.930531</td>\n","      <td>0.872180</td>\n","      <td>0.904232</td>\n","      <td>0.842324</td>\n","      <td>[[1188, 43], [76, 406]]</td>\n","      <td>0.789289</td>\n","      <td>0.865546</td>\n","      <td>0.680000</td>\n","      <td>0.708333</td>\n","      <td>0.653846</td>\n","      <td>[[258, 21], [27, 51]]</td>\n","      <td>axial_23_1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.880512</td>\n","      <td>0.915353</td>\n","      <td>0.841876</td>\n","      <td>0.887356</td>\n","      <td>0.800830</td>\n","      <td>[[1182, 49], [96, 386]]</td>\n","      <td>0.752895</td>\n","      <td>0.837535</td>\n","      <td>0.618421</td>\n","      <td>0.635135</td>\n","      <td>0.602564</td>\n","      <td>[[252, 27], [31, 47]]</td>\n","      <td>axial_24_1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.969417</td>\n","      <td>0.977817</td>\n","      <td>0.960168</td>\n","      <td>0.970339</td>\n","      <td>0.950207</td>\n","      <td>[[1217, 14], [24, 458]]</td>\n","      <td>0.777985</td>\n","      <td>0.876751</td>\n","      <td>0.681159</td>\n","      <td>0.783333</td>\n","      <td>0.602564</td>\n","      <td>[[266, 13], [31, 47]]</td>\n","      <td>axial_25_1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.900316</td>\n","      <td>0.931115</td>\n","      <td>0.871460</td>\n","      <td>0.917431</td>\n","      <td>0.829876</td>\n","      <td>[[1195, 36], [82, 400]]</td>\n","      <td>0.785429</td>\n","      <td>0.873950</td>\n","      <td>0.685315</td>\n","      <td>0.753846</td>\n","      <td>0.628205</td>\n","      <td>[[263, 16], [29, 49]]</td>\n","      <td>axial_26_1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.963418</td>\n","      <td>0.973730</td>\n","      <td>0.952681</td>\n","      <td>0.965885</td>\n","      <td>0.939834</td>\n","      <td>[[1215, 16], [29, 453]]</td>\n","      <td>0.781086</td>\n","      <td>0.859944</td>\n","      <td>0.666667</td>\n","      <td>0.694444</td>\n","      <td>0.641026</td>\n","      <td>[[257, 22], [28, 50]]</td>\n","      <td>axial_27_1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.997519</td>\n","      <td>0.998249</td>\n","      <td>0.996885</td>\n","      <td>0.997921</td>\n","      <td>0.995851</td>\n","      <td>[[1230, 1], [2, 480]]</td>\n","      <td>0.810587</td>\n","      <td>0.862745</td>\n","      <td>0.695652</td>\n","      <td>0.674699</td>\n","      <td>0.717949</td>\n","      <td>[[252, 27], [22, 56]]</td>\n","      <td>axial_28_1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.921019</td>\n","      <td>0.944542</td>\n","      <td>0.897959</td>\n","      <td>0.930958</td>\n","      <td>0.867220</td>\n","      <td>[[1200, 31], [64, 418]]</td>\n","      <td>0.788599</td>\n","      <td>0.806723</td>\n","      <td>0.631016</td>\n","      <td>0.541284</td>\n","      <td>0.756410</td>\n","      <td>[[229, 50], [19, 59]]</td>\n","      <td>axial_29_1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.991339</td>\n","      <td>0.992995</td>\n","      <td>0.987552</td>\n","      <td>0.987552</td>\n","      <td>0.987552</td>\n","      <td>[[1225, 6], [6, 476]]</td>\n","      <td>0.816998</td>\n","      <td>0.865546</td>\n","      <td>0.703704</td>\n","      <td>0.678571</td>\n","      <td>0.730769</td>\n","      <td>[[252, 27], [21, 57]]</td>\n","      <td>axial_30_1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.498725</td>\n","      <td>0.710280</td>\n","      <td>0.027451</td>\n","      <td>0.250000</td>\n","      <td>0.014523</td>\n","      <td>[[1209, 21], [475, 7]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_70_1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.499860</td>\n","      <td>0.715537</td>\n","      <td>0.012170</td>\n","      <td>0.272727</td>\n","      <td>0.006224</td>\n","      <td>[[1222, 8], [479, 3]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_71_1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.503154</td>\n","      <td>0.718458</td>\n","      <td>0.020325</td>\n","      <td>0.500000</td>\n","      <td>0.010373</td>\n","      <td>[[1225, 5], [477, 5]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_72_1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.497014</td>\n","      <td>0.711449</td>\n","      <td>0.012000</td>\n","      <td>0.166667</td>\n","      <td>0.006224</td>\n","      <td>[[1215, 15], [479, 3]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_73_1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.922494</td>\n","      <td>0.943925</td>\n","      <td>0.897655</td>\n","      <td>0.923246</td>\n","      <td>0.873444</td>\n","      <td>[[1195, 35], [61, 421]]</td>\n","      <td>0.585263</td>\n","      <td>0.719888</td>\n","      <td>0.350649</td>\n","      <td>0.355263</td>\n","      <td>0.346154</td>\n","      <td>[[230, 49], [51, 27]]</td>\n","      <td>axial_74_1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.501262</td>\n","      <td>0.718458</td>\n","      <td>0.008230</td>\n","      <td>0.500000</td>\n","      <td>0.004149</td>\n","      <td>[[1228, 2], [480, 2]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_75_1</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.499636</td>\n","      <td>0.716121</td>\n","      <td>0.008163</td>\n","      <td>0.250000</td>\n","      <td>0.004149</td>\n","      <td>[[1224, 6], [480, 2]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_76_1</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.892062</td>\n","      <td>0.906542</td>\n","      <td>0.838057</td>\n","      <td>0.818182</td>\n","      <td>0.858921</td>\n","      <td>[[1138, 92], [68, 414]]</td>\n","      <td>0.582368</td>\n","      <td>0.773109</td>\n","      <td>0.319328</td>\n","      <td>0.463415</td>\n","      <td>0.243590</td>\n","      <td>[[257, 22], [59, 19]]</td>\n","      <td>axial_77_1</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.500897</td>\n","      <td>0.716121</td>\n","      <td>0.016194</td>\n","      <td>0.333333</td>\n","      <td>0.008299</td>\n","      <td>[[1222, 8], [478, 4]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_78_1</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>0.500224</td>\n","      <td>0.717874</td>\n","      <td>0.004124</td>\n","      <td>0.333333</td>\n","      <td>0.002075</td>\n","      <td>[[1228, 2], [481, 1]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_79_1</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0.501080</td>\n","      <td>0.717290</td>\n","      <td>0.012245</td>\n","      <td>0.375000</td>\n","      <td>0.006224</td>\n","      <td>[[1225, 5], [479, 3]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_80_1</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0.922325</td>\n","      <td>0.942790</td>\n","      <td>0.895966</td>\n","      <td>0.917391</td>\n","      <td>0.875519</td>\n","      <td>[[1193, 38], [60, 422]]</td>\n","      <td>0.860835</td>\n","      <td>0.890756</td>\n","      <td>0.763636</td>\n","      <td>0.724138</td>\n","      <td>0.807692</td>\n","      <td>[[255, 24], [15, 63]]</td>\n","      <td>axial_20_2</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0.904690</td>\n","      <td>0.932866</td>\n","      <td>0.875676</td>\n","      <td>0.914221</td>\n","      <td>0.840249</td>\n","      <td>[[1193, 38], [77, 405]]</td>\n","      <td>0.827750</td>\n","      <td>0.882353</td>\n","      <td>0.730769</td>\n","      <td>0.730769</td>\n","      <td>0.730769</td>\n","      <td>[[258, 21], [21, 57]]</td>\n","      <td>axial_21_2</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0.919844</td>\n","      <td>0.941039</td>\n","      <td>0.892667</td>\n","      <td>0.915033</td>\n","      <td>0.871369</td>\n","      <td>[[1192, 39], [62, 420]]</td>\n","      <td>0.826303</td>\n","      <td>0.815126</td>\n","      <td>0.666667</td>\n","      <td>0.550000</td>\n","      <td>0.846154</td>\n","      <td>[[225, 54], [12, 66]]</td>\n","      <td>axial_22_2</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0.861791</td>\n","      <td>0.898424</td>\n","      <td>0.811688</td>\n","      <td>0.848416</td>\n","      <td>0.778008</td>\n","      <td>[[1164, 67], [107, 375]]</td>\n","      <td>0.802867</td>\n","      <td>0.879552</td>\n","      <td>0.707483</td>\n","      <td>0.753623</td>\n","      <td>0.666667</td>\n","      <td>[[262, 17], [26, 52]]</td>\n","      <td>axial_23_2</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0.941678</td>\n","      <td>0.959720</td>\n","      <td>0.926361</td>\n","      <td>0.953846</td>\n","      <td>0.900415</td>\n","      <td>[[1210, 21], [48, 434]]</td>\n","      <td>0.791908</td>\n","      <td>0.826331</td>\n","      <td>0.647727</td>\n","      <td>0.581633</td>\n","      <td>0.730769</td>\n","      <td>[[238, 41], [21, 57]]</td>\n","      <td>axial_24_2</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>0.939466</td>\n","      <td>0.955633</td>\n","      <td>0.919662</td>\n","      <td>0.937500</td>\n","      <td>0.902490</td>\n","      <td>[[1202, 29], [47, 435]]</td>\n","      <td>0.771850</td>\n","      <td>0.859944</td>\n","      <td>0.657534</td>\n","      <td>0.705882</td>\n","      <td>0.615385</td>\n","      <td>[[259, 20], [30, 48]]</td>\n","      <td>axial_25_2</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0.929948</td>\n","      <td>0.949212</td>\n","      <td>0.907545</td>\n","      <td>0.930283</td>\n","      <td>0.885892</td>\n","      <td>[[1199, 32], [55, 427]]</td>\n","      <td>0.783154</td>\n","      <td>0.848739</td>\n","      <td>0.658228</td>\n","      <td>0.650000</td>\n","      <td>0.666667</td>\n","      <td>[[251, 28], [26, 52]]</td>\n","      <td>axial_26_2</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>0.985790</td>\n","      <td>0.987741</td>\n","      <td>0.978283</td>\n","      <td>0.975258</td>\n","      <td>0.981328</td>\n","      <td>[[1219, 12], [9, 473]]</td>\n","      <td>0.806245</td>\n","      <td>0.848739</td>\n","      <td>0.678571</td>\n","      <td>0.633333</td>\n","      <td>0.730769</td>\n","      <td>[[246, 33], [21, 57]]</td>\n","      <td>axial_27_2</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>0.984752</td>\n","      <td>0.987157</td>\n","      <td>0.977226</td>\n","      <td>0.975207</td>\n","      <td>0.979253</td>\n","      <td>[[1219, 12], [10, 472]]</td>\n","      <td>0.754687</td>\n","      <td>0.840336</td>\n","      <td>0.622517</td>\n","      <td>0.643836</td>\n","      <td>0.602564</td>\n","      <td>[[253, 26], [31, 47]]</td>\n","      <td>axial_28_2</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>0.930442</td>\n","      <td>0.946293</td>\n","      <td>0.903564</td>\n","      <td>0.913136</td>\n","      <td>0.894191</td>\n","      <td>[[1190, 41], [51, 431]]</td>\n","      <td>0.790323</td>\n","      <td>0.859944</td>\n","      <td>0.675325</td>\n","      <td>0.684211</td>\n","      <td>0.666667</td>\n","      <td>[[255, 24], [26, 52]]</td>\n","      <td>axial_29_2</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>0.954126</td>\n","      <td>0.966725</td>\n","      <td>0.939937</td>\n","      <td>0.955032</td>\n","      <td>0.925311</td>\n","      <td>[[1210, 21], [36, 446]]</td>\n","      <td>0.803901</td>\n","      <td>0.873950</td>\n","      <td>0.701987</td>\n","      <td>0.726027</td>\n","      <td>0.679487</td>\n","      <td>[[259, 20], [25, 53]]</td>\n","      <td>axial_30_2</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1230, 0], [0, 482]]</td>\n","      <td>0.682175</td>\n","      <td>0.770308</td>\n","      <td>0.500000</td>\n","      <td>0.476744</td>\n","      <td>0.525641</td>\n","      <td>[[234, 45], [37, 41]]</td>\n","      <td>axial_70_2</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>0.501486</td>\n","      <td>0.717874</td>\n","      <td>0.012270</td>\n","      <td>0.428571</td>\n","      <td>0.006224</td>\n","      <td>[[1226, 4], [479, 3]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_71_2</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>0.501528</td>\n","      <td>0.716121</td>\n","      <td>0.020161</td>\n","      <td>0.357143</td>\n","      <td>0.010373</td>\n","      <td>[[1221, 9], [477, 5]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_72_2</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>0.967787</td>\n","      <td>0.975467</td>\n","      <td>0.956159</td>\n","      <td>0.962185</td>\n","      <td>0.950207</td>\n","      <td>[[1212, 18], [24, 458]]</td>\n","      <td>0.581610</td>\n","      <td>0.764706</td>\n","      <td>0.322581</td>\n","      <td>0.434783</td>\n","      <td>0.256410</td>\n","      <td>[[253, 26], [58, 20]]</td>\n","      <td>axial_73_2</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>0.786240</td>\n","      <td>0.838785</td>\n","      <td>0.699346</td>\n","      <td>0.736239</td>\n","      <td>0.665975</td>\n","      <td>[[1115, 115], [161, 321]]</td>\n","      <td>0.573683</td>\n","      <td>0.745098</td>\n","      <td>0.315789</td>\n","      <td>0.381818</td>\n","      <td>0.269231</td>\n","      <td>[[245, 34], [57, 21]]</td>\n","      <td>axial_74_2</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>0.500309</td>\n","      <td>0.714369</td>\n","      <td>0.020040</td>\n","      <td>0.294118</td>\n","      <td>0.010373</td>\n","      <td>[[1218, 12], [477, 5]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_75_2</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>0.502341</td>\n","      <td>0.717290</td>\n","      <td>0.020243</td>\n","      <td>0.416667</td>\n","      <td>0.010373</td>\n","      <td>[[1223, 7], [477, 5]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_76_2</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>0.937830</td>\n","      <td>0.953271</td>\n","      <td>0.915789</td>\n","      <td>0.929487</td>\n","      <td>0.902490</td>\n","      <td>[[1197, 33], [47, 435]]</td>\n","      <td>0.624207</td>\n","      <td>0.759104</td>\n","      <td>0.410959</td>\n","      <td>0.441176</td>\n","      <td>0.384615</td>\n","      <td>[[241, 38], [48, 30]]</td>\n","      <td>axial_77_2</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>0.503967</td>\n","      <td>0.719626</td>\n","      <td>0.020408</td>\n","      <td>0.625000</td>\n","      <td>0.010373</td>\n","      <td>[[1227, 3], [477, 5]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_78_2</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>0.501122</td>\n","      <td>0.715537</td>\n","      <td>0.020121</td>\n","      <td>0.333333</td>\n","      <td>0.010373</td>\n","      <td>[[1220, 10], [477, 5]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_79_2</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>0.498458</td>\n","      <td>0.712617</td>\n","      <td>0.016000</td>\n","      <td>0.222222</td>\n","      <td>0.008299</td>\n","      <td>[[1216, 14], [478, 4]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_80_2</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>0.960981</td>\n","      <td>0.970228</td>\n","      <td>0.946708</td>\n","      <td>0.953684</td>\n","      <td>0.939834</td>\n","      <td>[[1209, 22], [29, 453]]</td>\n","      <td>0.849531</td>\n","      <td>0.901961</td>\n","      <td>0.771242</td>\n","      <td>0.786667</td>\n","      <td>0.756410</td>\n","      <td>[[263, 16], [19, 59]]</td>\n","      <td>axial_20_3</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>0.899410</td>\n","      <td>0.925277</td>\n","      <td>0.863539</td>\n","      <td>0.888158</td>\n","      <td>0.840249</td>\n","      <td>[[1180, 51], [77, 405]]</td>\n","      <td>0.814447</td>\n","      <td>0.854342</td>\n","      <td>0.690476</td>\n","      <td>0.644444</td>\n","      <td>0.743590</td>\n","      <td>[[247, 32], [20, 58]]</td>\n","      <td>axial_21_3</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>0.817541</td>\n","      <td>0.867484</td>\n","      <td>0.749171</td>\n","      <td>0.801418</td>\n","      <td>0.703320</td>\n","      <td>[[1147, 84], [143, 339]]</td>\n","      <td>0.773642</td>\n","      <td>0.862745</td>\n","      <td>0.662069</td>\n","      <td>0.716418</td>\n","      <td>0.615385</td>\n","      <td>[[260, 19], [30, 48]]</td>\n","      <td>axial_22_3</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>0.975010</td>\n","      <td>0.981319</td>\n","      <td>0.966597</td>\n","      <td>0.972689</td>\n","      <td>0.960581</td>\n","      <td>[[1218, 13], [19, 463]]</td>\n","      <td>0.791356</td>\n","      <td>0.854342</td>\n","      <td>0.670886</td>\n","      <td>0.662500</td>\n","      <td>0.679487</td>\n","      <td>[[252, 27], [25, 53]]</td>\n","      <td>axial_23_3</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>0.840594</td>\n","      <td>0.887916</td>\n","      <td>0.786192</td>\n","      <td>0.848558</td>\n","      <td>0.732365</td>\n","      <td>[[1168, 63], [129, 353]]</td>\n","      <td>0.777502</td>\n","      <td>0.854342</td>\n","      <td>0.657895</td>\n","      <td>0.675676</td>\n","      <td>0.641026</td>\n","      <td>[[255, 24], [28, 50]]</td>\n","      <td>axial_24_3</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1231, 0], [0, 482]]</td>\n","      <td>0.815205</td>\n","      <td>0.862745</td>\n","      <td>0.699387</td>\n","      <td>0.670588</td>\n","      <td>0.730769</td>\n","      <td>[[251, 28], [21, 57]]</td>\n","      <td>axial_25_3</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>0.949752</td>\n","      <td>0.964974</td>\n","      <td>0.936306</td>\n","      <td>0.958696</td>\n","      <td>0.914938</td>\n","      <td>[[1212, 19], [41, 441]]</td>\n","      <td>0.763372</td>\n","      <td>0.868347</td>\n","      <td>0.656934</td>\n","      <td>0.762712</td>\n","      <td>0.576923</td>\n","      <td>[[265, 14], [33, 45]]</td>\n","      <td>axial_26_3</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1231, 0], [0, 482]]</td>\n","      <td>0.762889</td>\n","      <td>0.845938</td>\n","      <td>0.635762</td>\n","      <td>0.657534</td>\n","      <td>0.615385</td>\n","      <td>[[254, 25], [30, 48]]</td>\n","      <td>axial_27_3</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>0.954576</td>\n","      <td>0.965558</td>\n","      <td>0.938220</td>\n","      <td>0.947146</td>\n","      <td>0.929461</td>\n","      <td>[[1206, 25], [34, 448]]</td>\n","      <td>0.760891</td>\n","      <td>0.806723</td>\n","      <td>0.605714</td>\n","      <td>0.546392</td>\n","      <td>0.679487</td>\n","      <td>[[235, 44], [25, 53]]</td>\n","      <td>axial_28_3</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>0.950202</td>\n","      <td>0.963806</td>\n","      <td>0.934599</td>\n","      <td>0.950644</td>\n","      <td>0.919087</td>\n","      <td>[[1208, 23], [39, 443]]</td>\n","      <td>0.793011</td>\n","      <td>0.770308</td>\n","      <td>0.613208</td>\n","      <td>0.485075</td>\n","      <td>0.833333</td>\n","      <td>[[210, 69], [13, 65]]</td>\n","      <td>axial_29_3</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>0.990889</td>\n","      <td>0.994162</td>\n","      <td>0.989562</td>\n","      <td>0.995798</td>\n","      <td>0.983402</td>\n","      <td>[[1229, 2], [8, 474]]</td>\n","      <td>0.803626</td>\n","      <td>0.887955</td>\n","      <td>0.718310</td>\n","      <td>0.796875</td>\n","      <td>0.653846</td>\n","      <td>[[266, 13], [27, 51]]</td>\n","      <td>axial_30_3</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>0.503154</td>\n","      <td>0.718458</td>\n","      <td>0.020325</td>\n","      <td>0.500000</td>\n","      <td>0.010373</td>\n","      <td>[[1225, 5], [477, 5]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_70_3</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>0.499818</td>\n","      <td>0.717290</td>\n","      <td>0.004115</td>\n","      <td>0.250000</td>\n","      <td>0.002075</td>\n","      <td>[[1227, 3], [481, 1]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_71_3</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>0.988225</td>\n","      <td>0.991238</td>\n","      <td>0.984391</td>\n","      <td>0.987474</td>\n","      <td>0.981328</td>\n","      <td>[[1224, 6], [9, 473]]</td>\n","      <td>0.584988</td>\n","      <td>0.733894</td>\n","      <td>0.344828</td>\n","      <td>0.373134</td>\n","      <td>0.320513</td>\n","      <td>[[237, 42], [53, 25]]</td>\n","      <td>axial_72_3</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>0.500982</td>\n","      <td>0.712617</td>\n","      <td>0.031496</td>\n","      <td>0.307692</td>\n","      <td>0.016598</td>\n","      <td>[[1212, 18], [474, 8]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_73_3</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>0.503743</td>\n","      <td>0.720210</td>\n","      <td>0.016427</td>\n","      <td>0.800000</td>\n","      <td>0.008299</td>\n","      <td>[[1229, 1], [478, 4]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_74_3</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>0.959166</td>\n","      <td>0.966706</td>\n","      <td>0.940933</td>\n","      <td>0.939959</td>\n","      <td>0.941909</td>\n","      <td>[[1201, 29], [28, 454]]</td>\n","      <td>0.557486</td>\n","      <td>0.770308</td>\n","      <td>0.254545</td>\n","      <td>0.437500</td>\n","      <td>0.179487</td>\n","      <td>[[261, 18], [64, 14]]</td>\n","      <td>axial_75_3</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>0.499636</td>\n","      <td>0.716121</td>\n","      <td>0.008163</td>\n","      <td>0.250000</td>\n","      <td>0.004149</td>\n","      <td>[[1224, 6], [480, 2]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_76_3</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>0.502341</td>\n","      <td>0.717290</td>\n","      <td>0.020243</td>\n","      <td>0.416667</td>\n","      <td>0.010373</td>\n","      <td>[[1223, 7], [477, 5]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_77_3</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>0.502650</td>\n","      <td>0.713201</td>\n","      <td>0.039139</td>\n","      <td>0.344828</td>\n","      <td>0.020747</td>\n","      <td>[[1211, 19], [472, 10]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_78_3</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>0.500673</td>\n","      <td>0.716706</td>\n","      <td>0.012220</td>\n","      <td>0.333333</td>\n","      <td>0.006224</td>\n","      <td>[[1224, 6], [479, 3]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_79_3</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>0.501528</td>\n","      <td>0.716121</td>\n","      <td>0.020161</td>\n","      <td>0.357143</td>\n","      <td>0.010373</td>\n","      <td>[[1221, 9], [477, 5]]</td>\n","      <td>0.500000</td>\n","      <td>0.781513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[279, 0], [78, 0]]</td>\n","      <td>axial_80_3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    train_auc  train_accuracy  train_f1score  train_precision  train_recall  \\\n","0    0.909783        0.931115       0.875527         0.890558      0.860996   \n","1    0.855654        0.891419       0.800429         0.828889      0.773859   \n","2    0.955207        0.965558       0.938349         0.945263      0.931535   \n","3    0.903696        0.930531       0.872180         0.904232      0.842324   \n","4    0.880512        0.915353       0.841876         0.887356      0.800830   \n","5    0.969417        0.977817       0.960168         0.970339      0.950207   \n","6    0.900316        0.931115       0.871460         0.917431      0.829876   \n","7    0.963418        0.973730       0.952681         0.965885      0.939834   \n","8    0.997519        0.998249       0.996885         0.997921      0.995851   \n","9    0.921019        0.944542       0.897959         0.930958      0.867220   \n","10   0.991339        0.992995       0.987552         0.987552      0.987552   \n","11   0.498725        0.710280       0.027451         0.250000      0.014523   \n","12   0.499860        0.715537       0.012170         0.272727      0.006224   \n","13   0.503154        0.718458       0.020325         0.500000      0.010373   \n","14   0.497014        0.711449       0.012000         0.166667      0.006224   \n","15   0.922494        0.943925       0.897655         0.923246      0.873444   \n","16   0.501262        0.718458       0.008230         0.500000      0.004149   \n","17   0.499636        0.716121       0.008163         0.250000      0.004149   \n","18   0.892062        0.906542       0.838057         0.818182      0.858921   \n","19   0.500897        0.716121       0.016194         0.333333      0.008299   \n","20   0.500224        0.717874       0.004124         0.333333      0.002075   \n","21   0.501080        0.717290       0.012245         0.375000      0.006224   \n","22   0.922325        0.942790       0.895966         0.917391      0.875519   \n","23   0.904690        0.932866       0.875676         0.914221      0.840249   \n","24   0.919844        0.941039       0.892667         0.915033      0.871369   \n","25   0.861791        0.898424       0.811688         0.848416      0.778008   \n","26   0.941678        0.959720       0.926361         0.953846      0.900415   \n","27   0.939466        0.955633       0.919662         0.937500      0.902490   \n","28   0.929948        0.949212       0.907545         0.930283      0.885892   \n","29   0.985790        0.987741       0.978283         0.975258      0.981328   \n","30   0.984752        0.987157       0.977226         0.975207      0.979253   \n","31   0.930442        0.946293       0.903564         0.913136      0.894191   \n","32   0.954126        0.966725       0.939937         0.955032      0.925311   \n","33   1.000000        1.000000       1.000000         1.000000      1.000000   \n","34   0.501486        0.717874       0.012270         0.428571      0.006224   \n","35   0.501528        0.716121       0.020161         0.357143      0.010373   \n","36   0.967787        0.975467       0.956159         0.962185      0.950207   \n","37   0.786240        0.838785       0.699346         0.736239      0.665975   \n","38   0.500309        0.714369       0.020040         0.294118      0.010373   \n","39   0.502341        0.717290       0.020243         0.416667      0.010373   \n","40   0.937830        0.953271       0.915789         0.929487      0.902490   \n","41   0.503967        0.719626       0.020408         0.625000      0.010373   \n","42   0.501122        0.715537       0.020121         0.333333      0.010373   \n","43   0.498458        0.712617       0.016000         0.222222      0.008299   \n","44   0.960981        0.970228       0.946708         0.953684      0.939834   \n","45   0.899410        0.925277       0.863539         0.888158      0.840249   \n","46   0.817541        0.867484       0.749171         0.801418      0.703320   \n","47   0.975010        0.981319       0.966597         0.972689      0.960581   \n","48   0.840594        0.887916       0.786192         0.848558      0.732365   \n","49   1.000000        1.000000       1.000000         1.000000      1.000000   \n","50   0.949752        0.964974       0.936306         0.958696      0.914938   \n","51   1.000000        1.000000       1.000000         1.000000      1.000000   \n","52   0.954576        0.965558       0.938220         0.947146      0.929461   \n","53   0.950202        0.963806       0.934599         0.950644      0.919087   \n","54   0.990889        0.994162       0.989562         0.995798      0.983402   \n","55   0.503154        0.718458       0.020325         0.500000      0.010373   \n","56   0.499818        0.717290       0.004115         0.250000      0.002075   \n","57   0.988225        0.991238       0.984391         0.987474      0.981328   \n","58   0.500982        0.712617       0.031496         0.307692      0.016598   \n","59   0.503743        0.720210       0.016427         0.800000      0.008299   \n","60   0.959166        0.966706       0.940933         0.939959      0.941909   \n","61   0.499636        0.716121       0.008163         0.250000      0.004149   \n","62   0.502341        0.717290       0.020243         0.416667      0.010373   \n","63   0.502650        0.713201       0.039139         0.344828      0.020747   \n","64   0.500673        0.716706       0.012220         0.333333      0.006224   \n","65   0.501528        0.716121       0.020161         0.357143      0.010373   \n","\n","               train_conf_mat  validation_auc  validation_accuracy  \\\n","0     [[1180, 51], [67, 415]]        0.828026             0.868347   \n","1    [[1154, 77], [109, 373]]        0.812862             0.887955   \n","2     [[1205, 26], [33, 449]]        0.800110             0.831933   \n","3     [[1188, 43], [76, 406]]        0.789289             0.865546   \n","4     [[1182, 49], [96, 386]]        0.752895             0.837535   \n","5     [[1217, 14], [24, 458]]        0.777985             0.876751   \n","6     [[1195, 36], [82, 400]]        0.785429             0.873950   \n","7     [[1215, 16], [29, 453]]        0.781086             0.859944   \n","8       [[1230, 1], [2, 480]]        0.810587             0.862745   \n","9     [[1200, 31], [64, 418]]        0.788599             0.806723   \n","10      [[1225, 6], [6, 476]]        0.816998             0.865546   \n","11     [[1209, 21], [475, 7]]        0.500000             0.781513   \n","12      [[1222, 8], [479, 3]]        0.500000             0.781513   \n","13      [[1225, 5], [477, 5]]        0.500000             0.781513   \n","14     [[1215, 15], [479, 3]]        0.500000             0.781513   \n","15    [[1195, 35], [61, 421]]        0.585263             0.719888   \n","16      [[1228, 2], [480, 2]]        0.500000             0.781513   \n","17      [[1224, 6], [480, 2]]        0.500000             0.781513   \n","18    [[1138, 92], [68, 414]]        0.582368             0.773109   \n","19      [[1222, 8], [478, 4]]        0.500000             0.781513   \n","20      [[1228, 2], [481, 1]]        0.500000             0.781513   \n","21      [[1225, 5], [479, 3]]        0.500000             0.781513   \n","22    [[1193, 38], [60, 422]]        0.860835             0.890756   \n","23    [[1193, 38], [77, 405]]        0.827750             0.882353   \n","24    [[1192, 39], [62, 420]]        0.826303             0.815126   \n","25   [[1164, 67], [107, 375]]        0.802867             0.879552   \n","26    [[1210, 21], [48, 434]]        0.791908             0.826331   \n","27    [[1202, 29], [47, 435]]        0.771850             0.859944   \n","28    [[1199, 32], [55, 427]]        0.783154             0.848739   \n","29     [[1219, 12], [9, 473]]        0.806245             0.848739   \n","30    [[1219, 12], [10, 472]]        0.754687             0.840336   \n","31    [[1190, 41], [51, 431]]        0.790323             0.859944   \n","32    [[1210, 21], [36, 446]]        0.803901             0.873950   \n","33      [[1230, 0], [0, 482]]        0.682175             0.770308   \n","34      [[1226, 4], [479, 3]]        0.500000             0.781513   \n","35      [[1221, 9], [477, 5]]        0.500000             0.781513   \n","36    [[1212, 18], [24, 458]]        0.581610             0.764706   \n","37  [[1115, 115], [161, 321]]        0.573683             0.745098   \n","38     [[1218, 12], [477, 5]]        0.500000             0.781513   \n","39      [[1223, 7], [477, 5]]        0.500000             0.781513   \n","40    [[1197, 33], [47, 435]]        0.624207             0.759104   \n","41      [[1227, 3], [477, 5]]        0.500000             0.781513   \n","42     [[1220, 10], [477, 5]]        0.500000             0.781513   \n","43     [[1216, 14], [478, 4]]        0.500000             0.781513   \n","44    [[1209, 22], [29, 453]]        0.849531             0.901961   \n","45    [[1180, 51], [77, 405]]        0.814447             0.854342   \n","46   [[1147, 84], [143, 339]]        0.773642             0.862745   \n","47    [[1218, 13], [19, 463]]        0.791356             0.854342   \n","48   [[1168, 63], [129, 353]]        0.777502             0.854342   \n","49      [[1231, 0], [0, 482]]        0.815205             0.862745   \n","50    [[1212, 19], [41, 441]]        0.763372             0.868347   \n","51      [[1231, 0], [0, 482]]        0.762889             0.845938   \n","52    [[1206, 25], [34, 448]]        0.760891             0.806723   \n","53    [[1208, 23], [39, 443]]        0.793011             0.770308   \n","54      [[1229, 2], [8, 474]]        0.803626             0.887955   \n","55      [[1225, 5], [477, 5]]        0.500000             0.781513   \n","56      [[1227, 3], [481, 1]]        0.500000             0.781513   \n","57      [[1224, 6], [9, 473]]        0.584988             0.733894   \n","58     [[1212, 18], [474, 8]]        0.500000             0.781513   \n","59      [[1229, 1], [478, 4]]        0.500000             0.781513   \n","60    [[1201, 29], [28, 454]]        0.557486             0.770308   \n","61      [[1224, 6], [480, 2]]        0.500000             0.781513   \n","62      [[1223, 7], [477, 5]]        0.500000             0.781513   \n","63    [[1211, 19], [472, 10]]        0.500000             0.781513   \n","64      [[1224, 6], [479, 3]]        0.500000             0.781513   \n","65      [[1221, 9], [477, 5]]        0.500000             0.781513   \n","\n","    validation_f1score  validation_precision  validation_recall  \\\n","0             0.715152              0.678161           0.756410   \n","1             0.726027              0.779412           0.679487   \n","2             0.659091              0.591837           0.743590   \n","3             0.680000              0.708333           0.653846   \n","4             0.618421              0.635135           0.602564   \n","5             0.681159              0.783333           0.602564   \n","6             0.685315              0.753846           0.628205   \n","7             0.666667              0.694444           0.641026   \n","8             0.695652              0.674699           0.717949   \n","9             0.631016              0.541284           0.756410   \n","10            0.703704              0.678571           0.730769   \n","11            0.000000              0.000000           0.000000   \n","12            0.000000              0.000000           0.000000   \n","13            0.000000              0.000000           0.000000   \n","14            0.000000              0.000000           0.000000   \n","15            0.350649              0.355263           0.346154   \n","16            0.000000              0.000000           0.000000   \n","17            0.000000              0.000000           0.000000   \n","18            0.319328              0.463415           0.243590   \n","19            0.000000              0.000000           0.000000   \n","20            0.000000              0.000000           0.000000   \n","21            0.000000              0.000000           0.000000   \n","22            0.763636              0.724138           0.807692   \n","23            0.730769              0.730769           0.730769   \n","24            0.666667              0.550000           0.846154   \n","25            0.707483              0.753623           0.666667   \n","26            0.647727              0.581633           0.730769   \n","27            0.657534              0.705882           0.615385   \n","28            0.658228              0.650000           0.666667   \n","29            0.678571              0.633333           0.730769   \n","30            0.622517              0.643836           0.602564   \n","31            0.675325              0.684211           0.666667   \n","32            0.701987              0.726027           0.679487   \n","33            0.500000              0.476744           0.525641   \n","34            0.000000              0.000000           0.000000   \n","35            0.000000              0.000000           0.000000   \n","36            0.322581              0.434783           0.256410   \n","37            0.315789              0.381818           0.269231   \n","38            0.000000              0.000000           0.000000   \n","39            0.000000              0.000000           0.000000   \n","40            0.410959              0.441176           0.384615   \n","41            0.000000              0.000000           0.000000   \n","42            0.000000              0.000000           0.000000   \n","43            0.000000              0.000000           0.000000   \n","44            0.771242              0.786667           0.756410   \n","45            0.690476              0.644444           0.743590   \n","46            0.662069              0.716418           0.615385   \n","47            0.670886              0.662500           0.679487   \n","48            0.657895              0.675676           0.641026   \n","49            0.699387              0.670588           0.730769   \n","50            0.656934              0.762712           0.576923   \n","51            0.635762              0.657534           0.615385   \n","52            0.605714              0.546392           0.679487   \n","53            0.613208              0.485075           0.833333   \n","54            0.718310              0.796875           0.653846   \n","55            0.000000              0.000000           0.000000   \n","56            0.000000              0.000000           0.000000   \n","57            0.344828              0.373134           0.320513   \n","58            0.000000              0.000000           0.000000   \n","59            0.000000              0.000000           0.000000   \n","60            0.254545              0.437500           0.179487   \n","61            0.000000              0.000000           0.000000   \n","62            0.000000              0.000000           0.000000   \n","63            0.000000              0.000000           0.000000   \n","64            0.000000              0.000000           0.000000   \n","65            0.000000              0.000000           0.000000   \n","\n","      validation_conf_mat      RUN_ID  \n","0   [[251, 28], [19, 59]]  axial_20_1  \n","1   [[264, 15], [25, 53]]  axial_21_1  \n","2   [[239, 40], [20, 58]]  axial_22_1  \n","3   [[258, 21], [27, 51]]  axial_23_1  \n","4   [[252, 27], [31, 47]]  axial_24_1  \n","5   [[266, 13], [31, 47]]  axial_25_1  \n","6   [[263, 16], [29, 49]]  axial_26_1  \n","7   [[257, 22], [28, 50]]  axial_27_1  \n","8   [[252, 27], [22, 56]]  axial_28_1  \n","9   [[229, 50], [19, 59]]  axial_29_1  \n","10  [[252, 27], [21, 57]]  axial_30_1  \n","11    [[279, 0], [78, 0]]  axial_70_1  \n","12    [[279, 0], [78, 0]]  axial_71_1  \n","13    [[279, 0], [78, 0]]  axial_72_1  \n","14    [[279, 0], [78, 0]]  axial_73_1  \n","15  [[230, 49], [51, 27]]  axial_74_1  \n","16    [[279, 0], [78, 0]]  axial_75_1  \n","17    [[279, 0], [78, 0]]  axial_76_1  \n","18  [[257, 22], [59, 19]]  axial_77_1  \n","19    [[279, 0], [78, 0]]  axial_78_1  \n","20    [[279, 0], [78, 0]]  axial_79_1  \n","21    [[279, 0], [78, 0]]  axial_80_1  \n","22  [[255, 24], [15, 63]]  axial_20_2  \n","23  [[258, 21], [21, 57]]  axial_21_2  \n","24  [[225, 54], [12, 66]]  axial_22_2  \n","25  [[262, 17], [26, 52]]  axial_23_2  \n","26  [[238, 41], [21, 57]]  axial_24_2  \n","27  [[259, 20], [30, 48]]  axial_25_2  \n","28  [[251, 28], [26, 52]]  axial_26_2  \n","29  [[246, 33], [21, 57]]  axial_27_2  \n","30  [[253, 26], [31, 47]]  axial_28_2  \n","31  [[255, 24], [26, 52]]  axial_29_2  \n","32  [[259, 20], [25, 53]]  axial_30_2  \n","33  [[234, 45], [37, 41]]  axial_70_2  \n","34    [[279, 0], [78, 0]]  axial_71_2  \n","35    [[279, 0], [78, 0]]  axial_72_2  \n","36  [[253, 26], [58, 20]]  axial_73_2  \n","37  [[245, 34], [57, 21]]  axial_74_2  \n","38    [[279, 0], [78, 0]]  axial_75_2  \n","39    [[279, 0], [78, 0]]  axial_76_2  \n","40  [[241, 38], [48, 30]]  axial_77_2  \n","41    [[279, 0], [78, 0]]  axial_78_2  \n","42    [[279, 0], [78, 0]]  axial_79_2  \n","43    [[279, 0], [78, 0]]  axial_80_2  \n","44  [[263, 16], [19, 59]]  axial_20_3  \n","45  [[247, 32], [20, 58]]  axial_21_3  \n","46  [[260, 19], [30, 48]]  axial_22_3  \n","47  [[252, 27], [25, 53]]  axial_23_3  \n","48  [[255, 24], [28, 50]]  axial_24_3  \n","49  [[251, 28], [21, 57]]  axial_25_3  \n","50  [[265, 14], [33, 45]]  axial_26_3  \n","51  [[254, 25], [30, 48]]  axial_27_3  \n","52  [[235, 44], [25, 53]]  axial_28_3  \n","53  [[210, 69], [13, 65]]  axial_29_3  \n","54  [[266, 13], [27, 51]]  axial_30_3  \n","55    [[279, 0], [78, 0]]  axial_70_3  \n","56    [[279, 0], [78, 0]]  axial_71_3  \n","57  [[237, 42], [53, 25]]  axial_72_3  \n","58    [[279, 0], [78, 0]]  axial_73_3  \n","59    [[279, 0], [78, 0]]  axial_74_3  \n","60  [[261, 18], [64, 14]]  axial_75_3  \n","61    [[279, 0], [78, 0]]  axial_76_3  \n","62    [[279, 0], [78, 0]]  axial_77_3  \n","63    [[279, 0], [78, 0]]  axial_78_3  \n","64    [[279, 0], [78, 0]]  axial_79_3  \n","65    [[279, 0], [78, 0]]  axial_80_3  "]},"metadata":{},"execution_count":142}]},{"cell_type":"markdown","metadata":{"id":"ZcBlYtZbwRLy"},"source":["## Sagittal 20-30 + 70-80"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1HkSnqsZp2ARTzWKlAjJQ8qIOAxeJrDlX"},"id":"QMQtumyJwRLy","executionInfo":{"status":"ok","timestamp":1634144171289,"user_tz":180,"elapsed":600085,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"79f3228f-fa29-4f72-d831-c6eff97b09be"},"source":["df_results_sagittal = run_mris_experiments(orientation = 'sagittal',\n","                          slices = list(range(20,31)) + list(range(70,81)),\n","                          num_repeats = 3,\n","                          model='vgg11',\n","                          classes=['AD','CN'],\n","                          save_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/data/RESULTS_SAGITTAL_VGG11.csv')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"36OY3NwvnADx"},"source":["df_results_sagittal_backup = df_results_sagittal.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rnnk3KYvwRLz"},"source":["df_results_sagittal['ORIENTATION'] = 'sagittal'\n","df_results_sagittal['SLICE'] = [x.split('_')[1] for x in df_results_sagittal['RUN_ID']]\n","df = df_results_sagittal.groupby(['ORIENTATION','SLICE'])[['train_auc','validation_auc','train_f1score','validation_f1score']].aggregate([np.mean,np.std])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":790},"id":"Wq2-xc3snooV","executionInfo":{"status":"ok","timestamp":1634145491115,"user_tz":180,"elapsed":258,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"7997f40c-3150-40d9-bd02-e705712cab6a"},"source":["df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th colspan=\"2\" halign=\"left\">train_auc</th>\n","      <th colspan=\"2\" halign=\"left\">validation_auc</th>\n","      <th colspan=\"2\" halign=\"left\">train_f1score</th>\n","      <th colspan=\"2\" halign=\"left\">validation_f1score</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>mean</th>\n","      <th>std</th>\n","    </tr>\n","    <tr>\n","      <th>ORIENTATION</th>\n","      <th>SLICE</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"22\" valign=\"top\">sagittal</th>\n","      <th>20</th>\n","      <td>0.875547</td>\n","      <td>0.108449</td>\n","      <td>0.747771</td>\n","      <td>0.032457</td>\n","      <td>0.826013</td>\n","      <td>0.152356</td>\n","      <td>0.606786</td>\n","      <td>0.041139</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0.945179</td>\n","      <td>0.017701</td>\n","      <td>0.786417</td>\n","      <td>0.022068</td>\n","      <td>0.927433</td>\n","      <td>0.023921</td>\n","      <td>0.652821</td>\n","      <td>0.023795</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0.941932</td>\n","      <td>0.018227</td>\n","      <td>0.815343</td>\n","      <td>0.032972</td>\n","      <td>0.923657</td>\n","      <td>0.023884</td>\n","      <td>0.665979</td>\n","      <td>0.043269</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0.903834</td>\n","      <td>0.036035</td>\n","      <td>0.836159</td>\n","      <td>0.012778</td>\n","      <td>0.875324</td>\n","      <td>0.045795</td>\n","      <td>0.714976</td>\n","      <td>0.028415</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0.899364</td>\n","      <td>0.019891</td>\n","      <td>0.836941</td>\n","      <td>0.023183</td>\n","      <td>0.862147</td>\n","      <td>0.026770</td>\n","      <td>0.705944</td>\n","      <td>0.017367</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0.864634</td>\n","      <td>0.012590</td>\n","      <td>0.815504</td>\n","      <td>0.011341</td>\n","      <td>0.818023</td>\n","      <td>0.021338</td>\n","      <td>0.672255</td>\n","      <td>0.015782</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0.855493</td>\n","      <td>0.051036</td>\n","      <td>0.864305</td>\n","      <td>0.019093</td>\n","      <td>0.805354</td>\n","      <td>0.068968</td>\n","      <td>0.726807</td>\n","      <td>0.026971</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>0.945209</td>\n","      <td>0.013822</td>\n","      <td>0.863432</td>\n","      <td>0.039821</td>\n","      <td>0.925765</td>\n","      <td>0.019886</td>\n","      <td>0.740370</td>\n","      <td>0.058345</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0.911408</td>\n","      <td>0.089183</td>\n","      <td>0.832483</td>\n","      <td>0.015126</td>\n","      <td>0.876999</td>\n","      <td>0.124129</td>\n","      <td>0.711872</td>\n","      <td>0.035771</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>0.930203</td>\n","      <td>0.015737</td>\n","      <td>0.808083</td>\n","      <td>0.025621</td>\n","      <td>0.905076</td>\n","      <td>0.021417</td>\n","      <td>0.657708</td>\n","      <td>0.047970</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>0.982167</td>\n","      <td>0.023946</td>\n","      <td>0.810266</td>\n","      <td>0.028212</td>\n","      <td>0.976285</td>\n","      <td>0.033002</td>\n","      <td>0.682058</td>\n","      <td>0.047137</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>0.875009</td>\n","      <td>0.086230</td>\n","      <td>0.819226</td>\n","      <td>0.011992</td>\n","      <td>0.831117</td>\n","      <td>0.122256</td>\n","      <td>0.701749</td>\n","      <td>0.016287</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>0.948052</td>\n","      <td>0.028390</td>\n","      <td>0.817158</td>\n","      <td>0.010627</td>\n","      <td>0.932333</td>\n","      <td>0.036947</td>\n","      <td>0.713416</td>\n","      <td>0.034864</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>0.918011</td>\n","      <td>0.005617</td>\n","      <td>0.832116</td>\n","      <td>0.014491</td>\n","      <td>0.892541</td>\n","      <td>0.008248</td>\n","      <td>0.731257</td>\n","      <td>0.029027</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>0.818445</td>\n","      <td>0.055136</td>\n","      <td>0.833218</td>\n","      <td>0.004602</td>\n","      <td>0.750750</td>\n","      <td>0.080547</td>\n","      <td>0.741274</td>\n","      <td>0.031247</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>0.942203</td>\n","      <td>0.017935</td>\n","      <td>0.828554</td>\n","      <td>0.019852</td>\n","      <td>0.924381</td>\n","      <td>0.025178</td>\n","      <td>0.705673</td>\n","      <td>0.040200</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>0.909427</td>\n","      <td>0.084895</td>\n","      <td>0.825108</td>\n","      <td>0.009643</td>\n","      <td>0.879816</td>\n","      <td>0.115054</td>\n","      <td>0.722623</td>\n","      <td>0.026488</td>\n","    </tr>\n","    <tr>\n","      <th>76</th>\n","      <td>0.829570</td>\n","      <td>0.047175</td>\n","      <td>0.850060</td>\n","      <td>0.007789</td>\n","      <td>0.766538</td>\n","      <td>0.066473</td>\n","      <td>0.756775</td>\n","      <td>0.005975</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>0.916340</td>\n","      <td>0.017908</td>\n","      <td>0.815734</td>\n","      <td>0.013201</td>\n","      <td>0.887341</td>\n","      <td>0.025274</td>\n","      <td>0.688898</td>\n","      <td>0.019889</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>0.934775</td>\n","      <td>0.012021</td>\n","      <td>0.806498</td>\n","      <td>0.018526</td>\n","      <td>0.913686</td>\n","      <td>0.014124</td>\n","      <td>0.683630</td>\n","      <td>0.045281</td>\n","    </tr>\n","    <tr>\n","      <th>79</th>\n","      <td>0.852727</td>\n","      <td>0.096545</td>\n","      <td>0.804866</td>\n","      <td>0.012793</td>\n","      <td>0.799051</td>\n","      <td>0.138091</td>\n","      <td>0.686516</td>\n","      <td>0.030063</td>\n","    </tr>\n","    <tr>\n","      <th>80</th>\n","      <td>0.781419</td>\n","      <td>0.174752</td>\n","      <td>0.779777</td>\n","      <td>0.016405</td>\n","      <td>0.682704</td>\n","      <td>0.254324</td>\n","      <td>0.686131</td>\n","      <td>0.029197</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  train_auc           validation_auc           train_f1score  \\\n","                       mean       std           mean       std          mean   \n","ORIENTATION SLICE                                                              \n","sagittal    20     0.875547  0.108449       0.747771  0.032457      0.826013   \n","            21     0.945179  0.017701       0.786417  0.022068      0.927433   \n","            22     0.941932  0.018227       0.815343  0.032972      0.923657   \n","            23     0.903834  0.036035       0.836159  0.012778      0.875324   \n","            24     0.899364  0.019891       0.836941  0.023183      0.862147   \n","            25     0.864634  0.012590       0.815504  0.011341      0.818023   \n","            26     0.855493  0.051036       0.864305  0.019093      0.805354   \n","            27     0.945209  0.013822       0.863432  0.039821      0.925765   \n","            28     0.911408  0.089183       0.832483  0.015126      0.876999   \n","            29     0.930203  0.015737       0.808083  0.025621      0.905076   \n","            30     0.982167  0.023946       0.810266  0.028212      0.976285   \n","            70     0.875009  0.086230       0.819226  0.011992      0.831117   \n","            71     0.948052  0.028390       0.817158  0.010627      0.932333   \n","            72     0.918011  0.005617       0.832116  0.014491      0.892541   \n","            73     0.818445  0.055136       0.833218  0.004602      0.750750   \n","            74     0.942203  0.017935       0.828554  0.019852      0.924381   \n","            75     0.909427  0.084895       0.825108  0.009643      0.879816   \n","            76     0.829570  0.047175       0.850060  0.007789      0.766538   \n","            77     0.916340  0.017908       0.815734  0.013201      0.887341   \n","            78     0.934775  0.012021       0.806498  0.018526      0.913686   \n","            79     0.852727  0.096545       0.804866  0.012793      0.799051   \n","            80     0.781419  0.174752       0.779777  0.016405      0.682704   \n","\n","                            validation_f1score            \n","                        std               mean       std  \n","ORIENTATION SLICE                                         \n","sagittal    20     0.152356           0.606786  0.041139  \n","            21     0.023921           0.652821  0.023795  \n","            22     0.023884           0.665979  0.043269  \n","            23     0.045795           0.714976  0.028415  \n","            24     0.026770           0.705944  0.017367  \n","            25     0.021338           0.672255  0.015782  \n","            26     0.068968           0.726807  0.026971  \n","            27     0.019886           0.740370  0.058345  \n","            28     0.124129           0.711872  0.035771  \n","            29     0.021417           0.657708  0.047970  \n","            30     0.033002           0.682058  0.047137  \n","            70     0.122256           0.701749  0.016287  \n","            71     0.036947           0.713416  0.034864  \n","            72     0.008248           0.731257  0.029027  \n","            73     0.080547           0.741274  0.031247  \n","            74     0.025178           0.705673  0.040200  \n","            75     0.115054           0.722623  0.026488  \n","            76     0.066473           0.756775  0.005975  \n","            77     0.025274           0.688898  0.019889  \n","            78     0.014124           0.683630  0.045281  \n","            79     0.138091           0.686516  0.030063  \n","            80     0.254324           0.686131  0.029197  "]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","metadata":{"id":"CgopPRzExBOh"},"source":["# Training Super Shallow CNN (Less convolutions and less neurons) (GPU) - 13/10/2021"]},{"cell_type":"markdown","metadata":{"id":"JifyfMO_xBOi"},"source":["## Coronal - 45~55"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"12rwMWz6QIHM21gIJw85eMuKaOVfsvmBa"},"id":"dieKnsaZxBOi","executionInfo":{"status":"ok","timestamp":1634155767536,"user_tz":180,"elapsed":28010,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"00bc0f61-f46d-4ec5-bc79-c815add567d8"},"source":["df_results_coronal = run_mris_experiments(orientation = 'coronal',\n","                          slices = list(range(45,56)),\n","                          num_repeats = 3,\n","                          model='super_shallow_cnn',\n","                          classes=['AD','CN'],\n","                          save_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/data/RESULTS_CORONAL_SUPER_SHALLOW_CNN.csv')"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"ytXi-zbpxBOj","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1634155767575,"user_tz":180,"elapsed":9,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"da8b64ca-f6ed-4572-ec39-e30ca50d7c18"},"source":["df_results_coronal"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>train_auc</th>\n","      <th>train_accuracy</th>\n","      <th>train_f1score</th>\n","      <th>train_precision</th>\n","      <th>train_recall</th>\n","      <th>train_conf_mat</th>\n","      <th>validation_auc</th>\n","      <th>validation_accuracy</th>\n","      <th>validation_f1score</th>\n","      <th>validation_precision</th>\n","      <th>validation_recall</th>\n","      <th>validation_conf_mat</th>\n","      <th>RUN_ID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.952095</td>\n","      <td>0.963806</td>\n","      <td>0.935010</td>\n","      <td>0.944915</td>\n","      <td>0.925311</td>\n","      <td>[[1205, 26], [36, 446]]</td>\n","      <td>0.806245</td>\n","      <td>0.848739</td>\n","      <td>0.678571</td>\n","      <td>0.633333</td>\n","      <td>0.730769</td>\n","      <td>[[246, 33], [21, 57]]</td>\n","      <td>coronal_45_1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.944246</td>\n","      <td>0.957968</td>\n","      <td>0.924370</td>\n","      <td>0.936170</td>\n","      <td>0.912863</td>\n","      <td>[[1201, 30], [42, 440]]</td>\n","      <td>0.780052</td>\n","      <td>0.865546</td>\n","      <td>0.671233</td>\n","      <td>0.720588</td>\n","      <td>0.628205</td>\n","      <td>[[260, 19], [29, 49]]</td>\n","      <td>coronal_46_1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.955569</td>\n","      <td>0.967893</td>\n","      <td>0.942044</td>\n","      <td>0.957173</td>\n","      <td>0.927386</td>\n","      <td>[[1211, 20], [35, 447]]</td>\n","      <td>0.802178</td>\n","      <td>0.820728</td>\n","      <td>0.652174</td>\n","      <td>0.566038</td>\n","      <td>0.769231</td>\n","      <td>[[233, 46], [18, 60]]</td>\n","      <td>coronal_47_1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.948171</td>\n","      <td>0.960887</td>\n","      <td>0.929696</td>\n","      <td>0.940552</td>\n","      <td>0.919087</td>\n","      <td>[[1203, 28], [39, 443]]</td>\n","      <td>0.775986</td>\n","      <td>0.837535</td>\n","      <td>0.641975</td>\n","      <td>0.619048</td>\n","      <td>0.666667</td>\n","      <td>[[247, 32], [26, 52]]</td>\n","      <td>coronal_48_1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.970455</td>\n","      <td>0.978400</td>\n","      <td>0.961257</td>\n","      <td>0.970402</td>\n","      <td>0.952282</td>\n","      <td>[[1217, 14], [23, 459]]</td>\n","      <td>0.769300</td>\n","      <td>0.848739</td>\n","      <td>0.644737</td>\n","      <td>0.662162</td>\n","      <td>0.628205</td>\n","      <td>[[254, 25], [29, 49]]</td>\n","      <td>coronal_49_1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.977672</td>\n","      <td>0.984238</td>\n","      <td>0.971728</td>\n","      <td>0.980973</td>\n","      <td>0.962656</td>\n","      <td>[[1222, 9], [18, 464]]</td>\n","      <td>0.776468</td>\n","      <td>0.859944</td>\n","      <td>0.662162</td>\n","      <td>0.700000</td>\n","      <td>0.628205</td>\n","      <td>[[258, 21], [29, 49]]</td>\n","      <td>coronal_50_1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.938066</td>\n","      <td>0.952715</td>\n","      <td>0.915005</td>\n","      <td>0.925690</td>\n","      <td>0.904564</td>\n","      <td>[[1196, 35], [46, 436]]</td>\n","      <td>0.769300</td>\n","      <td>0.848739</td>\n","      <td>0.644737</td>\n","      <td>0.662162</td>\n","      <td>0.628205</td>\n","      <td>[[254, 25], [29, 49]]</td>\n","      <td>coronal_51_1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.964862</td>\n","      <td>0.974898</td>\n","      <td>0.954784</td>\n","      <td>0.968017</td>\n","      <td>0.941909</td>\n","      <td>[[1216, 15], [28, 454]]</td>\n","      <td>0.705749</td>\n","      <td>0.792717</td>\n","      <td>0.537500</td>\n","      <td>0.524390</td>\n","      <td>0.551282</td>\n","      <td>[[240, 39], [35, 43]]</td>\n","      <td>coronal_52_1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.836669</td>\n","      <td>0.884997</td>\n","      <td>0.780379</td>\n","      <td>0.843373</td>\n","      <td>0.726141</td>\n","      <td>[[1166, 65], [132, 350]]</td>\n","      <td>0.735939</td>\n","      <td>0.854342</td>\n","      <td>0.611940</td>\n","      <td>0.732143</td>\n","      <td>0.525641</td>\n","      <td>[[264, 15], [37, 41]]</td>\n","      <td>coronal_53_1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.958906</td>\n","      <td>0.969060</td>\n","      <td>0.944503</td>\n","      <td>0.953488</td>\n","      <td>0.935685</td>\n","      <td>[[1209, 22], [31, 451]]</td>\n","      <td>0.711607</td>\n","      <td>0.823529</td>\n","      <td>0.559441</td>\n","      <td>0.615385</td>\n","      <td>0.512821</td>\n","      <td>[[254, 25], [38, 40]]</td>\n","      <td>coronal_54_1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.974785</td>\n","      <td>0.981903</td>\n","      <td>0.967539</td>\n","      <td>0.976744</td>\n","      <td>0.958506</td>\n","      <td>[[1220, 11], [20, 462]]</td>\n","      <td>0.736766</td>\n","      <td>0.812325</td>\n","      <td>0.583851</td>\n","      <td>0.566265</td>\n","      <td>0.602564</td>\n","      <td>[[243, 36], [31, 47]]</td>\n","      <td>coronal_55_1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.984977</td>\n","      <td>0.986573</td>\n","      <td>0.976264</td>\n","      <td>0.971253</td>\n","      <td>0.981328</td>\n","      <td>[[1217, 14], [9, 473]]</td>\n","      <td>0.768817</td>\n","      <td>0.826331</td>\n","      <td>0.626506</td>\n","      <td>0.590909</td>\n","      <td>0.666667</td>\n","      <td>[[243, 36], [26, 52]]</td>\n","      <td>coronal_45_2</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.959494</td>\n","      <td>0.970811</td>\n","      <td>0.947368</td>\n","      <td>0.961538</td>\n","      <td>0.933610</td>\n","      <td>[[1213, 18], [32, 450]]</td>\n","      <td>0.763165</td>\n","      <td>0.831933</td>\n","      <td>0.625000</td>\n","      <td>0.609756</td>\n","      <td>0.641026</td>\n","      <td>[[247, 32], [28, 50]]</td>\n","      <td>coronal_46_2</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.971492</td>\n","      <td>0.978984</td>\n","      <td>0.962343</td>\n","      <td>0.970464</td>\n","      <td>0.954357</td>\n","      <td>[[1217, 14], [22, 460]]</td>\n","      <td>0.738282</td>\n","      <td>0.829132</td>\n","      <td>0.596026</td>\n","      <td>0.616438</td>\n","      <td>0.576923</td>\n","      <td>[[251, 28], [33, 45]]</td>\n","      <td>coronal_47_2</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.976410</td>\n","      <td>0.984238</td>\n","      <td>0.971609</td>\n","      <td>0.985075</td>\n","      <td>0.958506</td>\n","      <td>[[1224, 7], [20, 462]]</td>\n","      <td>0.790874</td>\n","      <td>0.831933</td>\n","      <td>0.651163</td>\n","      <td>0.595745</td>\n","      <td>0.717949</td>\n","      <td>[[241, 38], [22, 56]]</td>\n","      <td>coronal_48_2</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.985746</td>\n","      <td>0.989492</td>\n","      <td>0.981250</td>\n","      <td>0.985356</td>\n","      <td>0.977178</td>\n","      <td>[[1224, 7], [11, 471]]</td>\n","      <td>0.751654</td>\n","      <td>0.806723</td>\n","      <td>0.596491</td>\n","      <td>0.548387</td>\n","      <td>0.653846</td>\n","      <td>[[237, 42], [27, 51]]</td>\n","      <td>coronal_49_2</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.954757</td>\n","      <td>0.966725</td>\n","      <td>0.940063</td>\n","      <td>0.953092</td>\n","      <td>0.927386</td>\n","      <td>[[1209, 22], [35, 447]]</td>\n","      <td>0.739592</td>\n","      <td>0.809524</td>\n","      <td>0.585366</td>\n","      <td>0.558140</td>\n","      <td>0.615385</td>\n","      <td>[[241, 38], [30, 48]]</td>\n","      <td>coronal_50_2</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.979385</td>\n","      <td>0.983071</td>\n","      <td>0.969948</td>\n","      <td>0.968944</td>\n","      <td>0.970954</td>\n","      <td>[[1216, 15], [14, 468]]</td>\n","      <td>0.746485</td>\n","      <td>0.834734</td>\n","      <td>0.609272</td>\n","      <td>0.630137</td>\n","      <td>0.589744</td>\n","      <td>[[252, 27], [32, 46]]</td>\n","      <td>coronal_51_2</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.955569</td>\n","      <td>0.967893</td>\n","      <td>0.942044</td>\n","      <td>0.957173</td>\n","      <td>0.927386</td>\n","      <td>[[1211, 20], [35, 447]]</td>\n","      <td>0.791356</td>\n","      <td>0.854342</td>\n","      <td>0.670886</td>\n","      <td>0.662500</td>\n","      <td>0.679487</td>\n","      <td>[[252, 27], [25, 53]]</td>\n","      <td>coronal_52_2</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.946052</td>\n","      <td>0.961471</td>\n","      <td>0.930085</td>\n","      <td>0.950216</td>\n","      <td>0.910788</td>\n","      <td>[[1208, 23], [43, 439]]</td>\n","      <td>0.743383</td>\n","      <td>0.851541</td>\n","      <td>0.618705</td>\n","      <td>0.704918</td>\n","      <td>0.551282</td>\n","      <td>[[261, 18], [35, 43]]</td>\n","      <td>coronal_53_2</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>0.997519</td>\n","      <td>0.998249</td>\n","      <td>0.996885</td>\n","      <td>0.997921</td>\n","      <td>0.995851</td>\n","      <td>[[1230, 1], [2, 480]]</td>\n","      <td>0.729804</td>\n","      <td>0.837535</td>\n","      <td>0.591549</td>\n","      <td>0.656250</td>\n","      <td>0.538462</td>\n","      <td>[[257, 22], [36, 42]]</td>\n","      <td>coronal_54_2</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0.979972</td>\n","      <td>0.984822</td>\n","      <td>0.972917</td>\n","      <td>0.976987</td>\n","      <td>0.968880</td>\n","      <td>[[1220, 11], [15, 467]]</td>\n","      <td>0.785429</td>\n","      <td>0.873950</td>\n","      <td>0.685315</td>\n","      <td>0.753846</td>\n","      <td>0.628205</td>\n","      <td>[[263, 16], [29, 49]]</td>\n","      <td>coronal_55_2</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0.914207</td>\n","      <td>0.939288</td>\n","      <td>0.888172</td>\n","      <td>0.921875</td>\n","      <td>0.856846</td>\n","      <td>[[1196, 35], [69, 413]]</td>\n","      <td>0.765164</td>\n","      <td>0.871148</td>\n","      <td>0.661765</td>\n","      <td>0.775862</td>\n","      <td>0.576923</td>\n","      <td>[[266, 13], [33, 45]]</td>\n","      <td>coronal_45_3</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0.975554</td>\n","      <td>0.984822</td>\n","      <td>0.972516</td>\n","      <td>0.991379</td>\n","      <td>0.954357</td>\n","      <td>[[1227, 4], [22, 460]]</td>\n","      <td>0.804453</td>\n","      <td>0.845938</td>\n","      <td>0.674556</td>\n","      <td>0.626374</td>\n","      <td>0.730769</td>\n","      <td>[[245, 34], [21, 57]]</td>\n","      <td>coronal_46_3</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0.966893</td>\n","      <td>0.977817</td>\n","      <td>0.959831</td>\n","      <td>0.978448</td>\n","      <td>0.941909</td>\n","      <td>[[1221, 10], [28, 454]]</td>\n","      <td>0.762338</td>\n","      <td>0.873950</td>\n","      <td>0.661654</td>\n","      <td>0.800000</td>\n","      <td>0.564103</td>\n","      <td>[[268, 11], [34, 44]]</td>\n","      <td>coronal_47_3</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0.914251</td>\n","      <td>0.937536</td>\n","      <td>0.885806</td>\n","      <td>0.912088</td>\n","      <td>0.860996</td>\n","      <td>[[1191, 40], [67, 415]]</td>\n","      <td>0.783361</td>\n","      <td>0.885154</td>\n","      <td>0.696296</td>\n","      <td>0.824561</td>\n","      <td>0.602564</td>\n","      <td>[[269, 10], [31, 47]]</td>\n","      <td>coronal_48_3</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0.938791</td>\n","      <td>0.957385</td>\n","      <td>0.922092</td>\n","      <td>0.949451</td>\n","      <td>0.896266</td>\n","      <td>[[1208, 23], [50, 432]]</td>\n","      <td>0.769300</td>\n","      <td>0.848739</td>\n","      <td>0.644737</td>\n","      <td>0.662162</td>\n","      <td>0.628205</td>\n","      <td>[[254, 25], [29, 49]]</td>\n","      <td>coronal_49_3</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>0.975010</td>\n","      <td>0.981319</td>\n","      <td>0.966597</td>\n","      <td>0.972689</td>\n","      <td>0.960581</td>\n","      <td>[[1218, 13], [19, 463]]</td>\n","      <td>0.742349</td>\n","      <td>0.857143</td>\n","      <td>0.622222</td>\n","      <td>0.736842</td>\n","      <td>0.538462</td>\n","      <td>[[264, 15], [36, 42]]</td>\n","      <td>coronal_50_3</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0.967524</td>\n","      <td>0.977817</td>\n","      <td>0.959916</td>\n","      <td>0.976395</td>\n","      <td>0.943983</td>\n","      <td>[[1220, 11], [27, 455]]</td>\n","      <td>0.774469</td>\n","      <td>0.820728</td>\n","      <td>0.627907</td>\n","      <td>0.574468</td>\n","      <td>0.692308</td>\n","      <td>[[239, 40], [24, 54]]</td>\n","      <td>coronal_51_3</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>0.968605</td>\n","      <td>0.976649</td>\n","      <td>0.958159</td>\n","      <td>0.966245</td>\n","      <td>0.950207</td>\n","      <td>[[1215, 16], [24, 458]]</td>\n","      <td>0.761856</td>\n","      <td>0.851541</td>\n","      <td>0.639456</td>\n","      <td>0.681159</td>\n","      <td>0.602564</td>\n","      <td>[[257, 22], [31, 47]]</td>\n","      <td>coronal_52_3</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>0.938022</td>\n","      <td>0.954466</td>\n","      <td>0.917548</td>\n","      <td>0.935345</td>\n","      <td>0.900415</td>\n","      <td>[[1201, 30], [48, 434]]</td>\n","      <td>0.806245</td>\n","      <td>0.848739</td>\n","      <td>0.678571</td>\n","      <td>0.633333</td>\n","      <td>0.730769</td>\n","      <td>[[246, 33], [21, 57]]</td>\n","      <td>coronal_53_3</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>0.976679</td>\n","      <td>0.981903</td>\n","      <td>0.967742</td>\n","      <td>0.970772</td>\n","      <td>0.964730</td>\n","      <td>[[1217, 14], [17, 465]]</td>\n","      <td>0.777985</td>\n","      <td>0.876751</td>\n","      <td>0.681159</td>\n","      <td>0.783333</td>\n","      <td>0.602564</td>\n","      <td>[[266, 13], [31, 47]]</td>\n","      <td>coronal_54_3</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>0.973117</td>\n","      <td>0.981319</td>\n","      <td>0.966387</td>\n","      <td>0.978723</td>\n","      <td>0.954357</td>\n","      <td>[[1221, 10], [22, 460]]</td>\n","      <td>0.767783</td>\n","      <td>0.831933</td>\n","      <td>0.629630</td>\n","      <td>0.607143</td>\n","      <td>0.653846</td>\n","      <td>[[246, 33], [27, 51]]</td>\n","      <td>coronal_55_3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    train_auc  train_accuracy  train_f1score  train_precision  train_recall  \\\n","0    0.952095        0.963806       0.935010         0.944915      0.925311   \n","1    0.944246        0.957968       0.924370         0.936170      0.912863   \n","2    0.955569        0.967893       0.942044         0.957173      0.927386   \n","3    0.948171        0.960887       0.929696         0.940552      0.919087   \n","4    0.970455        0.978400       0.961257         0.970402      0.952282   \n","5    0.977672        0.984238       0.971728         0.980973      0.962656   \n","6    0.938066        0.952715       0.915005         0.925690      0.904564   \n","7    0.964862        0.974898       0.954784         0.968017      0.941909   \n","8    0.836669        0.884997       0.780379         0.843373      0.726141   \n","9    0.958906        0.969060       0.944503         0.953488      0.935685   \n","10   0.974785        0.981903       0.967539         0.976744      0.958506   \n","11   0.984977        0.986573       0.976264         0.971253      0.981328   \n","12   0.959494        0.970811       0.947368         0.961538      0.933610   \n","13   0.971492        0.978984       0.962343         0.970464      0.954357   \n","14   0.976410        0.984238       0.971609         0.985075      0.958506   \n","15   0.985746        0.989492       0.981250         0.985356      0.977178   \n","16   0.954757        0.966725       0.940063         0.953092      0.927386   \n","17   0.979385        0.983071       0.969948         0.968944      0.970954   \n","18   0.955569        0.967893       0.942044         0.957173      0.927386   \n","19   0.946052        0.961471       0.930085         0.950216      0.910788   \n","20   0.997519        0.998249       0.996885         0.997921      0.995851   \n","21   0.979972        0.984822       0.972917         0.976987      0.968880   \n","22   0.914207        0.939288       0.888172         0.921875      0.856846   \n","23   0.975554        0.984822       0.972516         0.991379      0.954357   \n","24   0.966893        0.977817       0.959831         0.978448      0.941909   \n","25   0.914251        0.937536       0.885806         0.912088      0.860996   \n","26   0.938791        0.957385       0.922092         0.949451      0.896266   \n","27   0.975010        0.981319       0.966597         0.972689      0.960581   \n","28   0.967524        0.977817       0.959916         0.976395      0.943983   \n","29   0.968605        0.976649       0.958159         0.966245      0.950207   \n","30   0.938022        0.954466       0.917548         0.935345      0.900415   \n","31   0.976679        0.981903       0.967742         0.970772      0.964730   \n","32   0.973117        0.981319       0.966387         0.978723      0.954357   \n","\n","              train_conf_mat  validation_auc  validation_accuracy  \\\n","0    [[1205, 26], [36, 446]]        0.806245             0.848739   \n","1    [[1201, 30], [42, 440]]        0.780052             0.865546   \n","2    [[1211, 20], [35, 447]]        0.802178             0.820728   \n","3    [[1203, 28], [39, 443]]        0.775986             0.837535   \n","4    [[1217, 14], [23, 459]]        0.769300             0.848739   \n","5     [[1222, 9], [18, 464]]        0.776468             0.859944   \n","6    [[1196, 35], [46, 436]]        0.769300             0.848739   \n","7    [[1216, 15], [28, 454]]        0.705749             0.792717   \n","8   [[1166, 65], [132, 350]]        0.735939             0.854342   \n","9    [[1209, 22], [31, 451]]        0.711607             0.823529   \n","10   [[1220, 11], [20, 462]]        0.736766             0.812325   \n","11    [[1217, 14], [9, 473]]        0.768817             0.826331   \n","12   [[1213, 18], [32, 450]]        0.763165             0.831933   \n","13   [[1217, 14], [22, 460]]        0.738282             0.829132   \n","14    [[1224, 7], [20, 462]]        0.790874             0.831933   \n","15    [[1224, 7], [11, 471]]        0.751654             0.806723   \n","16   [[1209, 22], [35, 447]]        0.739592             0.809524   \n","17   [[1216, 15], [14, 468]]        0.746485             0.834734   \n","18   [[1211, 20], [35, 447]]        0.791356             0.854342   \n","19   [[1208, 23], [43, 439]]        0.743383             0.851541   \n","20     [[1230, 1], [2, 480]]        0.729804             0.837535   \n","21   [[1220, 11], [15, 467]]        0.785429             0.873950   \n","22   [[1196, 35], [69, 413]]        0.765164             0.871148   \n","23    [[1227, 4], [22, 460]]        0.804453             0.845938   \n","24   [[1221, 10], [28, 454]]        0.762338             0.873950   \n","25   [[1191, 40], [67, 415]]        0.783361             0.885154   \n","26   [[1208, 23], [50, 432]]        0.769300             0.848739   \n","27   [[1218, 13], [19, 463]]        0.742349             0.857143   \n","28   [[1220, 11], [27, 455]]        0.774469             0.820728   \n","29   [[1215, 16], [24, 458]]        0.761856             0.851541   \n","30   [[1201, 30], [48, 434]]        0.806245             0.848739   \n","31   [[1217, 14], [17, 465]]        0.777985             0.876751   \n","32   [[1221, 10], [22, 460]]        0.767783             0.831933   \n","\n","    validation_f1score  validation_precision  validation_recall  \\\n","0             0.678571              0.633333           0.730769   \n","1             0.671233              0.720588           0.628205   \n","2             0.652174              0.566038           0.769231   \n","3             0.641975              0.619048           0.666667   \n","4             0.644737              0.662162           0.628205   \n","5             0.662162              0.700000           0.628205   \n","6             0.644737              0.662162           0.628205   \n","7             0.537500              0.524390           0.551282   \n","8             0.611940              0.732143           0.525641   \n","9             0.559441              0.615385           0.512821   \n","10            0.583851              0.566265           0.602564   \n","11            0.626506              0.590909           0.666667   \n","12            0.625000              0.609756           0.641026   \n","13            0.596026              0.616438           0.576923   \n","14            0.651163              0.595745           0.717949   \n","15            0.596491              0.548387           0.653846   \n","16            0.585366              0.558140           0.615385   \n","17            0.609272              0.630137           0.589744   \n","18            0.670886              0.662500           0.679487   \n","19            0.618705              0.704918           0.551282   \n","20            0.591549              0.656250           0.538462   \n","21            0.685315              0.753846           0.628205   \n","22            0.661765              0.775862           0.576923   \n","23            0.674556              0.626374           0.730769   \n","24            0.661654              0.800000           0.564103   \n","25            0.696296              0.824561           0.602564   \n","26            0.644737              0.662162           0.628205   \n","27            0.622222              0.736842           0.538462   \n","28            0.627907              0.574468           0.692308   \n","29            0.639456              0.681159           0.602564   \n","30            0.678571              0.633333           0.730769   \n","31            0.681159              0.783333           0.602564   \n","32            0.629630              0.607143           0.653846   \n","\n","      validation_conf_mat        RUN_ID  \n","0   [[246, 33], [21, 57]]  coronal_45_1  \n","1   [[260, 19], [29, 49]]  coronal_46_1  \n","2   [[233, 46], [18, 60]]  coronal_47_1  \n","3   [[247, 32], [26, 52]]  coronal_48_1  \n","4   [[254, 25], [29, 49]]  coronal_49_1  \n","5   [[258, 21], [29, 49]]  coronal_50_1  \n","6   [[254, 25], [29, 49]]  coronal_51_1  \n","7   [[240, 39], [35, 43]]  coronal_52_1  \n","8   [[264, 15], [37, 41]]  coronal_53_1  \n","9   [[254, 25], [38, 40]]  coronal_54_1  \n","10  [[243, 36], [31, 47]]  coronal_55_1  \n","11  [[243, 36], [26, 52]]  coronal_45_2  \n","12  [[247, 32], [28, 50]]  coronal_46_2  \n","13  [[251, 28], [33, 45]]  coronal_47_2  \n","14  [[241, 38], [22, 56]]  coronal_48_2  \n","15  [[237, 42], [27, 51]]  coronal_49_2  \n","16  [[241, 38], [30, 48]]  coronal_50_2  \n","17  [[252, 27], [32, 46]]  coronal_51_2  \n","18  [[252, 27], [25, 53]]  coronal_52_2  \n","19  [[261, 18], [35, 43]]  coronal_53_2  \n","20  [[257, 22], [36, 42]]  coronal_54_2  \n","21  [[263, 16], [29, 49]]  coronal_55_2  \n","22  [[266, 13], [33, 45]]  coronal_45_3  \n","23  [[245, 34], [21, 57]]  coronal_46_3  \n","24  [[268, 11], [34, 44]]  coronal_47_3  \n","25  [[269, 10], [31, 47]]  coronal_48_3  \n","26  [[254, 25], [29, 49]]  coronal_49_3  \n","27  [[264, 15], [36, 42]]  coronal_50_3  \n","28  [[239, 40], [24, 54]]  coronal_51_3  \n","29  [[257, 22], [31, 47]]  coronal_52_3  \n","30  [[246, 33], [21, 57]]  coronal_53_3  \n","31  [[266, 13], [31, 47]]  coronal_54_3  \n","32  [[246, 33], [27, 51]]  coronal_55_3  "]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"A5l_XNYMxBOk"},"source":["## Axial 20-30 + 70-80"]},{"cell_type":"code","metadata":{"id":"x_I3huT9xBOk","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1PDJFXWLzNRw3vxNwyGuq7odx_OXTU3R8"},"executionInfo":{"status":"ok","timestamp":1634176265449,"user_tz":180,"elapsed":7548626,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"49d9b405-05ed-4d1a-f365-888d329d53d9"},"source":["df_results_axial = run_mris_experiments(orientation = 'axial',\n","                          slices = list(range(20,31)) + list(range(70,81)),\n","                          num_repeats = 3,\n","                          model='super_shallow_cnn',\n","                          classes=['AD','CN'],\n","                          save_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/data/RESULTS_AXIAL_SUPER_SHALLOW_CNN.csv')"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"YaAMsulMxBOm"},"source":["## Sagittal 20-30 + 70-80"]},{"cell_type":"code","metadata":{"id":"QtHkPzx9xBOm","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1vkvarU5qH3g5O3YFQHa07W4EGyq-oLyX"},"executionInfo":{"status":"ok","timestamp":1634184076012,"user_tz":180,"elapsed":7810583,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"7f960f88-d3d7-413b-b5bd-3105e311f875"},"source":["df_results_sagittal = run_mris_experiments(orientation = 'sagittal',\n","                          slices = list(range(20,31)) + list(range(70,81)),\n","                          num_repeats = 3,\n","                          model='super_shallow_cnn',\n","                          classes=['AD','CN'],\n","                          save_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/data/RESULTS_SAGITTAL_SUPER_SHALLOW_CNN.csv')"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"laneS6ntxBOn","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1634184076018,"user_tz":180,"elapsed":46,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"b9238cb4-2c09-4e6d-9515-036e7695f807"},"source":["df_results_sagittal"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>train_auc</th>\n","      <th>train_accuracy</th>\n","      <th>train_f1score</th>\n","      <th>train_precision</th>\n","      <th>train_recall</th>\n","      <th>train_conf_mat</th>\n","      <th>validation_auc</th>\n","      <th>validation_accuracy</th>\n","      <th>validation_f1score</th>\n","      <th>validation_precision</th>\n","      <th>validation_recall</th>\n","      <th>validation_conf_mat</th>\n","      <th>RUN_ID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.992151</td>\n","      <td>0.994162</td>\n","      <td>0.989605</td>\n","      <td>0.991667</td>\n","      <td>0.987552</td>\n","      <td>[[1227, 4], [6, 476]]</td>\n","      <td>0.737042</td>\n","      <td>0.798319</td>\n","      <td>0.576471</td>\n","      <td>0.532609</td>\n","      <td>0.628205</td>\n","      <td>[[236, 43], [29, 49]]</td>\n","      <td>sagittal_20_1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.925893</td>\n","      <td>0.951547</td>\n","      <td>0.909684</td>\n","      <td>0.956522</td>\n","      <td>0.867220</td>\n","      <td>[[1212, 19], [64, 418]]</td>\n","      <td>0.732906</td>\n","      <td>0.820728</td>\n","      <td>0.584416</td>\n","      <td>0.592105</td>\n","      <td>0.576923</td>\n","      <td>[[248, 31], [33, 45]]</td>\n","      <td>sagittal_21_1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.958007</td>\n","      <td>0.971395</td>\n","      <td>0.948038</td>\n","      <td>0.969631</td>\n","      <td>0.927386</td>\n","      <td>[[1217, 14], [35, 447]]</td>\n","      <td>0.777502</td>\n","      <td>0.854342</td>\n","      <td>0.657895</td>\n","      <td>0.675676</td>\n","      <td>0.641026</td>\n","      <td>[[255, 24], [28, 50]]</td>\n","      <td>sagittal_22_1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.971673</td>\n","      <td>0.980152</td>\n","      <td>0.964286</td>\n","      <td>0.976596</td>\n","      <td>0.952282</td>\n","      <td>[[1220, 11], [23, 459]]</td>\n","      <td>0.796733</td>\n","      <td>0.862745</td>\n","      <td>0.683871</td>\n","      <td>0.688312</td>\n","      <td>0.679487</td>\n","      <td>[[255, 24], [25, 53]]</td>\n","      <td>sagittal_23_1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.860803</td>\n","      <td>0.904262</td>\n","      <td>0.817372</td>\n","      <td>0.882212</td>\n","      <td>0.761411</td>\n","      <td>[[1182, 49], [115, 367]]</td>\n","      <td>0.738282</td>\n","      <td>0.829132</td>\n","      <td>0.596026</td>\n","      <td>0.616438</td>\n","      <td>0.576923</td>\n","      <td>[[251, 28], [33, 45]]</td>\n","      <td>sagittal_24_1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.949752</td>\n","      <td>0.964974</td>\n","      <td>0.936306</td>\n","      <td>0.958696</td>\n","      <td>0.914938</td>\n","      <td>[[1212, 19], [41, 441]]</td>\n","      <td>0.797560</td>\n","      <td>0.820728</td>\n","      <td>0.648352</td>\n","      <td>0.567308</td>\n","      <td>0.756410</td>\n","      <td>[[234, 45], [19, 59]]</td>\n","      <td>sagittal_25_1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1231, 0], [0, 482]]</td>\n","      <td>0.738282</td>\n","      <td>0.829132</td>\n","      <td>0.596026</td>\n","      <td>0.616438</td>\n","      <td>0.576923</td>\n","      <td>[[251, 28], [33, 45]]</td>\n","      <td>sagittal_26_1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.890392</td>\n","      <td>0.924110</td>\n","      <td>0.857768</td>\n","      <td>0.907407</td>\n","      <td>0.813278</td>\n","      <td>[[1191, 40], [90, 392]]</td>\n","      <td>0.775986</td>\n","      <td>0.837535</td>\n","      <td>0.641975</td>\n","      <td>0.619048</td>\n","      <td>0.666667</td>\n","      <td>[[247, 32], [26, 52]]</td>\n","      <td>sagittal_27_1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1231, 0], [0, 482]]</td>\n","      <td>0.789289</td>\n","      <td>0.865546</td>\n","      <td>0.680000</td>\n","      <td>0.708333</td>\n","      <td>0.653846</td>\n","      <td>[[258, 21], [27, 51]]</td>\n","      <td>sagittal_28_1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.871401</td>\n","      <td>0.909515</td>\n","      <td>0.829857</td>\n","      <td>0.881119</td>\n","      <td>0.784232</td>\n","      <td>[[1180, 51], [104, 378]]</td>\n","      <td>0.782327</td>\n","      <td>0.890756</td>\n","      <td>0.702290</td>\n","      <td>0.867925</td>\n","      <td>0.589744</td>\n","      <td>[[272, 7], [32, 46]]</td>\n","      <td>sagittal_29_1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.984484</td>\n","      <td>0.989492</td>\n","      <td>0.981172</td>\n","      <td>0.989451</td>\n","      <td>0.973029</td>\n","      <td>[[1226, 5], [13, 469]]</td>\n","      <td>0.765991</td>\n","      <td>0.829132</td>\n","      <td>0.625767</td>\n","      <td>0.600000</td>\n","      <td>0.653846</td>\n","      <td>[[245, 34], [27, 51]]</td>\n","      <td>sagittal_30_1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.960262</td>\n","      <td>0.973730</td>\n","      <td>0.952179</td>\n","      <td>0.976035</td>\n","      <td>0.929461</td>\n","      <td>[[1220, 11], [34, 448]]</td>\n","      <td>0.725186</td>\n","      <td>0.837535</td>\n","      <td>0.585714</td>\n","      <td>0.661290</td>\n","      <td>0.525641</td>\n","      <td>[[258, 21], [37, 41]]</td>\n","      <td>sagittal_70_1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.994407</td>\n","      <td>0.996497</td>\n","      <td>0.993750</td>\n","      <td>0.997908</td>\n","      <td>0.989627</td>\n","      <td>[[1230, 1], [5, 477]]</td>\n","      <td>0.780811</td>\n","      <td>0.873950</td>\n","      <td>0.680851</td>\n","      <td>0.761905</td>\n","      <td>0.615385</td>\n","      <td>[[264, 15], [30, 48]]</td>\n","      <td>sagittal_71_1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.982409</td>\n","      <td>0.988325</td>\n","      <td>0.979036</td>\n","      <td>0.989407</td>\n","      <td>0.968880</td>\n","      <td>[[1226, 5], [15, 467]]</td>\n","      <td>0.798249</td>\n","      <td>0.879552</td>\n","      <td>0.703448</td>\n","      <td>0.761194</td>\n","      <td>0.653846</td>\n","      <td>[[263, 16], [27, 51]]</td>\n","      <td>sagittal_72_1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.946865</td>\n","      <td>0.962639</td>\n","      <td>0.932059</td>\n","      <td>0.954348</td>\n","      <td>0.910788</td>\n","      <td>[[1210, 21], [43, 439]]</td>\n","      <td>0.847808</td>\n","      <td>0.848739</td>\n","      <td>0.709677</td>\n","      <td>0.611111</td>\n","      <td>0.846154</td>\n","      <td>[[237, 42], [12, 66]]</td>\n","      <td>sagittal_73_1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.910645</td>\n","      <td>0.938704</td>\n","      <td>0.885993</td>\n","      <td>0.929385</td>\n","      <td>0.846473</td>\n","      <td>[[1200, 31], [74, 408]]</td>\n","      <td>0.750069</td>\n","      <td>0.840336</td>\n","      <td>0.617450</td>\n","      <td>0.647887</td>\n","      <td>0.589744</td>\n","      <td>[[254, 25], [32, 46]]</td>\n","      <td>sagittal_74_1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.923906</td>\n","      <td>0.946877</td>\n","      <td>0.902256</td>\n","      <td>0.935412</td>\n","      <td>0.871369</td>\n","      <td>[[1202, 29], [62, 420]]</td>\n","      <td>0.760822</td>\n","      <td>0.857143</td>\n","      <td>0.643357</td>\n","      <td>0.707692</td>\n","      <td>0.589744</td>\n","      <td>[[260, 19], [32, 46]]</td>\n","      <td>sagittal_75_1</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1231, 0], [0, 482]]</td>\n","      <td>0.798249</td>\n","      <td>0.879552</td>\n","      <td>0.703448</td>\n","      <td>0.761194</td>\n","      <td>0.653846</td>\n","      <td>[[263, 16], [27, 51]]</td>\n","      <td>sagittal_76_1</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.887055</td>\n","      <td>0.922942</td>\n","      <td>0.854626</td>\n","      <td>0.910798</td>\n","      <td>0.804979</td>\n","      <td>[[1193, 38], [94, 388]]</td>\n","      <td>0.766267</td>\n","      <td>0.815126</td>\n","      <td>0.616279</td>\n","      <td>0.563830</td>\n","      <td>0.679487</td>\n","      <td>[[238, 41], [25, 53]]</td>\n","      <td>sagittal_77_1</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.979747</td>\n","      <td>0.985406</td>\n","      <td>0.973877</td>\n","      <td>0.981053</td>\n","      <td>0.966805</td>\n","      <td>[[1222, 9], [16, 466]]</td>\n","      <td>0.780121</td>\n","      <td>0.815126</td>\n","      <td>0.629213</td>\n","      <td>0.560000</td>\n","      <td>0.717949</td>\n","      <td>[[235, 44], [22, 56]]</td>\n","      <td>sagittal_78_1</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>0.936129</td>\n","      <td>0.954466</td>\n","      <td>0.917021</td>\n","      <td>0.941048</td>\n","      <td>0.894191</td>\n","      <td>[[1204, 27], [51, 431]]</td>\n","      <td>0.772608</td>\n","      <td>0.868347</td>\n","      <td>0.666667</td>\n","      <td>0.746032</td>\n","      <td>0.602564</td>\n","      <td>[[263, 16], [31, 47]]</td>\n","      <td>sagittal_79_1</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1231, 0], [0, 482]]</td>\n","      <td>0.753377</td>\n","      <td>0.859944</td>\n","      <td>0.637681</td>\n","      <td>0.733333</td>\n","      <td>0.564103</td>\n","      <td>[[263, 16], [34, 44]]</td>\n","      <td>sagittal_80_1</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0.997113</td>\n","      <td>0.997665</td>\n","      <td>0.995851</td>\n","      <td>0.995851</td>\n","      <td>0.995851</td>\n","      <td>[[1229, 2], [2, 480]]</td>\n","      <td>0.674731</td>\n","      <td>0.773109</td>\n","      <td>0.490566</td>\n","      <td>0.481481</td>\n","      <td>0.500000</td>\n","      <td>[[237, 42], [39, 39]]</td>\n","      <td>sagittal_20_2</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0.975191</td>\n","      <td>0.982487</td>\n","      <td>0.968553</td>\n","      <td>0.978814</td>\n","      <td>0.958506</td>\n","      <td>[[1221, 10], [20, 462]]</td>\n","      <td>0.788599</td>\n","      <td>0.806723</td>\n","      <td>0.631016</td>\n","      <td>0.541284</td>\n","      <td>0.756410</td>\n","      <td>[[229, 50], [19, 59]]</td>\n","      <td>sagittal_21_2</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0.893098</td>\n","      <td>0.925277</td>\n","      <td>0.860566</td>\n","      <td>0.905963</td>\n","      <td>0.819502</td>\n","      <td>[[1190, 41], [87, 395]]</td>\n","      <td>0.765715</td>\n","      <td>0.843137</td>\n","      <td>0.636364</td>\n","      <td>0.644737</td>\n","      <td>0.628205</td>\n","      <td>[[252, 27], [29, 49]]</td>\n","      <td>sagittal_22_2</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0.976410</td>\n","      <td>0.984238</td>\n","      <td>0.971609</td>\n","      <td>0.985075</td>\n","      <td>0.958506</td>\n","      <td>[[1224, 7], [20, 462]]</td>\n","      <td>0.823201</td>\n","      <td>0.831933</td>\n","      <td>0.677419</td>\n","      <td>0.583333</td>\n","      <td>0.807692</td>\n","      <td>[[234, 45], [15, 63]]</td>\n","      <td>sagittal_23_2</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0.884843</td>\n","      <td>0.918856</td>\n","      <td>0.848419</td>\n","      <td>0.894253</td>\n","      <td>0.807054</td>\n","      <td>[[1185, 46], [93, 389]]</td>\n","      <td>0.780604</td>\n","      <td>0.837535</td>\n","      <td>0.646341</td>\n","      <td>0.616279</td>\n","      <td>0.679487</td>\n","      <td>[[246, 33], [25, 53]]</td>\n","      <td>sagittal_24_2</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>0.897379</td>\n","      <td>0.922358</td>\n","      <td>0.858961</td>\n","      <td>0.878525</td>\n","      <td>0.840249</td>\n","      <td>[[1175, 56], [77, 405]]</td>\n","      <td>0.763372</td>\n","      <td>0.868347</td>\n","      <td>0.656934</td>\n","      <td>0.762712</td>\n","      <td>0.576923</td>\n","      <td>[[265, 14], [33, 45]]</td>\n","      <td>sagittal_25_2</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0.919619</td>\n","      <td>0.941623</td>\n","      <td>0.893390</td>\n","      <td>0.918860</td>\n","      <td>0.869295</td>\n","      <td>[[1194, 37], [63, 419]]</td>\n","      <td>0.831334</td>\n","      <td>0.887955</td>\n","      <td>0.740260</td>\n","      <td>0.750000</td>\n","      <td>0.730769</td>\n","      <td>[[260, 19], [21, 57]]</td>\n","      <td>sagittal_26_2</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1231, 0], [0, 482]]</td>\n","      <td>0.762614</td>\n","      <td>0.859944</td>\n","      <td>0.647887</td>\n","      <td>0.718750</td>\n","      <td>0.589744</td>\n","      <td>[[261, 18], [32, 46]]</td>\n","      <td>sagittal_27_2</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1231, 0], [0, 482]]</td>\n","      <td>0.778260</td>\n","      <td>0.862745</td>\n","      <td>0.666667</td>\n","      <td>0.710145</td>\n","      <td>0.628205</td>\n","      <td>[[259, 20], [29, 49]]</td>\n","      <td>sagittal_28_2</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>0.949752</td>\n","      <td>0.964974</td>\n","      <td>0.936306</td>\n","      <td>0.958696</td>\n","      <td>0.914938</td>\n","      <td>[[1212, 19], [41, 441]]</td>\n","      <td>0.784188</td>\n","      <td>0.843137</td>\n","      <td>0.654321</td>\n","      <td>0.630952</td>\n","      <td>0.679487</td>\n","      <td>[[248, 31], [25, 53]]</td>\n","      <td>sagittal_29_2</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1231, 0], [0, 482]]</td>\n","      <td>0.754411</td>\n","      <td>0.854342</td>\n","      <td>0.633803</td>\n","      <td>0.703125</td>\n","      <td>0.576923</td>\n","      <td>[[260, 19], [33, 45]]</td>\n","      <td>sagittal_30_2</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>0.908433</td>\n","      <td>0.934618</td>\n","      <td>0.879570</td>\n","      <td>0.912946</td>\n","      <td>0.848548</td>\n","      <td>[[1192, 39], [73, 409]]</td>\n","      <td>0.781086</td>\n","      <td>0.859944</td>\n","      <td>0.666667</td>\n","      <td>0.694444</td>\n","      <td>0.641026</td>\n","      <td>[[257, 22], [28, 50]]</td>\n","      <td>sagittal_70_2</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>0.950564</td>\n","      <td>0.966141</td>\n","      <td>0.938298</td>\n","      <td>0.962882</td>\n","      <td>0.914938</td>\n","      <td>[[1214, 17], [41, 441]]</td>\n","      <td>0.748277</td>\n","      <td>0.837535</td>\n","      <td>0.613333</td>\n","      <td>0.638889</td>\n","      <td>0.589744</td>\n","      <td>[[253, 26], [32, 46]]</td>\n","      <td>sagittal_71_2</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>0.998963</td>\n","      <td>0.999416</td>\n","      <td>0.998962</td>\n","      <td>1.000000</td>\n","      <td>0.997925</td>\n","      <td>[[1231, 0], [1, 481]]</td>\n","      <td>0.729046</td>\n","      <td>0.829132</td>\n","      <td>0.585034</td>\n","      <td>0.623188</td>\n","      <td>0.551282</td>\n","      <td>[[253, 26], [35, 43]]</td>\n","      <td>sagittal_72_2</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>0.973386</td>\n","      <td>0.978984</td>\n","      <td>0.962578</td>\n","      <td>0.964583</td>\n","      <td>0.960581</td>\n","      <td>[[1214, 17], [19, 463]]</td>\n","      <td>0.754687</td>\n","      <td>0.840336</td>\n","      <td>0.622517</td>\n","      <td>0.643836</td>\n","      <td>0.602564</td>\n","      <td>[[253, 26], [31, 47]]</td>\n","      <td>sagittal_73_2</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>0.872032</td>\n","      <td>0.909515</td>\n","      <td>0.830230</td>\n","      <td>0.879350</td>\n","      <td>0.786307</td>\n","      <td>[[1179, 52], [103, 379]]</td>\n","      <td>0.794183</td>\n","      <td>0.851541</td>\n","      <td>0.670807</td>\n","      <td>0.650602</td>\n","      <td>0.692308</td>\n","      <td>[[250, 29], [24, 54]]</td>\n","      <td>sagittal_74_2</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>0.939603</td>\n","      <td>0.958552</td>\n","      <td>0.924064</td>\n","      <td>0.953642</td>\n","      <td>0.896266</td>\n","      <td>[[1210, 21], [50, 432]]</td>\n","      <td>0.820582</td>\n","      <td>0.871148</td>\n","      <td>0.712500</td>\n","      <td>0.695122</td>\n","      <td>0.730769</td>\n","      <td>[[254, 25], [21, 57]]</td>\n","      <td>sagittal_75_2</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>0.978260</td>\n","      <td>0.985989</td>\n","      <td>0.974737</td>\n","      <td>0.989316</td>\n","      <td>0.960581</td>\n","      <td>[[1226, 5], [19, 463]]</td>\n","      <td>0.815205</td>\n","      <td>0.862745</td>\n","      <td>0.699387</td>\n","      <td>0.670588</td>\n","      <td>0.730769</td>\n","      <td>[[251, 28], [21, 57]]</td>\n","      <td>sagittal_76_2</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>0.981234</td>\n","      <td>0.984822</td>\n","      <td>0.973029</td>\n","      <td>0.973029</td>\n","      <td>0.973029</td>\n","      <td>[[1218, 13], [13, 469]]</td>\n","      <td>0.749311</td>\n","      <td>0.831933</td>\n","      <td>0.610390</td>\n","      <td>0.618421</td>\n","      <td>0.602564</td>\n","      <td>[[250, 29], [31, 47]]</td>\n","      <td>sagittal_77_2</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>0.942128</td>\n","      <td>0.958552</td>\n","      <td>0.924708</td>\n","      <td>0.945770</td>\n","      <td>0.904564</td>\n","      <td>[[1206, 25], [46, 436]]</td>\n","      <td>0.721878</td>\n","      <td>0.817927</td>\n","      <td>0.569536</td>\n","      <td>0.589041</td>\n","      <td>0.551282</td>\n","      <td>[[249, 30], [35, 43]]</td>\n","      <td>sagittal_78_2</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>0.989670</td>\n","      <td>0.992411</td>\n","      <td>0.986472</td>\n","      <td>0.989562</td>\n","      <td>0.983402</td>\n","      <td>[[1226, 5], [8, 474]]</td>\n","      <td>0.781362</td>\n","      <td>0.845938</td>\n","      <td>0.654088</td>\n","      <td>0.641975</td>\n","      <td>0.666667</td>\n","      <td>[[250, 29], [26, 52]]</td>\n","      <td>sagittal_79_2</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>0.982815</td>\n","      <td>0.988908</td>\n","      <td>0.980063</td>\n","      <td>0.991507</td>\n","      <td>0.968880</td>\n","      <td>[[1227, 4], [15, 467]]</td>\n","      <td>0.757720</td>\n","      <td>0.873950</td>\n","      <td>0.656489</td>\n","      <td>0.811321</td>\n","      <td>0.551282</td>\n","      <td>[[269, 10], [35, 43]]</td>\n","      <td>sagittal_80_2</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>0.989852</td>\n","      <td>0.993579</td>\n","      <td>0.988506</td>\n","      <td>0.995789</td>\n","      <td>0.981328</td>\n","      <td>[[1229, 2], [9, 473]]</td>\n","      <td>0.726496</td>\n","      <td>0.817927</td>\n","      <td>0.575163</td>\n","      <td>0.586667</td>\n","      <td>0.564103</td>\n","      <td>[[248, 31], [34, 44]]</td>\n","      <td>sagittal_20_3</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>0.995038</td>\n","      <td>0.996497</td>\n","      <td>0.993763</td>\n","      <td>0.995833</td>\n","      <td>0.991701</td>\n","      <td>[[1229, 2], [4, 478]]</td>\n","      <td>0.793424</td>\n","      <td>0.843137</td>\n","      <td>0.662651</td>\n","      <td>0.625000</td>\n","      <td>0.705128</td>\n","      <td>[[246, 33], [23, 55]]</td>\n","      <td>sagittal_21_3</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>0.885387</td>\n","      <td>0.922358</td>\n","      <td>0.853039</td>\n","      <td>0.912530</td>\n","      <td>0.800830</td>\n","      <td>[[1194, 37], [96, 386]]</td>\n","      <td>0.754963</td>\n","      <td>0.826331</td>\n","      <td>0.612500</td>\n","      <td>0.597561</td>\n","      <td>0.628205</td>\n","      <td>[[246, 33], [29, 49]]</td>\n","      <td>sagittal_22_3</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>0.946821</td>\n","      <td>0.964390</td>\n","      <td>0.934759</td>\n","      <td>0.964680</td>\n","      <td>0.906639</td>\n","      <td>[[1215, 16], [45, 437]]</td>\n","      <td>0.771161</td>\n","      <td>0.801120</td>\n","      <td>0.612022</td>\n","      <td>0.533333</td>\n","      <td>0.717949</td>\n","      <td>[[230, 49], [22, 56]]</td>\n","      <td>sagittal_23_3</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>0.923044</td>\n","      <td>0.939288</td>\n","      <td>0.891441</td>\n","      <td>0.897059</td>\n","      <td>0.885892</td>\n","      <td>[[1182, 49], [55, 427]]</td>\n","      <td>0.764199</td>\n","      <td>0.826331</td>\n","      <td>0.621951</td>\n","      <td>0.593023</td>\n","      <td>0.653846</td>\n","      <td>[[244, 35], [27, 51]]</td>\n","      <td>sagittal_24_3</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>0.983852</td>\n","      <td>0.989492</td>\n","      <td>0.981132</td>\n","      <td>0.991525</td>\n","      <td>0.970954</td>\n","      <td>[[1227, 4], [14, 468]]</td>\n","      <td>0.767990</td>\n","      <td>0.868347</td>\n","      <td>0.661871</td>\n","      <td>0.754098</td>\n","      <td>0.589744</td>\n","      <td>[[264, 15], [32, 46]]</td>\n","      <td>sagittal_25_3</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>0.966080</td>\n","      <td>0.976649</td>\n","      <td>0.957806</td>\n","      <td>0.974249</td>\n","      <td>0.941909</td>\n","      <td>[[1219, 12], [28, 454]]</td>\n","      <td>0.787290</td>\n","      <td>0.826331</td>\n","      <td>0.643678</td>\n","      <td>0.583333</td>\n","      <td>0.717949</td>\n","      <td>[[239, 40], [22, 56]]</td>\n","      <td>sagittal_26_3</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>0.924943</td>\n","      <td>0.947461</td>\n","      <td>0.903433</td>\n","      <td>0.935556</td>\n","      <td>0.873444</td>\n","      <td>[[1202, 29], [61, 421]]</td>\n","      <td>0.781362</td>\n","      <td>0.845938</td>\n","      <td>0.654088</td>\n","      <td>0.641975</td>\n","      <td>0.666667</td>\n","      <td>[[250, 29], [26, 52]]</td>\n","      <td>sagittal_27_3</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1231, 0], [0, 482]]</td>\n","      <td>0.756203</td>\n","      <td>0.857143</td>\n","      <td>0.638298</td>\n","      <td>0.714286</td>\n","      <td>0.576923</td>\n","      <td>[[261, 18], [33, 45]]</td>\n","      <td>sagittal_28_3</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1231, 0], [0, 482]]</td>\n","      <td>0.745933</td>\n","      <td>0.862745</td>\n","      <td>0.631579</td>\n","      <td>0.763636</td>\n","      <td>0.538462</td>\n","      <td>[[266, 13], [36, 42]]</td>\n","      <td>sagittal_29_3</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>[[1231, 0], [0, 482]]</td>\n","      <td>0.746209</td>\n","      <td>0.848739</td>\n","      <td>0.619718</td>\n","      <td>0.687500</td>\n","      <td>0.564103</td>\n","      <td>[[259, 20], [34, 44]]</td>\n","      <td>sagittal_30_3</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>0.991520</td>\n","      <td>0.994162</td>\n","      <td>0.989583</td>\n","      <td>0.993724</td>\n","      <td>0.985477</td>\n","      <td>[[1228, 3], [7, 475]]</td>\n","      <td>0.813138</td>\n","      <td>0.873950</td>\n","      <td>0.709677</td>\n","      <td>0.714286</td>\n","      <td>0.705128</td>\n","      <td>[[257, 22], [23, 55]]</td>\n","      <td>sagittal_70_3</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>0.997925</td>\n","      <td>0.998832</td>\n","      <td>0.997921</td>\n","      <td>1.000000</td>\n","      <td>0.995851</td>\n","      <td>[[1231, 0], [2, 480]]</td>\n","      <td>0.734422</td>\n","      <td>0.837535</td>\n","      <td>0.597222</td>\n","      <td>0.651515</td>\n","      <td>0.551282</td>\n","      <td>[[256, 23], [35, 43]]</td>\n","      <td>sagittal_71_3</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>0.897472</td>\n","      <td>0.927029</td>\n","      <td>0.864865</td>\n","      <td>0.902935</td>\n","      <td>0.829876</td>\n","      <td>[[1188, 43], [82, 400]]</td>\n","      <td>0.745175</td>\n","      <td>0.854342</td>\n","      <td>0.623188</td>\n","      <td>0.716667</td>\n","      <td>0.551282</td>\n","      <td>[[262, 17], [35, 43]]</td>\n","      <td>sagittal_72_3</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>0.982228</td>\n","      <td>0.987157</td>\n","      <td>0.977035</td>\n","      <td>0.983193</td>\n","      <td>0.970954</td>\n","      <td>[[1223, 8], [14, 468]]</td>\n","      <td>0.782672</td>\n","      <td>0.826331</td>\n","      <td>0.639535</td>\n","      <td>0.585106</td>\n","      <td>0.705128</td>\n","      <td>[[240, 39], [23, 55]]</td>\n","      <td>sagittal_73_3</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>0.971492</td>\n","      <td>0.978984</td>\n","      <td>0.962343</td>\n","      <td>0.970464</td>\n","      <td>0.954357</td>\n","      <td>[[1217, 14], [22, 460]]</td>\n","      <td>0.800110</td>\n","      <td>0.831933</td>\n","      <td>0.659091</td>\n","      <td>0.591837</td>\n","      <td>0.743590</td>\n","      <td>[[239, 40], [20, 58]]</td>\n","      <td>sagittal_74_3</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>0.932473</td>\n","      <td>0.949212</td>\n","      <td>0.908325</td>\n","      <td>0.922912</td>\n","      <td>0.894191</td>\n","      <td>[[1195, 36], [51, 431]]</td>\n","      <td>0.793424</td>\n","      <td>0.843137</td>\n","      <td>0.662651</td>\n","      <td>0.625000</td>\n","      <td>0.705128</td>\n","      <td>[[246, 33], [23, 55]]</td>\n","      <td>sagittal_75_3</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>0.960894</td>\n","      <td>0.973730</td>\n","      <td>0.952280</td>\n","      <td>0.973970</td>\n","      <td>0.931535</td>\n","      <td>[[1219, 12], [33, 449]]</td>\n","      <td>0.802936</td>\n","      <td>0.829132</td>\n","      <td>0.659218</td>\n","      <td>0.584158</td>\n","      <td>0.756410</td>\n","      <td>[[237, 42], [19, 59]]</td>\n","      <td>sagittal_76_3</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>0.976229</td>\n","      <td>0.983071</td>\n","      <td>0.969634</td>\n","      <td>0.978858</td>\n","      <td>0.960581</td>\n","      <td>[[1221, 10], [19, 463]]</td>\n","      <td>0.802109</td>\n","      <td>0.871148</td>\n","      <td>0.697368</td>\n","      <td>0.716216</td>\n","      <td>0.679487</td>\n","      <td>[[258, 21], [25, 53]]</td>\n","      <td>sagittal_77_3</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>0.981822</td>\n","      <td>0.986573</td>\n","      <td>0.976017</td>\n","      <td>0.981132</td>\n","      <td>0.970954</td>\n","      <td>[[1222, 9], [14, 468]]</td>\n","      <td>0.756479</td>\n","      <td>0.843137</td>\n","      <td>0.626667</td>\n","      <td>0.652778</td>\n","      <td>0.602564</td>\n","      <td>[[254, 25], [31, 47]]</td>\n","      <td>sagittal_78_3</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>0.974785</td>\n","      <td>0.981903</td>\n","      <td>0.967539</td>\n","      <td>0.976744</td>\n","      <td>0.958506</td>\n","      <td>[[1220, 11], [20, 462]]</td>\n","      <td>0.786256</td>\n","      <td>0.831933</td>\n","      <td>0.647059</td>\n","      <td>0.597826</td>\n","      <td>0.705128</td>\n","      <td>[[242, 37], [23, 55]]</td>\n","      <td>sagittal_79_3</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>0.992739</td>\n","      <td>0.995914</td>\n","      <td>0.992685</td>\n","      <td>1.000000</td>\n","      <td>0.985477</td>\n","      <td>[[1231, 0], [7, 475]]</td>\n","      <td>0.784671</td>\n","      <td>0.865546</td>\n","      <td>0.675676</td>\n","      <td>0.714286</td>\n","      <td>0.641026</td>\n","      <td>[[259, 20], [28, 50]]</td>\n","      <td>sagittal_80_3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    train_auc  train_accuracy  train_f1score  train_precision  train_recall  \\\n","0    0.992151        0.994162       0.989605         0.991667      0.987552   \n","1    0.925893        0.951547       0.909684         0.956522      0.867220   \n","2    0.958007        0.971395       0.948038         0.969631      0.927386   \n","3    0.971673        0.980152       0.964286         0.976596      0.952282   \n","4    0.860803        0.904262       0.817372         0.882212      0.761411   \n","5    0.949752        0.964974       0.936306         0.958696      0.914938   \n","6    1.000000        1.000000       1.000000         1.000000      1.000000   \n","7    0.890392        0.924110       0.857768         0.907407      0.813278   \n","8    1.000000        1.000000       1.000000         1.000000      1.000000   \n","9    0.871401        0.909515       0.829857         0.881119      0.784232   \n","10   0.984484        0.989492       0.981172         0.989451      0.973029   \n","11   0.960262        0.973730       0.952179         0.976035      0.929461   \n","12   0.994407        0.996497       0.993750         0.997908      0.989627   \n","13   0.982409        0.988325       0.979036         0.989407      0.968880   \n","14   0.946865        0.962639       0.932059         0.954348      0.910788   \n","15   0.910645        0.938704       0.885993         0.929385      0.846473   \n","16   0.923906        0.946877       0.902256         0.935412      0.871369   \n","17   1.000000        1.000000       1.000000         1.000000      1.000000   \n","18   0.887055        0.922942       0.854626         0.910798      0.804979   \n","19   0.979747        0.985406       0.973877         0.981053      0.966805   \n","20   0.936129        0.954466       0.917021         0.941048      0.894191   \n","21   1.000000        1.000000       1.000000         1.000000      1.000000   \n","22   0.997113        0.997665       0.995851         0.995851      0.995851   \n","23   0.975191        0.982487       0.968553         0.978814      0.958506   \n","24   0.893098        0.925277       0.860566         0.905963      0.819502   \n","25   0.976410        0.984238       0.971609         0.985075      0.958506   \n","26   0.884843        0.918856       0.848419         0.894253      0.807054   \n","27   0.897379        0.922358       0.858961         0.878525      0.840249   \n","28   0.919619        0.941623       0.893390         0.918860      0.869295   \n","29   1.000000        1.000000       1.000000         1.000000      1.000000   \n","30   1.000000        1.000000       1.000000         1.000000      1.000000   \n","31   0.949752        0.964974       0.936306         0.958696      0.914938   \n","32   1.000000        1.000000       1.000000         1.000000      1.000000   \n","33   0.908433        0.934618       0.879570         0.912946      0.848548   \n","34   0.950564        0.966141       0.938298         0.962882      0.914938   \n","35   0.998963        0.999416       0.998962         1.000000      0.997925   \n","36   0.973386        0.978984       0.962578         0.964583      0.960581   \n","37   0.872032        0.909515       0.830230         0.879350      0.786307   \n","38   0.939603        0.958552       0.924064         0.953642      0.896266   \n","39   0.978260        0.985989       0.974737         0.989316      0.960581   \n","40   0.981234        0.984822       0.973029         0.973029      0.973029   \n","41   0.942128        0.958552       0.924708         0.945770      0.904564   \n","42   0.989670        0.992411       0.986472         0.989562      0.983402   \n","43   0.982815        0.988908       0.980063         0.991507      0.968880   \n","44   0.989852        0.993579       0.988506         0.995789      0.981328   \n","45   0.995038        0.996497       0.993763         0.995833      0.991701   \n","46   0.885387        0.922358       0.853039         0.912530      0.800830   \n","47   0.946821        0.964390       0.934759         0.964680      0.906639   \n","48   0.923044        0.939288       0.891441         0.897059      0.885892   \n","49   0.983852        0.989492       0.981132         0.991525      0.970954   \n","50   0.966080        0.976649       0.957806         0.974249      0.941909   \n","51   0.924943        0.947461       0.903433         0.935556      0.873444   \n","52   1.000000        1.000000       1.000000         1.000000      1.000000   \n","53   1.000000        1.000000       1.000000         1.000000      1.000000   \n","54   1.000000        1.000000       1.000000         1.000000      1.000000   \n","55   0.991520        0.994162       0.989583         0.993724      0.985477   \n","56   0.997925        0.998832       0.997921         1.000000      0.995851   \n","57   0.897472        0.927029       0.864865         0.902935      0.829876   \n","58   0.982228        0.987157       0.977035         0.983193      0.970954   \n","59   0.971492        0.978984       0.962343         0.970464      0.954357   \n","60   0.932473        0.949212       0.908325         0.922912      0.894191   \n","61   0.960894        0.973730       0.952280         0.973970      0.931535   \n","62   0.976229        0.983071       0.969634         0.978858      0.960581   \n","63   0.981822        0.986573       0.976017         0.981132      0.970954   \n","64   0.974785        0.981903       0.967539         0.976744      0.958506   \n","65   0.992739        0.995914       0.992685         1.000000      0.985477   \n","\n","              train_conf_mat  validation_auc  validation_accuracy  \\\n","0      [[1227, 4], [6, 476]]        0.737042             0.798319   \n","1    [[1212, 19], [64, 418]]        0.732906             0.820728   \n","2    [[1217, 14], [35, 447]]        0.777502             0.854342   \n","3    [[1220, 11], [23, 459]]        0.796733             0.862745   \n","4   [[1182, 49], [115, 367]]        0.738282             0.829132   \n","5    [[1212, 19], [41, 441]]        0.797560             0.820728   \n","6      [[1231, 0], [0, 482]]        0.738282             0.829132   \n","7    [[1191, 40], [90, 392]]        0.775986             0.837535   \n","8      [[1231, 0], [0, 482]]        0.789289             0.865546   \n","9   [[1180, 51], [104, 378]]        0.782327             0.890756   \n","10    [[1226, 5], [13, 469]]        0.765991             0.829132   \n","11   [[1220, 11], [34, 448]]        0.725186             0.837535   \n","12     [[1230, 1], [5, 477]]        0.780811             0.873950   \n","13    [[1226, 5], [15, 467]]        0.798249             0.879552   \n","14   [[1210, 21], [43, 439]]        0.847808             0.848739   \n","15   [[1200, 31], [74, 408]]        0.750069             0.840336   \n","16   [[1202, 29], [62, 420]]        0.760822             0.857143   \n","17     [[1231, 0], [0, 482]]        0.798249             0.879552   \n","18   [[1193, 38], [94, 388]]        0.766267             0.815126   \n","19    [[1222, 9], [16, 466]]        0.780121             0.815126   \n","20   [[1204, 27], [51, 431]]        0.772608             0.868347   \n","21     [[1231, 0], [0, 482]]        0.753377             0.859944   \n","22     [[1229, 2], [2, 480]]        0.674731             0.773109   \n","23   [[1221, 10], [20, 462]]        0.788599             0.806723   \n","24   [[1190, 41], [87, 395]]        0.765715             0.843137   \n","25    [[1224, 7], [20, 462]]        0.823201             0.831933   \n","26   [[1185, 46], [93, 389]]        0.780604             0.837535   \n","27   [[1175, 56], [77, 405]]        0.763372             0.868347   \n","28   [[1194, 37], [63, 419]]        0.831334             0.887955   \n","29     [[1231, 0], [0, 482]]        0.762614             0.859944   \n","30     [[1231, 0], [0, 482]]        0.778260             0.862745   \n","31   [[1212, 19], [41, 441]]        0.784188             0.843137   \n","32     [[1231, 0], [0, 482]]        0.754411             0.854342   \n","33   [[1192, 39], [73, 409]]        0.781086             0.859944   \n","34   [[1214, 17], [41, 441]]        0.748277             0.837535   \n","35     [[1231, 0], [1, 481]]        0.729046             0.829132   \n","36   [[1214, 17], [19, 463]]        0.754687             0.840336   \n","37  [[1179, 52], [103, 379]]        0.794183             0.851541   \n","38   [[1210, 21], [50, 432]]        0.820582             0.871148   \n","39    [[1226, 5], [19, 463]]        0.815205             0.862745   \n","40   [[1218, 13], [13, 469]]        0.749311             0.831933   \n","41   [[1206, 25], [46, 436]]        0.721878             0.817927   \n","42     [[1226, 5], [8, 474]]        0.781362             0.845938   \n","43    [[1227, 4], [15, 467]]        0.757720             0.873950   \n","44     [[1229, 2], [9, 473]]        0.726496             0.817927   \n","45     [[1229, 2], [4, 478]]        0.793424             0.843137   \n","46   [[1194, 37], [96, 386]]        0.754963             0.826331   \n","47   [[1215, 16], [45, 437]]        0.771161             0.801120   \n","48   [[1182, 49], [55, 427]]        0.764199             0.826331   \n","49    [[1227, 4], [14, 468]]        0.767990             0.868347   \n","50   [[1219, 12], [28, 454]]        0.787290             0.826331   \n","51   [[1202, 29], [61, 421]]        0.781362             0.845938   \n","52     [[1231, 0], [0, 482]]        0.756203             0.857143   \n","53     [[1231, 0], [0, 482]]        0.745933             0.862745   \n","54     [[1231, 0], [0, 482]]        0.746209             0.848739   \n","55     [[1228, 3], [7, 475]]        0.813138             0.873950   \n","56     [[1231, 0], [2, 480]]        0.734422             0.837535   \n","57   [[1188, 43], [82, 400]]        0.745175             0.854342   \n","58    [[1223, 8], [14, 468]]        0.782672             0.826331   \n","59   [[1217, 14], [22, 460]]        0.800110             0.831933   \n","60   [[1195, 36], [51, 431]]        0.793424             0.843137   \n","61   [[1219, 12], [33, 449]]        0.802936             0.829132   \n","62   [[1221, 10], [19, 463]]        0.802109             0.871148   \n","63    [[1222, 9], [14, 468]]        0.756479             0.843137   \n","64   [[1220, 11], [20, 462]]        0.786256             0.831933   \n","65     [[1231, 0], [7, 475]]        0.784671             0.865546   \n","\n","    validation_f1score  validation_precision  validation_recall  \\\n","0             0.576471              0.532609           0.628205   \n","1             0.584416              0.592105           0.576923   \n","2             0.657895              0.675676           0.641026   \n","3             0.683871              0.688312           0.679487   \n","4             0.596026              0.616438           0.576923   \n","5             0.648352              0.567308           0.756410   \n","6             0.596026              0.616438           0.576923   \n","7             0.641975              0.619048           0.666667   \n","8             0.680000              0.708333           0.653846   \n","9             0.702290              0.867925           0.589744   \n","10            0.625767              0.600000           0.653846   \n","11            0.585714              0.661290           0.525641   \n","12            0.680851              0.761905           0.615385   \n","13            0.703448              0.761194           0.653846   \n","14            0.709677              0.611111           0.846154   \n","15            0.617450              0.647887           0.589744   \n","16            0.643357              0.707692           0.589744   \n","17            0.703448              0.761194           0.653846   \n","18            0.616279              0.563830           0.679487   \n","19            0.629213              0.560000           0.717949   \n","20            0.666667              0.746032           0.602564   \n","21            0.637681              0.733333           0.564103   \n","22            0.490566              0.481481           0.500000   \n","23            0.631016              0.541284           0.756410   \n","24            0.636364              0.644737           0.628205   \n","25            0.677419              0.583333           0.807692   \n","26            0.646341              0.616279           0.679487   \n","27            0.656934              0.762712           0.576923   \n","28            0.740260              0.750000           0.730769   \n","29            0.647887              0.718750           0.589744   \n","30            0.666667              0.710145           0.628205   \n","31            0.654321              0.630952           0.679487   \n","32            0.633803              0.703125           0.576923   \n","33            0.666667              0.694444           0.641026   \n","34            0.613333              0.638889           0.589744   \n","35            0.585034              0.623188           0.551282   \n","36            0.622517              0.643836           0.602564   \n","37            0.670807              0.650602           0.692308   \n","38            0.712500              0.695122           0.730769   \n","39            0.699387              0.670588           0.730769   \n","40            0.610390              0.618421           0.602564   \n","41            0.569536              0.589041           0.551282   \n","42            0.654088              0.641975           0.666667   \n","43            0.656489              0.811321           0.551282   \n","44            0.575163              0.586667           0.564103   \n","45            0.662651              0.625000           0.705128   \n","46            0.612500              0.597561           0.628205   \n","47            0.612022              0.533333           0.717949   \n","48            0.621951              0.593023           0.653846   \n","49            0.661871              0.754098           0.589744   \n","50            0.643678              0.583333           0.717949   \n","51            0.654088              0.641975           0.666667   \n","52            0.638298              0.714286           0.576923   \n","53            0.631579              0.763636           0.538462   \n","54            0.619718              0.687500           0.564103   \n","55            0.709677              0.714286           0.705128   \n","56            0.597222              0.651515           0.551282   \n","57            0.623188              0.716667           0.551282   \n","58            0.639535              0.585106           0.705128   \n","59            0.659091              0.591837           0.743590   \n","60            0.662651              0.625000           0.705128   \n","61            0.659218              0.584158           0.756410   \n","62            0.697368              0.716216           0.679487   \n","63            0.626667              0.652778           0.602564   \n","64            0.647059              0.597826           0.705128   \n","65            0.675676              0.714286           0.641026   \n","\n","      validation_conf_mat         RUN_ID  \n","0   [[236, 43], [29, 49]]  sagittal_20_1  \n","1   [[248, 31], [33, 45]]  sagittal_21_1  \n","2   [[255, 24], [28, 50]]  sagittal_22_1  \n","3   [[255, 24], [25, 53]]  sagittal_23_1  \n","4   [[251, 28], [33, 45]]  sagittal_24_1  \n","5   [[234, 45], [19, 59]]  sagittal_25_1  \n","6   [[251, 28], [33, 45]]  sagittal_26_1  \n","7   [[247, 32], [26, 52]]  sagittal_27_1  \n","8   [[258, 21], [27, 51]]  sagittal_28_1  \n","9    [[272, 7], [32, 46]]  sagittal_29_1  \n","10  [[245, 34], [27, 51]]  sagittal_30_1  \n","11  [[258, 21], [37, 41]]  sagittal_70_1  \n","12  [[264, 15], [30, 48]]  sagittal_71_1  \n","13  [[263, 16], [27, 51]]  sagittal_72_1  \n","14  [[237, 42], [12, 66]]  sagittal_73_1  \n","15  [[254, 25], [32, 46]]  sagittal_74_1  \n","16  [[260, 19], [32, 46]]  sagittal_75_1  \n","17  [[263, 16], [27, 51]]  sagittal_76_1  \n","18  [[238, 41], [25, 53]]  sagittal_77_1  \n","19  [[235, 44], [22, 56]]  sagittal_78_1  \n","20  [[263, 16], [31, 47]]  sagittal_79_1  \n","21  [[263, 16], [34, 44]]  sagittal_80_1  \n","22  [[237, 42], [39, 39]]  sagittal_20_2  \n","23  [[229, 50], [19, 59]]  sagittal_21_2  \n","24  [[252, 27], [29, 49]]  sagittal_22_2  \n","25  [[234, 45], [15, 63]]  sagittal_23_2  \n","26  [[246, 33], [25, 53]]  sagittal_24_2  \n","27  [[265, 14], [33, 45]]  sagittal_25_2  \n","28  [[260, 19], [21, 57]]  sagittal_26_2  \n","29  [[261, 18], [32, 46]]  sagittal_27_2  \n","30  [[259, 20], [29, 49]]  sagittal_28_2  \n","31  [[248, 31], [25, 53]]  sagittal_29_2  \n","32  [[260, 19], [33, 45]]  sagittal_30_2  \n","33  [[257, 22], [28, 50]]  sagittal_70_2  \n","34  [[253, 26], [32, 46]]  sagittal_71_2  \n","35  [[253, 26], [35, 43]]  sagittal_72_2  \n","36  [[253, 26], [31, 47]]  sagittal_73_2  \n","37  [[250, 29], [24, 54]]  sagittal_74_2  \n","38  [[254, 25], [21, 57]]  sagittal_75_2  \n","39  [[251, 28], [21, 57]]  sagittal_76_2  \n","40  [[250, 29], [31, 47]]  sagittal_77_2  \n","41  [[249, 30], [35, 43]]  sagittal_78_2  \n","42  [[250, 29], [26, 52]]  sagittal_79_2  \n","43  [[269, 10], [35, 43]]  sagittal_80_2  \n","44  [[248, 31], [34, 44]]  sagittal_20_3  \n","45  [[246, 33], [23, 55]]  sagittal_21_3  \n","46  [[246, 33], [29, 49]]  sagittal_22_3  \n","47  [[230, 49], [22, 56]]  sagittal_23_3  \n","48  [[244, 35], [27, 51]]  sagittal_24_3  \n","49  [[264, 15], [32, 46]]  sagittal_25_3  \n","50  [[239, 40], [22, 56]]  sagittal_26_3  \n","51  [[250, 29], [26, 52]]  sagittal_27_3  \n","52  [[261, 18], [33, 45]]  sagittal_28_3  \n","53  [[266, 13], [36, 42]]  sagittal_29_3  \n","54  [[259, 20], [34, 44]]  sagittal_30_3  \n","55  [[257, 22], [23, 55]]  sagittal_70_3  \n","56  [[256, 23], [35, 43]]  sagittal_71_3  \n","57  [[262, 17], [35, 43]]  sagittal_72_3  \n","58  [[240, 39], [23, 55]]  sagittal_73_3  \n","59  [[239, 40], [20, 58]]  sagittal_74_3  \n","60  [[246, 33], [23, 55]]  sagittal_75_3  \n","61  [[237, 42], [19, 59]]  sagittal_76_3  \n","62  [[258, 21], [25, 53]]  sagittal_77_3  \n","63  [[254, 25], [31, 47]]  sagittal_78_3  \n","64  [[242, 37], [23, 55]]  sagittal_79_3  \n","65  [[259, 20], [28, 50]]  sagittal_80_3  "]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"IJMsMZ58wIrb"},"source":["# Trying simple experiments"]},{"cell_type":"markdown","metadata":{"id":"jd0FFIazKlp7"},"source":["## Coronal - Simple experiments exploring data augmentation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RqROFvX2Kpz5","executionInfo":{"status":"ok","timestamp":1634057824666,"user_tz":180,"elapsed":1792,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"ffc310c8-dc96-4a40-e417-181fd4f4b2e3"},"source":["mri_config = {\n","'orientation':'coronal',\n","'slice':50,\n","'num_samples':3,\n","'num_rotations':3,\n","'sampling_range':3,\n","'mri_reference':'/content/gdrive/MyDrive/Lucas_Thimoteo/data/reference/PROCESSED_MRI_REFERENCE_ALL_ORIENTATIONS_20211012_0206.csv',\n","'output_path':'/content/gdrive/MyDrive/Lucas_Thimoteo/data/mri/experiments/',\n","}\n","df = generate_mri_dataset_reference(mri_reference_path = mri_config['mri_reference'],\n","                                output_path = mri_config['output_path'],\n","                                orientation = mri_config['orientation'],\n","                                orientation_slice = mri_config['slice'],\n","                                num_sampled_images = mri_config['num_samples'],\n","                                sampling_range = mri_config['sampling_range'],\n","                                num_rotations = mri_config['num_rotations'],\n","                                save_reference_file = False)\n","df.shape"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating augmented samples...\n","Creating 2d image rotations...\n","Creating final reference file for prepared images...\n"]},{"output_type":"execute_result","data":{"text/plain":["(59664, 15)"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"lQDFDEhnavpO","executionInfo":{"status":"ok","timestamp":1634059168515,"user_tz":180,"elapsed":1318362,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"7d1cddb3-23d9-4ad0-9c0f-63f40fc51fb6"},"source":["cnn_config = {\n","  'type':'shallow',\n","  'name':'shallow_cnn'\n","}\n","os.chdir('/content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/src/model_training')\n","\n","df_prediction1  = run_cnn_experiment(model_type = cnn_config['type'],\n","                    model_name = cnn_config['name'],\n","                    classes = ['AD','CN'],\n","                    mri_reference = df,\n","                    prediction_dataset_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/data/reference/',\n","                    model_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/models/',\n","                    additional_experiment_params = None)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading untrained model...\n","NeuralNetwork(\n","  (features): Sequential(\n","    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n","    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU(inplace=True)\n","    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n","    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): ReLU(inplace=True)\n","    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (12): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (13): ReLU(inplace=True)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(8, 8))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=4096, out_features=512, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU(inplace=True)\n","    (4): Linear(in_features=512, out_features=1, bias=True)\n","  )\n",")\n","\n","Total number of trainable parameters: 2385329\n","Setting up experiment parameters...\n","Train size: 27408\n","Validation size: 357\n","Test size: 349\n","\n","---------------------------------------------------------------------\n","Running Epoch 1 of  100\n","Loss::      Train 0.0377      Validation 0.0415\n","AUC::       Train 0.4999      Validation 0.5000\n","Accuracy::  Train 0.7140      Validation 0.7815\n","F1::        Train 0.0200      Validation 0.0000\n","Precision:: Train 0.2778      Validation 0.0000\n","Recall::    Train 0.0104      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 1 took 319.88 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.5000\n","\n","---------------------------------------------------------------------\n","Running Epoch 2 of  100\n","Loss::      Train 0.0327      Validation 0.0337\n","AUC::       Train 0.5868      Validation 0.5321\n","Accuracy::  Train 0.7461      Validation 0.7955\n","F1::        Train 0.3303      Validation 0.1205\n","Precision:: Train 0.6403      Validation 1.0000\n","Recall::    Train 0.2225      Validation 0.0641\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 73   5]]\n","\n","Epoch 2 took 42.17 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.5321\n","\n","---------------------------------------------------------------------\n","Running Epoch 3 of  100\n","Loss::      Train 0.0260      Validation 0.0364\n","AUC::       Train 0.7496      Validation 0.5769\n","Accuracy::  Train 0.8272      Validation 0.8151\n","F1::        Train 0.6507      Validation 0.2667\n","Precision:: Train 0.7544      Validation 1.0000\n","Recall::    Train 0.5721      Validation 0.1538\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 66  12]]\n","\n","Epoch 3 took 43.40 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.5769\n","\n","---------------------------------------------------------------------\n","Running Epoch 4 of  100\n","Loss::      Train 0.0223      Validation 0.0515\n","AUC::       Train 0.8009      Validation 0.5385\n","Accuracy::  Train 0.8612      Validation 0.7983\n","F1::        Train 0.7288      Validation 0.1429\n","Precision:: Train 0.8094      Validation 1.0000\n","Recall::    Train 0.6629      Validation 0.0769\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 72   6]]\n","\n","Epoch 4 took 42.08 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 5 of  100\n","Loss::      Train 0.0195      Validation 0.0269\n","AUC::       Train 0.8344      Validation 0.7044\n","Accuracy::  Train 0.8828      Validation 0.8627\n","F1::        Train 0.7765      Validation 0.5739\n","Precision:: Train 0.8378      Validation 0.8919\n","Recall::    Train 0.7235      Validation 0.4231\n","Validation Confusion Matrix:\n"," [[275   4]\n"," [ 45  33]]\n","\n","Epoch 5 took 42.24 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.7044\n","\n","---------------------------------------------------------------------\n","Running Epoch 6 of  100\n","Loss::      Train 0.0162      Validation 0.0282\n","AUC::       Train 0.8655      Validation 0.7115\n","Accuracy::  Train 0.9048      Validation 0.8739\n","F1::        Train 0.8210      Validation 0.5946\n","Precision:: Train 0.8722      Validation 1.0000\n","Recall::    Train 0.7754      Validation 0.4231\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 45  33]]\n","\n","Epoch 6 took 42.34 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.7115\n","\n","---------------------------------------------------------------------\n","Running Epoch 7 of  100\n","Loss::      Train 0.0134      Validation 0.0346\n","AUC::       Train 0.8934      Validation 0.6667\n","Accuracy::  Train 0.9232      Validation 0.8543\n","F1::        Train 0.8581      Validation 0.5000\n","Precision:: Train 0.8938      Validation 1.0000\n","Recall::    Train 0.8252      Validation 0.3333\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 52  26]]\n","\n","Epoch 7 took 41.96 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 8 of  100\n","Loss::      Train 0.0106      Validation 0.0353\n","AUC::       Train 0.9178      Validation 0.7033\n","Accuracy::  Train 0.9406      Validation 0.8683\n","F1::        Train 0.8913      Validation 0.5766\n","Precision:: Train 0.9185      Validation 0.9697\n","Recall::    Train 0.8657      Validation 0.4103\n","Validation Confusion Matrix:\n"," [[278   1]\n"," [ 46  32]]\n","\n","Epoch 8 took 44.86 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 9 of  100\n","Loss::      Train 0.0084      Validation 0.0484\n","AUC::       Train 0.9394      Validation 0.6538\n","Accuracy::  Train 0.9546      Validation 0.8487\n","F1::        Train 0.9181      Validation 0.4706\n","Precision:: Train 0.9321      Validation 1.0000\n","Recall::    Train 0.9046      Validation 0.3077\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 54  24]]\n","\n","Epoch 9 took 43.18 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 10 of  100\n","Loss::      Train 0.0061      Validation 0.0402\n","AUC::       Train 0.9547      Validation 0.7546\n","Accuracy::  Train 0.9664      Validation 0.8908\n","F1::        Train 0.9396      Validation 0.6723\n","Precision:: Train 0.9516      Validation 0.9756\n","Recall::    Train 0.9279      Validation 0.5128\n","Validation Confusion Matrix:\n"," [[278   1]\n"," [ 38  40]]\n","\n","Epoch 10 took 42.64 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.7546\n","\n","---------------------------------------------------------------------\n","Running Epoch 11 of  100\n","Loss::      Train 0.0056      Validation 0.0504\n","AUC::       Train 0.9568      Validation 0.6851\n","Accuracy::  Train 0.9683      Validation 0.8543\n","F1::        Train 0.9430      Validation 0.5357\n","Precision:: Train 0.9558      Validation 0.8824\n","Recall::    Train 0.9305      Validation 0.3846\n","Validation Confusion Matrix:\n"," [[275   4]\n"," [ 48  30]]\n","\n","Epoch 11 took 42.98 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 12 of  100\n","Loss::      Train 0.0036      Validation 0.0582\n","AUC::       Train 0.9719      Validation 0.7080\n","Accuracy::  Train 0.9796      Validation 0.8683\n","F1::        Train 0.9634      Validation 0.5841\n","Precision:: Train 0.9725      Validation 0.9429\n","Recall::    Train 0.9544      Validation 0.4231\n","Validation Confusion Matrix:\n"," [[277   2]\n"," [ 45  33]]\n","\n","Epoch 12 took 42.69 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 13 of  100\n","Loss::      Train 0.0034      Validation 0.0415\n","AUC::       Train 0.9757      Validation 0.7731\n","Accuracy::  Train 0.9815      Validation 0.8908\n","F1::        Train 0.9669      Validation 0.6929\n","Precision:: Train 0.9712      Validation 0.8980\n","Recall::    Train 0.9627      Validation 0.5641\n","Validation Confusion Matrix:\n"," [[274   5]\n"," [ 34  44]]\n","\n","Epoch 13 took 42.64 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.7731\n","\n","---------------------------------------------------------------------\n","Running Epoch 14 of  100\n","Loss::      Train 0.0032      Validation 0.0611\n","AUC::       Train 0.9787      Validation 0.7264\n","Accuracy::  Train 0.9841      Validation 0.8683\n","F1::        Train 0.9716      Validation 0.6116\n","Precision:: Train 0.9769      Validation 0.8605\n","Recall::    Train 0.9663      Validation 0.4744\n","Validation Confusion Matrix:\n"," [[273   6]\n"," [ 41  37]]\n","\n","Epoch 14 took 42.18 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 15 of  100\n","Loss::      Train 0.0028      Validation 0.0530\n","AUC::       Train 0.9767      Validation 0.7531\n","Accuracy::  Train 0.9828      Validation 0.8739\n","F1::        Train 0.9692      Validation 0.6512\n","Precision:: Train 0.9758      Validation 0.8235\n","Recall::    Train 0.9627      Validation 0.5385\n","Validation Confusion Matrix:\n"," [[270   9]\n"," [ 36  42]]\n","\n","Epoch 15 took 43.28 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 16 of  100\n","Loss::      Train 0.0017      Validation 0.0693\n","AUC::       Train 0.9884      Validation 0.7182\n","Accuracy::  Train 0.9908      Validation 0.8627\n","F1::        Train 0.9836      Validation 0.5950\n","Precision:: Train 0.9844      Validation 0.8372\n","Recall::    Train 0.9829      Validation 0.4615\n","Validation Confusion Matrix:\n"," [[272   7]\n"," [ 42  36]]\n","\n","Epoch 16 took 41.88 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 17 of  100\n","Loss::      Train 0.0018      Validation 0.0521\n","AUC::       Train 0.9872      Validation 0.7552\n","Accuracy::  Train 0.9902      Validation 0.8627\n","F1::        Train 0.9826      Validation 0.6423\n","Precision:: Train 0.9849      Validation 0.7458\n","Recall::    Train 0.9803      Validation 0.5641\n","Validation Confusion Matrix:\n"," [[264  15]\n"," [ 34  44]]\n","\n","Epoch 17 took 42.47 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 18 of  100\n","Loss::      Train 0.0022      Validation 0.0675\n","AUC::       Train 0.9842      Validation 0.7218\n","Accuracy::  Train 0.9885      Validation 0.8683\n","F1::        Train 0.9794      Validation 0.6050\n","Precision:: Train 0.9843      Validation 0.8780\n","Recall::    Train 0.9746      Validation 0.4615\n","Validation Confusion Matrix:\n"," [[274   5]\n"," [ 42  36]]\n","\n","Epoch 18 took 44.38 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 19 of  100\n","Loss::      Train 0.0022      Validation 0.0719\n","AUC::       Train 0.9835      Validation 0.7239\n","Accuracy::  Train 0.9874      Validation 0.8571\n","F1::        Train 0.9776      Validation 0.5984\n","Precision:: Train 0.9807      Validation 0.7755\n","Recall::    Train 0.9746      Validation 0.4872\n","Validation Confusion Matrix:\n"," [[268  11]\n"," [ 40  38]]\n","\n","Epoch 19 took 42.51 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 20 of  100\n","Loss::      Train 0.0010      Validation 0.0618\n","AUC::       Train 0.9930      Validation 0.7423\n","Accuracy::  Train 0.9945      Validation 0.8571\n","F1::        Train 0.9901      Validation 0.6222\n","Precision:: Train 0.9907      Validation 0.7368\n","Recall::    Train 0.9896      Validation 0.5385\n","Validation Confusion Matrix:\n"," [[264  15]\n"," [ 36  42]]\n","\n","Epoch 20 took 42.59 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 21 of  100\n","Loss::      Train 0.0018      Validation 0.0986\n","AUC::       Train 0.9860      Validation 0.6585\n","Accuracy::  Train 0.9896      Validation 0.8487\n","F1::        Train 0.9815      Validation 0.4808\n","Precision:: Train 0.9854      Validation 0.9615\n","Recall::    Train 0.9777      Validation 0.3205\n","Validation Confusion Matrix:\n"," [[278   1]\n"," [ 53  25]]\n","\n","Epoch 21 took 42.73 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 22 of  100\n","Loss::      Train 0.0023      Validation 0.0623\n","AUC::       Train 0.9835      Validation 0.7506\n","Accuracy::  Train 0.9874      Validation 0.8627\n","F1::        Train 0.9776      Validation 0.6370\n","Precision:: Train 0.9807      Validation 0.7544\n","Recall::    Train 0.9746      Validation 0.5513\n","Validation Confusion Matrix:\n"," [[265  14]\n"," [ 35  43]]\n","\n","Epoch 22 took 42.37 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 23 of  100\n","Loss::      Train 0.0010      Validation 0.0642\n","AUC::       Train 0.9920      Validation 0.7423\n","Accuracy::  Train 0.9940      Validation 0.8571\n","F1::        Train 0.9893      Validation 0.6222\n","Precision:: Train 0.9912      Validation 0.7368\n","Recall::    Train 0.9876      Validation 0.5385\n","Validation Confusion Matrix:\n"," [[264  15]\n"," [ 36  42]]\n","\n","Epoch 23 took 42.46 seconds\n","---------------------------------------------------------------------\n","\n","Exiting training... It hit early stopping criteria of: 10 epochs\n","Saving model at: /content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/models/\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","-------------------------------\n","Best metrics for validation set on Epoch 13:\n","Loss::      0.0415\n","AUC::       0.7731\n","Accuracy::  0.8908\n","F1::        0.6929\n","Precision:: 0.8980\n","Recall::    0.5641\n","Confusion Matrix:\n"," [[274   5]\n"," [ 34  44]]\n","-------------------------------\n","\n","Performance for test set:\n","Loss::      0.0758\n","AUC::       0.6227\n","Accuracy::  0.8309\n","F1::        0.3918\n","Precision:: 0.6129\n","Recall::    0.2879\n","Confusion Matrix:\n"," [[271  12]\n"," [ 47  19]]\n","Saving predictions from trained model...\n","Computing Predictions for train set.\n","dataset size: (27408, 15)\n","Performance for test set:\n","Loss::      0.0170\n","AUC::       0.8975\n","Accuracy::  0.9418\n","F1::        0.8850\n","Precision:: 0.9961\n","Recall::    0.7962\n","Confusion Matrix:\n"," [[19672    24]\n"," [ 1572  6140]]\n","Computing Predictions for validation set.\n","dataset size: (357, 15)\n","Performance for test set:\n","Loss::      0.0655\n","AUC::       0.7588\n","Accuracy::  0.8683\n","F1::        0.6519\n","Precision:: 0.7719\n","Recall::    0.5641\n","Confusion Matrix:\n"," [[266  13]\n"," [ 34  44]]\n","Computing Predictions for test set.\n","dataset size: (349, 15)\n","Performance for test set:\n","Loss::      0.0758\n","AUC::       0.6227\n","Accuracy::  0.8309\n","F1::        0.3918\n","Precision:: 0.6129\n","Recall::    0.2879\n","Confusion Matrix:\n"," [[271  12]\n"," [ 47  19]]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q1afIvWWi-z9","executionInfo":{"status":"ok","timestamp":1634059707838,"user_tz":180,"elapsed":1582,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"8466baa7-e972-49a9-baaf-045a0cf06f40"},"source":["mri_config = {\n","'orientation':'coronal',\n","'slice':50,\n","'num_samples':5,\n","'num_rotations':0,\n","'sampling_range':3,\n","'mri_reference':'/content/gdrive/MyDrive/Lucas_Thimoteo/data/reference/PROCESSED_MRI_REFERENCE_ALL_ORIENTATIONS_20211012_0206.csv',\n","'output_path':'/content/gdrive/MyDrive/Lucas_Thimoteo/data/mri/experiments/',\n","}\n","df = generate_mri_dataset_reference(mri_reference_path = mri_config['mri_reference'],\n","                                output_path = mri_config['output_path'],\n","                                orientation = mri_config['orientation'],\n","                                orientation_slice = mri_config['slice'],\n","                                num_sampled_images = mri_config['num_samples'],\n","                                sampling_range = mri_config['sampling_range'],\n","                                num_rotations = mri_config['num_rotations'],\n","                                save_reference_file = False)\n","df.shape"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating augmented samples...\n","Creating final reference file for prepared images...\n"]},{"output_type":"execute_result","data":{"text/plain":["(22374, 14)"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"NahNxSLji-tF","executionInfo":{"status":"ok","timestamp":1634060682556,"user_tz":180,"elapsed":967234,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"0baca993-52fe-4e3c-fbf8-34dfc8fbde10"},"source":["cnn_config = {\n","  'type':'shallow',\n","  'name':'shallow_cnn'\n","}\n","os.chdir('/content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/src/model_training')\n","\n","df_prediction2  = run_cnn_experiment(model_type = cnn_config['type'],\n","                    model_name = cnn_config['name'],\n","                    classes = ['AD','CN'],\n","                    mri_reference = df,\n","                    prediction_dataset_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/data/reference/',\n","                    model_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/models/',\n","                    additional_experiment_params = None)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading untrained model...\n","NeuralNetwork(\n","  (features): Sequential(\n","    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n","    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU(inplace=True)\n","    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n","    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): ReLU(inplace=True)\n","    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (12): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (13): ReLU(inplace=True)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(8, 8))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=4096, out_features=512, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU(inplace=True)\n","    (4): Linear(in_features=512, out_features=1, bias=True)\n","  )\n",")\n","\n","Total number of trainable parameters: 2385329\n","Setting up experiment parameters...\n","Train size: 10278\n","Validation size: 357\n","Test size: 349\n","\n","---------------------------------------------------------------------\n","Running Epoch 1 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0371      Validation 0.0375\n","AUC::       Train 0.5000      Validation 0.5000\n","Accuracy::  Train 0.7186      Validation 0.7815\n","F1::        Train 0.0000      Validation 0.0000\n","Precision:: Train 0.0000      Validation 0.0000\n","Recall::    Train 0.0000      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 1 took 196.52 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.5000\n","\n","---------------------------------------------------------------------\n","Running Epoch 2 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    self._shutdown_workers()\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","Traceback (most recent call last):\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0343      Validation 0.0332\n","AUC::       Train 0.5203      Validation 0.5000\n","Accuracy::  Train 0.7169      Validation 0.7815\n","F1::        Train 0.1235      Validation 0.0000\n","Precision:: Train 0.4790      Validation 0.0000\n","Recall::    Train 0.0709      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 2 took 17.16 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 3 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","Traceback (most recent call last):\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","AssertionError: can only test a child process\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","AssertionError: can only test a child process\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0302      Validation 0.0278\n","AUC::       Train 0.6429      Validation 0.6090\n","Accuracy::  Train 0.7702      Validation 0.8291\n","F1::        Train 0.4627      Validation 0.3579\n","Precision:: Train 0.6762      Validation 1.0000\n","Recall::    Train 0.3517      Validation 0.2179\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 61  17]]\n","\n","Epoch 3 took 17.06 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.6090\n","\n","---------------------------------------------------------------------\n","Running Epoch 4 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Traceback (most recent call last):\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","AssertionError: can only test a child process\n","Traceback (most recent call last):\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    if w.is_alive():\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0249      Validation 0.0253\n","AUC::       Train 0.7524      Validation 0.6731\n","Accuracy::  Train 0.8259      Validation 0.8571\n","F1::        Train 0.6539      Validation 0.5143\n","Precision:: Train 0.7422      Validation 1.0000\n","Recall::    Train 0.5844      Validation 0.3462\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 51  27]]\n","\n","Epoch 4 took 17.44 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.6731\n","\n","---------------------------------------------------------------------\n","Running Epoch 5 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","Traceback (most recent call last):\n","    if w.is_alive():\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0213      Validation 0.0271\n","AUC::       Train 0.7966      Validation 0.6731\n","Accuracy::  Train 0.8538      Validation 0.8571\n","F1::        Train 0.7193      Validation 0.5143\n","Precision:: Train 0.7820      Validation 1.0000\n","Recall::    Train 0.6660      Validation 0.3462\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 51  27]]\n","\n","Epoch 5 took 17.16 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 6 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Traceback (most recent call last):\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    self._shutdown_workers()\n","    if w.is_alive():\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    if w.is_alive():\n","    self._shutdown_workers()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    if w.is_alive():\n","AssertionError: can only test a child process\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0184      Validation 0.0297\n","AUC::       Train 0.8326      Validation 0.6713\n","Accuracy::  Train 0.8777      Validation 0.8543\n","F1::        Train 0.7705      Validation 0.5094\n","Precision:: Train 0.8162      Validation 0.9643\n","Recall::    Train 0.7296      Validation 0.3462\n","Validation Confusion Matrix:\n"," [[278   1]\n"," [ 51  27]]\n","\n","Epoch 6 took 17.01 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 7 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Traceback (most recent call last):\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    self._shutdown_workers()\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    if w.is_alive():\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    self._shutdown_workers()\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0155      Validation 0.0349\n","AUC::       Train 0.8693      Validation 0.6503\n","Accuracy::  Train 0.9028      Validation 0.8431\n","F1::        Train 0.8211      Validation 0.4615\n","Precision:: Train 0.8517      Validation 0.9231\n","Recall::    Train 0.7925      Validation 0.3077\n","Validation Confusion Matrix:\n"," [[277   2]\n"," [ 54  24]]\n","\n","Epoch 7 took 17.27 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 8 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","Traceback (most recent call last):\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0123      Validation 0.0390\n","AUC::       Train 0.9063      Validation 0.6374\n","Accuracy::  Train 0.9292      Validation 0.8375\n","F1::        Train 0.8716      Validation 0.4314\n","Precision:: Train 0.8898      Validation 0.9167\n","Recall::    Train 0.8541      Validation 0.2821\n","Validation Confusion Matrix:\n"," [[277   2]\n"," [ 56  22]]\n","\n","Epoch 8 took 17.67 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 9 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    self._shutdown_workers()\n","    self._shutdown_workers()\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    self._shutdown_workers()\n","    if w.is_alive():\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    self._shutdown_workers()\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    if w.is_alive():\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0100      Validation 0.0422\n","AUC::       Train 0.9313      Validation 0.6356\n","Accuracy::  Train 0.9467      Validation 0.8347\n","F1::        Train 0.9044      Validation 0.4272\n","Precision:: Train 0.9127      Validation 0.8800\n","Recall::    Train 0.8963      Validation 0.2821\n","Validation Confusion Matrix:\n"," [[276   3]\n"," [ 56  22]]\n","\n","Epoch 9 took 17.12 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 10 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    self._shutdown_workers()\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Traceback (most recent call last):\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    self._shutdown_workers()\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0079      Validation 0.0455\n","AUC::       Train 0.9488      Validation 0.6403\n","Accuracy::  Train 0.9594      Validation 0.8347\n","F1::        Train 0.9277      Validation 0.4381\n","Precision:: Train 0.9307      Validation 0.8519\n","Recall::    Train 0.9246      Validation 0.2949\n","Validation Confusion Matrix:\n"," [[275   4]\n"," [ 55  23]]\n","\n","Epoch 10 took 16.94 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 11 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","Traceback (most recent call last):\n","    if w.is_alive():\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    self._shutdown_workers()\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","Traceback (most recent call last):\n","    if w.is_alive():\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    self._shutdown_workers()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","Traceback (most recent call last):\n","AssertionError: can only test a child process\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0060      Validation 0.0504\n","AUC::       Train 0.9652      Validation 0.6339\n","Accuracy::  Train 0.9717      Validation 0.8319\n","F1::        Train 0.9497      Validation 0.4231\n","Precision:: Train 0.9492      Validation 0.8462\n","Recall::    Train 0.9502      Validation 0.2821\n","Validation Confusion Matrix:\n"," [[275   4]\n"," [ 56  22]]\n","\n","Epoch 11 took 17.17 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 12 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    self._shutdown_workers()\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    if w.is_alive():\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    self._shutdown_workers()\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","AssertionError: can only test a child process\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","AssertionError: can only test a child process\n","    if w.is_alive():\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0046      Validation 0.1028\n","AUC::       Train 0.9723      Validation 0.5010\n","Accuracy::  Train 0.9771      Validation 0.7759\n","F1::        Train 0.9594      Validation 0.0244\n","Precision:: Train 0.9576      Validation 0.2500\n","Recall::    Train 0.9613      Validation 0.0128\n","Validation Confusion Matrix:\n"," [[276   3]\n"," [ 77   1]]\n","\n","Epoch 12 took 17.51 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 13 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    if w.is_alive():\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Traceback (most recent call last):\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    self._shutdown_workers()\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","AssertionError: can only test a child process\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0041      Validation 0.0719\n","AUC::       Train 0.9747      Validation 0.5769\n","Accuracy::  Train 0.9789      Validation 0.8151\n","F1::        Train 0.9626      Validation 0.2667\n","Precision:: Train 0.9601      Validation 1.0000\n","Recall::    Train 0.9651      Validation 0.1538\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 66  12]]\n","\n","Epoch 13 took 17.24 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 14 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","Traceback (most recent call last):\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    if w.is_alive():\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0035      Validation 0.0505\n","AUC::       Train 0.9748      Validation 0.7054\n","Accuracy::  Train 0.9797      Validation 0.8571\n","F1::        Train 0.9639      Validation 0.5714\n","Precision:: Train 0.9640      Validation 0.8293\n","Recall::    Train 0.9637      Validation 0.4359\n","Validation Confusion Matrix:\n"," [[272   7]\n"," [ 44  34]]\n","\n","Epoch 14 took 17.46 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.7054\n","\n","---------------------------------------------------------------------\n","Running Epoch 15 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Traceback (most recent call last):\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    if w.is_alive():\n","AssertionError: can only test a child process\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0029      Validation 0.0710\n","AUC::       Train 0.9799      Validation 0.6649\n","Accuracy::  Train 0.9823      Validation 0.8515\n","F1::        Train 0.9687      Validation 0.4952\n","Precision:: Train 0.9631      Validation 0.9630\n","Recall::    Train 0.9744      Validation 0.3333\n","Validation Confusion Matrix:\n"," [[278   1]\n"," [ 52  26]]\n","\n","Epoch 15 took 16.69 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 16 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","Traceback (most recent call last):\n","    if w.is_alive():\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Traceback (most recent call last):\n","    self._shutdown_workers()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    if w.is_alive():\n","    self._shutdown_workers()\n","AssertionError: can only test a child process\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    if w.is_alive():\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","AssertionError: can only test a child process\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0027      Validation 0.0626\n","AUC::       Train 0.9813      Validation 0.6734\n","Accuracy::  Train 0.9841      Validation 0.8431\n","F1::        Train 0.9719      Validation 0.5088\n","Precision:: Train 0.9691      Validation 0.8056\n","Recall::    Train 0.9748      Validation 0.3718\n","Validation Confusion Matrix:\n"," [[272   7]\n"," [ 49  29]]\n","\n","Epoch 16 took 17.36 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 17 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    self._shutdown_workers()\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    if w.is_alive():\n","Traceback (most recent call last):\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","AssertionError: can only test a child process\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    self._shutdown_workers()\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0026      Validation 0.0694\n","AUC::       Train 0.9804      Validation 0.6239\n","Accuracy::  Train 0.9833      Validation 0.8235\n","F1::        Train 0.9704      Validation 0.4000\n","Precision:: Train 0.9670      Validation 0.7778\n","Recall::    Train 0.9737      Validation 0.2692\n","Validation Confusion Matrix:\n"," [[273   6]\n"," [ 57  21]]\n","\n","Epoch 17 took 17.25 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 18 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Traceback (most recent call last):\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","AssertionError: can only test a child process\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0032      Validation 0.0508\n","AUC::       Train 0.9768      Validation 0.7359\n","Accuracy::  Train 0.9814      Validation 0.8543\n","F1::        Train 0.9669      Validation 0.6119\n","Precision:: Train 0.9678      Validation 0.7321\n","Recall::    Train 0.9661      Validation 0.5256\n","Validation Confusion Matrix:\n"," [[264  15]\n"," [ 37  41]]\n","\n","Epoch 18 took 16.65 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.7359\n","\n","---------------------------------------------------------------------\n","Running Epoch 19 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","AssertionError: can only test a child process\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","Traceback (most recent call last):\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0026      Validation 0.0485\n","AUC::       Train 0.9813      Validation 0.7434\n","Accuracy::  Train 0.9862      Validation 0.8515\n","F1::        Train 0.9753      Validation 0.6187\n","Precision:: Train 0.9804      Validation 0.7049\n","Recall::    Train 0.9703      Validation 0.5513\n","Validation Confusion Matrix:\n"," [[261  18]\n"," [ 35  43]]\n","\n","Epoch 19 took 17.52 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.7434\n","\n","---------------------------------------------------------------------\n","Running Epoch 20 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Traceback (most recent call last):\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0023      Validation 0.0586\n","AUC::       Train 0.9841      Validation 0.7388\n","Accuracy::  Train 0.9874      Validation 0.8011\n","F1::        Train 0.9777      Validation 0.5799\n","Precision:: Train 0.9789      Validation 0.5385\n","Recall::    Train 0.9765      Validation 0.6282\n","Validation Confusion Matrix:\n"," [[237  42]\n"," [ 29  49]]\n","\n","Epoch 20 took 17.86 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 21 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","Traceback (most recent call last):\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","AssertionError: can only test a child process\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0014      Validation 0.0549\n","AUC::       Train 0.9889      Validation 0.7452\n","Accuracy::  Train 0.9914      Validation 0.8039\n","F1::        Train 0.9848      Validation 0.5882\n","Precision:: Train 0.9865      Validation 0.5435\n","Recall::    Train 0.9831      Validation 0.6410\n","Validation Confusion Matrix:\n"," [[237  42]\n"," [ 28  50]]\n","\n","Epoch 21 took 16.87 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.7452\n","\n","---------------------------------------------------------------------\n","Running Epoch 22 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    self._shutdown_workers()\n","    self._shutdown_workers()\n","    if w.is_alive():\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    if w.is_alive():\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","AssertionError: can only test a child process\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0013      Validation 0.0563\n","AUC::       Train 0.9918      Validation 0.7642\n","Accuracy::  Train 0.9935      Validation 0.8263\n","F1::        Train 0.9884      Validation 0.6220\n","Precision:: Train 0.9889      Validation 0.5930\n","Recall::    Train 0.9879      Validation 0.6538\n","Validation Confusion Matrix:\n"," [[244  35]\n"," [ 27  51]]\n","\n","Epoch 22 took 16.83 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.7642\n","\n","---------------------------------------------------------------------\n","Running Epoch 23 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","Traceback (most recent call last):\n","    if w.is_alive():\n","    self._shutdown_workers()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","AssertionError: can only test a child process\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","AssertionError: can only test a child process\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0012      Validation 0.0633\n","AUC::       Train 0.9910      Validation 0.7159\n","Accuracy::  Train 0.9927      Validation 0.8375\n","F1::        Train 0.9870      Validation 0.5735\n","Precision:: Train 0.9869      Validation 0.6724\n","Recall::    Train 0.9872      Validation 0.5000\n","Validation Confusion Matrix:\n"," [[260  19]\n"," [ 39  39]]\n","\n","Epoch 23 took 17.80 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 24 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    if w.is_alive():\n","Traceback (most recent call last):\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    self._shutdown_workers()\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","AssertionError: can only test a child process\n","    self._shutdown_workers()\n","    if w.is_alive():\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0016      Validation 0.0642\n","AUC::       Train 0.9875      Validation 0.7524\n","Accuracy::  Train 0.9899      Validation 0.8151\n","F1::        Train 0.9820      Validation 0.6024\n","Precision:: Train 0.9820      Validation 0.5682\n","Recall::    Train 0.9820      Validation 0.6410\n","Validation Confusion Matrix:\n"," [[241  38]\n"," [ 28  50]]\n","\n","Epoch 24 took 17.53 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 25 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","    self._shutdown_workers()\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","    if w.is_alive():\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","AssertionError: can only test a child process\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","Traceback (most recent call last):\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    if w.is_alive():\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    if w.is_alive():\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","AssertionError: can only test a child process\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Traceback (most recent call last):\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","AssertionError: can only test a child process\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0011      Validation 0.0630\n","AUC::       Train 0.9924      Validation 0.7319\n","Accuracy::  Train 0.9940      Validation 0.8263\n","F1::        Train 0.9893      Validation 0.5867\n","Precision:: Train 0.9896      Validation 0.6111\n","Recall::    Train 0.9889      Validation 0.5641\n","Validation Confusion Matrix:\n"," [[251  28]\n"," [ 34  44]]\n","\n","Epoch 25 took 17.24 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 26 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","Traceback (most recent call last):\n","AssertionError: can only test a child process\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","AssertionError: can only test a child process\n","    self._shutdown_workers()\n","    if w.is_alive():\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    if w.is_alive():\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","AssertionError: can only test a child process\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    if w.is_alive():\n","    self._shutdown_workers()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    self._shutdown_workers()\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","    if w.is_alive():\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0010      Validation 0.0602\n","AUC::       Train 0.9932      Validation 0.7575\n","Accuracy::  Train 0.9948      Validation 0.8375\n","F1::        Train 0.9908      Validation 0.6234\n","Precision:: Train 0.9924      Validation 0.6316\n","Recall::    Train 0.9893      Validation 0.6154\n","Validation Confusion Matrix:\n"," [[251  28]\n"," [ 30  48]]\n","\n","Epoch 26 took 17.37 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 27 of  100\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Traceback (most recent call last):\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    if w.is_alive():\n","AssertionError: can only test a child process\n","    self._shutdown_workers()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9bb7512320>\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","Traceback (most recent call last):\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","AssertionError: can only test a child process\n","Traceback (most recent call last):\n","    if w.is_alive():\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    self._shutdown_workers()\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","AssertionError: can only test a child process\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","AssertionError: can only test a child process\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n"]},{"output_type":"stream","name":"stdout","text":["Loss::      Train 0.0007      Validation 0.0676\n","AUC::       Train 0.9945      Validation 0.7714\n","Accuracy::  Train 0.9953      Validation 0.8375\n","F1::        Train 0.9917      Validation 0.6375\n","Precision:: Train 0.9907      Validation 0.6220\n","Recall::    Train 0.9927      Validation 0.6538\n","Validation Confusion Matrix:\n"," [[248  31]\n"," [ 27  51]]\n","\n","Epoch 27 took 18.21 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.7714\n","\n","---------------------------------------------------------------------\n","Running Epoch 28 of  100\n","Loss::      Train 0.0017      Validation 0.0604\n","AUC::       Train 0.9898      Validation 0.7688\n","Accuracy::  Train 0.9920      Validation 0.8263\n","F1::        Train 0.9858      Validation 0.6265\n","Precision:: Train 0.9868      Validation 0.5909\n","Recall::    Train 0.9848      Validation 0.6667\n","Validation Confusion Matrix:\n"," [[243  36]\n"," [ 26  52]]\n","\n","Epoch 28 took 16.69 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 29 of  100\n","Loss::      Train 0.0018      Validation 0.0461\n","AUC::       Train 0.9880      Validation 0.7259\n","Accuracy::  Train 0.9907      Validation 0.8459\n","F1::        Train 0.9834      Validation 0.5926\n","Precision:: Train 0.9847      Validation 0.7018\n","Recall::    Train 0.9820      Validation 0.5128\n","Validation Confusion Matrix:\n"," [[262  17]\n"," [ 38  40]]\n","\n","Epoch 29 took 16.76 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 30 of  100\n","Loss::      Train 0.0014      Validation 0.0583\n","AUC::       Train 0.9898      Validation 0.7591\n","Accuracy::  Train 0.9920      Validation 0.8039\n","F1::        Train 0.9858      Validation 0.6023\n","Precision:: Train 0.9868      Validation 0.5408\n","Recall::    Train 0.9848      Validation 0.6795\n","Validation Confusion Matrix:\n"," [[234  45]\n"," [ 25  53]]\n","\n","Epoch 30 took 16.93 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 31 of  100\n","Loss::      Train 0.0005      Validation 0.0656\n","AUC::       Train 0.9961      Validation 0.7249\n","Accuracy::  Train 0.9970      Validation 0.8515\n","F1::        Train 0.9946      Validation 0.5954\n","Precision:: Train 0.9952      Validation 0.7358\n","Recall::    Train 0.9941      Validation 0.5000\n","Validation Confusion Matrix:\n"," [[265  14]\n"," [ 39  39]]\n","\n","Epoch 31 took 16.81 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 32 of  100\n","Loss::      Train 0.0004      Validation 0.0560\n","AUC::       Train 0.9973      Validation 0.7714\n","Accuracy::  Train 0.9980      Validation 0.8375\n","F1::        Train 0.9964      Validation 0.6375\n","Precision:: Train 0.9969      Validation 0.6220\n","Recall::    Train 0.9959      Validation 0.6538\n","Validation Confusion Matrix:\n"," [[248  31]\n"," [ 27  51]]\n","\n","Epoch 32 took 16.94 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 33 of  100\n","Loss::      Train 0.0004      Validation 0.0530\n","AUC::       Train 0.9974      Validation 0.7690\n","Accuracy::  Train 0.9978      Validation 0.8627\n","F1::        Train 0.9960      Validation 0.6573\n","Precision:: Train 0.9955      Validation 0.7231\n","Recall::    Train 0.9965      Validation 0.6026\n","Validation Confusion Matrix:\n"," [[261  18]\n"," [ 31  47]]\n","\n","Epoch 33 took 17.09 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 34 of  100\n","Loss::      Train 0.0006      Validation 0.0540\n","AUC::       Train 0.9967      Validation 0.7490\n","Accuracy::  Train 0.9972      Validation 0.8459\n","F1::        Train 0.9950      Validation 0.6207\n","Precision:: Train 0.9945      Validation 0.6716\n","Recall::    Train 0.9955      Validation 0.5769\n","Validation Confusion Matrix:\n"," [[257  22]\n"," [ 33  45]]\n","\n","Epoch 34 took 16.35 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 35 of  100\n","Loss::      Train 0.0011      Validation 0.0510\n","AUC::       Train 0.9914      Validation 0.8080\n","Accuracy::  Train 0.9931      Validation 0.8515\n","F1::        Train 0.9877      Validation 0.6826\n","Precision:: Train 0.9879      Validation 0.6404\n","Recall::    Train 0.9876      Validation 0.7308\n","Validation Confusion Matrix:\n"," [[247  32]\n"," [ 21  57]]\n","\n","Epoch 35 took 17.70 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.8080\n","\n","---------------------------------------------------------------------\n","Running Epoch 36 of  100\n","Loss::      Train 0.0003      Validation 0.0710\n","AUC::       Train 0.9974      Validation 0.7873\n","Accuracy::  Train 0.9981      Validation 0.8263\n","F1::        Train 0.9965      Validation 0.6437\n","Precision:: Train 0.9972      Validation 0.5833\n","Recall::    Train 0.9959      Validation 0.7179\n","Validation Confusion Matrix:\n"," [[239  40]\n"," [ 22  56]]\n","\n","Epoch 36 took 16.45 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 37 of  100\n","Loss::      Train 0.0007      Validation 0.0514\n","AUC::       Train 0.9944      Validation 0.7793\n","Accuracy::  Train 0.9954      Validation 0.8571\n","F1::        Train 0.9919      Validation 0.6623\n","Precision:: Train 0.9917      Validation 0.6849\n","Recall::    Train 0.9920      Validation 0.6410\n","Validation Confusion Matrix:\n"," [[256  23]\n"," [ 28  50]]\n","\n","Epoch 37 took 16.79 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 38 of  100\n","Loss::      Train 0.0007      Validation 0.0590\n","AUC::       Train 0.9941      Validation 0.7488\n","Accuracy::  Train 0.9952      Validation 0.8599\n","F1::        Train 0.9915      Validation 0.6324\n","Precision:: Train 0.9917      Validation 0.7414\n","Recall::    Train 0.9914      Validation 0.5513\n","Validation Confusion Matrix:\n"," [[264  15]\n"," [ 35  43]]\n","\n","Epoch 38 took 17.02 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 39 of  100\n","Loss::      Train 0.0002      Validation 0.0825\n","AUC::       Train 0.9980      Validation 0.6936\n","Accuracy::  Train 0.9985      Validation 0.8459\n","F1::        Train 0.9974      Validation 0.5455\n","Precision:: Train 0.9979      Validation 0.7674\n","Recall::    Train 0.9969      Validation 0.4231\n","Validation Confusion Matrix:\n"," [[269  10]\n"," [ 45  33]]\n","\n","Epoch 39 took 17.24 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 40 of  100\n","Loss::      Train 0.0001      Validation 0.0640\n","AUC::       Train 0.9992      Validation 0.7793\n","Accuracy::  Train 0.9995      Validation 0.8571\n","F1::        Train 0.9991      Validation 0.6623\n","Precision:: Train 0.9997      Validation 0.6849\n","Recall::    Train 0.9986      Validation 0.6410\n","Validation Confusion Matrix:\n"," [[256  23]\n"," [ 28  50]]\n","\n","Epoch 40 took 16.42 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 41 of  100\n","Loss::      Train 0.0026      Validation 0.0491\n","AUC::       Train 0.9859      Validation 0.7757\n","Accuracy::  Train 0.9888      Validation 0.8515\n","F1::        Train 0.9801      Validation 0.6536\n","Precision:: Train 0.9809      Validation 0.6667\n","Recall::    Train 0.9793      Validation 0.6410\n","Validation Confusion Matrix:\n"," [[254  25]\n"," [ 28  50]]\n","\n","Epoch 41 took 16.57 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 42 of  100\n","Loss::      Train 0.0003      Validation 0.0571\n","AUC::       Train 0.9982      Validation 0.7588\n","Accuracy::  Train 0.9986      Validation 0.8683\n","F1::        Train 0.9976      Validation 0.6519\n","Precision:: Train 0.9979      Validation 0.7719\n","Recall::    Train 0.9972      Validation 0.5641\n","Validation Confusion Matrix:\n"," [[266  13]\n"," [ 34  44]]\n","\n","Epoch 42 took 17.39 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 43 of  100\n","Loss::      Train 0.0003      Validation 0.0646\n","AUC::       Train 0.9982      Validation 0.7393\n","Accuracy::  Train 0.9984      Validation 0.8235\n","F1::        Train 0.9972      Validation 0.5935\n","Precision:: Train 0.9969      Validation 0.5974\n","Recall::    Train 0.9976      Validation 0.5897\n","Validation Confusion Matrix:\n"," [[248  31]\n"," [ 32  46]]\n","\n","Epoch 43 took 16.91 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 44 of  100\n","Loss::      Train 0.0002      Validation 0.0605\n","AUC::       Train 0.9987      Validation 0.7698\n","Accuracy::  Train 0.9988      Validation 0.8711\n","F1::        Train 0.9979      Validation 0.6667\n","Precision:: Train 0.9976      Validation 0.7667\n","Recall::    Train 0.9983      Validation 0.5897\n","Validation Confusion Matrix:\n"," [[265  14]\n"," [ 32  46]]\n","\n","Epoch 44 took 17.07 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 45 of  100\n","Loss::      Train 0.0001      Validation 0.0687\n","AUC::       Train 0.9996      Validation 0.7719\n","Accuracy::  Train 0.9997      Validation 0.8599\n","F1::        Train 0.9995      Validation 0.6575\n","Precision:: Train 0.9997      Validation 0.7059\n","Recall::    Train 0.9993      Validation 0.6154\n","Validation Confusion Matrix:\n"," [[259  20]\n"," [ 30  48]]\n","\n","Epoch 45 took 16.45 seconds\n","---------------------------------------------------------------------\n","\n","Exiting training... It hit early stopping criteria of: 10 epochs\n","Saving model at: /content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/models/\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","-------------------------------\n","Best metrics for validation set on Epoch 35:\n","Loss::      0.0510\n","AUC::       0.8080\n","Accuracy::  0.8515\n","F1::        0.6826\n","Precision:: 0.6404\n","Recall::    0.7308\n","Confusion Matrix:\n"," [[247  32]\n"," [ 21  57]]\n","-------------------------------\n","\n","Performance for test set:\n","Loss::      0.0812\n","AUC::       0.7543\n","Accuracy::  0.8653\n","F1::        0.6179\n","Precision:: 0.6667\n","Recall::    0.5758\n","Confusion Matrix:\n"," [[264  19]\n"," [ 28  38]]\n","Saving predictions from trained model...\n","Computing Predictions for train set.\n","dataset size: (10278, 14)\n","Performance for test set:\n","Loss::      0.0026\n","AUC::       0.9856\n","Accuracy::  0.9899\n","F1::        0.9819\n","Precision:: 0.9881\n","Recall::    0.9758\n","Confusion Matrix:\n"," [[7352   34]\n"," [  70 2822]]\n","Computing Predictions for validation set.\n","dataset size: (357, 14)\n","Performance for test set:\n","Loss::      0.0739\n","AUC::       0.7590\n","Accuracy::  0.8543\n","F1::        0.6389\n","Precision:: 0.6970\n","Recall::    0.5897\n","Confusion Matrix:\n"," [[259  20]\n"," [ 32  46]]\n","Computing Predictions for test set.\n","dataset size: (349, 14)\n","Performance for test set:\n","Loss::      0.0812\n","AUC::       0.7543\n","Accuracy::  0.8653\n","F1::        0.6179\n","Precision:: 0.6667\n","Recall::    0.5758\n","Confusion Matrix:\n"," [[264  19]\n"," [ 28  38]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"lzKpQvscC0ou"},"source":["## Axial - Simple experiments with really shallow CNN and VGG11"]},{"cell_type":"code","metadata":{"id":"3a0vD8sFmHC8"},"source":["mri_config = {\n","'orientation':'axial',\n","'slice':75,\n","'num_samples':0,\n","'num_rotations':0,\n","'sampling_range':3,\n","'mri_reference':'/content/gdrive/MyDrive/Lucas_Thimoteo/data/reference/PROCESSED_MRI_REFERENCE_ALL_ORIENTATIONS_20211012_0206.csv',\n","'output_path':'/content/gdrive/MyDrive/Lucas_Thimoteo/data/mri/experiments/',\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ZoY1oKJmG9s","executionInfo":{"status":"ok","timestamp":1634045722105,"user_tz":180,"elapsed":1118,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"34a56731-2a70-4e29-de8d-b590ee24297a"},"source":["df = generate_mri_dataset_reference(mri_reference_path = mri_config['mri_reference'],\n","                                output_path = mri_config['output_path'],\n","                                orientation = mri_config['orientation'],\n","                                orientation_slice = mri_config['slice'],\n","                                num_sampled_images = mri_config['num_samples'],\n","                                sampling_range = mri_config['sampling_range'],\n","                                num_rotations = mri_config['num_rotations'],\n","                                save_reference_file = False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating augmented samples...\n","Creating final reference file for prepared images...\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qvZ4fqanmTgn","executionInfo":{"status":"ok","timestamp":1634046689008,"user_tz":180,"elapsed":702744,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"aa9f05bf-b1c8-4278-a486-68ce76d2c5be"},"source":["cnn_config = {\n","  'type':'shallow',\n","  'name':'shallow_cnn'\n","}\n","os.chdir('/content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/src/model_training')\n","\n","df_prediction1  = run_cnn_experiment(model_type = cnn_config['type'],\n","                    model_name = cnn_config['name'],\n","                    classes = ['AD','CN'],\n","                    mri_reference = df,\n","                    prediction_dataset_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/data/reference/',\n","                    model_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/models/',\n","                    additional_experiment_params = None)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading untrained model...\n","NeuralNetwork(\n","  (features): Sequential(\n","    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n","    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU(inplace=True)\n","    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n","    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): ReLU(inplace=True)\n","    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (12): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (13): ReLU(inplace=True)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(8, 8))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=4096, out_features=512, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU(inplace=True)\n","    (4): Linear(in_features=512, out_features=1, bias=True)\n","  )\n",")\n","\n","Total number of trainable parameters: 2385329\n","Setting up experiment parameters...\n","Train size: 1712\n","Validation size: 357\n","Test size: 349\n","\n","---------------------------------------------------------------------\n","Running Epoch 1 of  100\n","Loss::      Train 0.0376      Validation 0.0331\n","AUC::       Train 0.5022      Validation 0.5000\n","Accuracy::  Train 0.7161      Validation 0.7815\n","F1::        Train 0.0241      Validation 0.0000\n","Precision:: Train 0.3750      Validation 0.0000\n","Recall::    Train 0.0124      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 1 took 558.42 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.5000\n","\n","---------------------------------------------------------------------\n","Running Epoch 2 of  100\n","Loss::      Train 0.0370      Validation 0.0333\n","AUC::       Train 0.5000      Validation 0.5000\n","Accuracy::  Train 0.7185      Validation 0.7815\n","F1::        Train 0.0000      Validation 0.0000\n","Precision:: Train 0.0000      Validation 0.0000\n","Recall::    Train 0.0000      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 2 took 5.45 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 3 of  100\n","Loss::      Train 0.0366      Validation 0.0333\n","AUC::       Train 0.5000      Validation 0.5000\n","Accuracy::  Train 0.7185      Validation 0.7815\n","F1::        Train 0.0000      Validation 0.0000\n","Precision:: Train 0.0000      Validation 0.0000\n","Recall::    Train 0.0000      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 3 took 5.22 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 4 of  100\n","Loss::      Train 0.0356      Validation 0.0333\n","AUC::       Train 0.5010      Validation 0.5000\n","Accuracy::  Train 0.7190      Validation 0.7815\n","F1::        Train 0.0041      Validation 0.0000\n","Precision:: Train 1.0000      Validation 0.0000\n","Recall::    Train 0.0021      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 4 took 4.06 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 5 of  100\n","Loss::      Train 0.0340      Validation 0.0337\n","AUC::       Train 0.5216      Validation 0.5000\n","Accuracy::  Train 0.7278      Validation 0.7815\n","F1::        Train 0.0934      Validation 0.0000\n","Precision:: Train 0.7500      Validation 0.0000\n","Recall::    Train 0.0498      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 5 took 5.41 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 6 of  100\n","Loss::      Train 0.0318      Validation 0.0344\n","AUC::       Train 0.5918      Validation 0.4982\n","Accuracy::  Train 0.7570      Validation 0.7787\n","F1::        Train 0.3312      Validation 0.0000\n","Precision:: Train 0.7357      Validation 0.0000\n","Recall::    Train 0.2137      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[278   1]\n"," [ 78   0]]\n","\n","Epoch 6 took 5.31 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 7 of  100\n","Loss::      Train 0.0284      Validation 0.0343\n","AUC::       Train 0.6915      Validation 0.5046\n","Accuracy::  Train 0.8014      Validation 0.7815\n","F1::        Train 0.5550      Validation 0.0250\n","Precision:: Train 0.7518      Validation 0.5000\n","Recall::    Train 0.4398      Validation 0.0128\n","Validation Confusion Matrix:\n"," [[278   1]\n"," [ 77   1]]\n","\n","Epoch 7 took 5.35 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.5046\n","\n","---------------------------------------------------------------------\n","Running Epoch 8 of  100\n","Loss::      Train 0.0229      Validation 0.0389\n","AUC::       Train 0.7779      Validation 0.5288\n","Accuracy::  Train 0.8522      Validation 0.7255\n","F1::        Train 0.6985      Validation 0.2222\n","Precision:: Train 0.8207      Validation 0.2917\n","Recall::    Train 0.6079      Validation 0.1795\n","Validation Confusion Matrix:\n"," [[245  34]\n"," [ 64  14]]\n","\n","Epoch 8 took 4.12 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.5288\n","\n","---------------------------------------------------------------------\n","Running Epoch 9 of  100\n","Loss::      Train 0.0163      Validation 0.0416\n","AUC::       Train 0.8763      Validation 0.5375\n","Accuracy::  Train 0.9147      Validation 0.7535\n","F1::        Train 0.8389      Validation 0.2143\n","Precision:: Train 0.8962      Validation 0.3529\n","Recall::    Train 0.7884      Validation 0.1538\n","Validation Confusion Matrix:\n"," [[257  22]\n"," [ 66  12]]\n","\n","Epoch 9 took 5.47 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.5375\n","\n","---------------------------------------------------------------------\n","Running Epoch 10 of  100\n","Loss::      Train 0.0115      Validation 0.0458\n","AUC::       Train 0.9257      Validation 0.5419\n","Accuracy::  Train 0.9486      Validation 0.7171\n","F1::        Train 0.9054      Validation 0.2628\n","Precision:: Train 0.9397      Validation 0.3051\n","Recall::    Train 0.8734      Validation 0.2308\n","Validation Confusion Matrix:\n"," [[238  41]\n"," [ 60  18]]\n","\n","Epoch 10 took 5.46 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.5419\n","\n","---------------------------------------------------------------------\n","Running Epoch 11 of  100\n","Loss::      Train 0.0072      Validation 0.0549\n","AUC::       Train 0.9568      Validation 0.5387\n","Accuracy::  Train 0.9696      Validation 0.6471\n","F1::        Train 0.9450      Validation 0.3000\n","Precision:: Train 0.9634      Validation 0.2647\n","Recall::    Train 0.9274      Validation 0.3462\n","Validation Confusion Matrix:\n"," [[204  75]\n"," [ 51  27]]\n","\n","Epoch 11 took 5.09 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 12 of  100\n","Loss::      Train 0.0046      Validation 0.0624\n","AUC::       Train 0.9729      Validation 0.5318\n","Accuracy::  Train 0.9819      Validation 0.6218\n","F1::        Train 0.9673      Validation 0.3005\n","Precision:: Train 0.9829      Validation 0.2522\n","Recall::    Train 0.9523      Validation 0.3718\n","Validation Confusion Matrix:\n"," [[193  86]\n"," [ 49  29]]\n","\n","Epoch 12 took 5.17 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 13 of  100\n","Loss::      Train 0.0047      Validation 0.0542\n","AUC::       Train 0.9706      Validation 0.5183\n","Accuracy::  Train 0.9796      Validation 0.7451\n","F1::        Train 0.9632      Validation 0.1651\n","Precision:: Train 0.9765      Validation 0.2903\n","Recall::    Train 0.9502      Validation 0.1154\n","Validation Confusion Matrix:\n"," [[257  22]\n"," [ 69   9]]\n","\n","Epoch 13 took 4.98 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 14 of  100\n","Loss::      Train 0.0082      Validation 0.0587\n","AUC::       Train 0.9328      Validation 0.5141\n","Accuracy::  Train 0.9515      Validation 0.7675\n","F1::        Train 0.9118      Validation 0.1075\n","Precision:: Train 0.9346      Validation 0.3333\n","Recall::    Train 0.8900      Validation 0.0641\n","Validation Confusion Matrix:\n"," [[269  10]\n"," [ 73   5]]\n","\n","Epoch 14 took 3.92 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 15 of  100\n","Loss::      Train 0.0071      Validation 0.0531\n","AUC::       Train 0.9432      Validation 0.5398\n","Accuracy::  Train 0.9574      Validation 0.7787\n","F1::        Train 0.9232      Validation 0.1856\n","Precision:: Train 0.9360      Validation 0.4737\n","Recall::    Train 0.9108      Validation 0.1154\n","Validation Confusion Matrix:\n"," [[269  10]\n"," [ 69   9]]\n","\n","Epoch 15 took 5.30 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 16 of  100\n","Loss::      Train 0.0064      Validation 0.0589\n","AUC::       Train 0.9525      Validation 0.4974\n","Accuracy::  Train 0.9644      Validation 0.7703\n","F1::        Train 0.9360      Validation 0.0238\n","Precision:: Train 0.9469      Validation 0.1667\n","Recall::    Train 0.9253      Validation 0.0128\n","Validation Confusion Matrix:\n"," [[274   5]\n"," [ 77   1]]\n","\n","Epoch 16 took 5.24 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 17 of  100\n","Loss::      Train 0.0044      Validation 0.0721\n","AUC::       Train 0.9671      Validation 0.5028\n","Accuracy::  Train 0.9772      Validation 0.7787\n","F1::        Train 0.9589      Validation 0.0247\n","Precision:: Train 0.9743      Validation 0.3333\n","Recall::    Train 0.9440      Validation 0.0128\n","Validation Confusion Matrix:\n"," [[277   2]\n"," [ 77   1]]\n","\n","Epoch 17 took 5.32 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 18 of  100\n","Loss::      Train 0.0040      Validation 0.0759\n","AUC::       Train 0.9713      Validation 0.4946\n","Accuracy::  Train 0.9778      Validation 0.7731\n","F1::        Train 0.9604      Validation 0.0000\n","Precision:: Train 0.9644      Validation 0.0000\n","Recall::    Train 0.9564      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[276   3]\n"," [ 78   0]]\n","\n","Epoch 18 took 4.18 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 19 of  100\n","Loss::      Train 0.0027      Validation 0.0655\n","AUC::       Train 0.9843      Validation 0.5123\n","Accuracy::  Train 0.9883      Validation 0.7647\n","F1::        Train 0.9792      Validation 0.1064\n","Precision:: Train 0.9833      Validation 0.3125\n","Recall::    Train 0.9751      Validation 0.0641\n","Validation Confusion Matrix:\n"," [[268  11]\n"," [ 73   5]]\n","\n","Epoch 19 took 5.08 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 20 of  100\n","Loss::      Train 0.0012      Validation 0.0678\n","AUC::       Train 0.9948      Validation 0.5301\n","Accuracy::  Train 0.9971      Validation 0.7563\n","F1::        Train 0.9948      Validation 0.1869\n","Precision:: Train 1.0000      Validation 0.3448\n","Recall::    Train 0.9896      Validation 0.1282\n","Validation Confusion Matrix:\n"," [[260  19]\n"," [ 68  10]]\n","\n","Epoch 20 took 5.13 seconds\n","---------------------------------------------------------------------\n","\n","Exiting training... It hit early stopping criteria of: 10 epochs\n","Saving model at: /content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/models/\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","-------------------------------\n","Best metrics for validation set on Epoch 10:\n","Loss::      0.0458\n","AUC::       0.5419\n","Accuracy::  0.7171\n","F1::        0.2628\n","Precision:: 0.3051\n","Recall::    0.2308\n","Confusion Matrix:\n"," [[238  41]\n"," [ 60  18]]\n","-------------------------------\n","\n","Performance for test set:\n","Loss::      0.0498\n","AUC::       0.6273\n","Accuracy::  0.8195\n","F1::        0.4000\n","Precision:: 0.5385\n","Recall::    0.3182\n","Confusion Matrix:\n"," [[265  18]\n"," [ 45  21]]\n","Saving predictions from trained model...\n","Computing Predictions for train set.\n","dataset size: (1712, 14)\n","Performance for test set:\n","Loss::      0.0039\n","AUC::       0.9602\n","Accuracy::  0.9772\n","F1::        0.9579\n","Precision:: 0.9978\n","Recall::    0.9212\n","Confusion Matrix:\n"," [[1229    1]\n"," [  38  444]]\n","Computing Predictions for validation set.\n","dataset size: (357, 14)\n","Performance for test set:\n","Loss::      0.0653\n","AUC::       0.5280\n","Accuracy::  0.7675\n","F1::        0.1616\n","Precision:: 0.3810\n","Recall::    0.1026\n","Confusion Matrix:\n"," [[266  13]\n"," [ 70   8]]\n","Computing Predictions for test set.\n","dataset size: (349, 14)\n","Performance for test set:\n","Loss::      0.0498\n","AUC::       0.6273\n","Accuracy::  0.8195\n","F1::        0.4000\n","Precision:: 0.5385\n","Recall::    0.3182\n","Confusion Matrix:\n"," [[265  18]\n"," [ 45  21]]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"keK3y0sYt1aU","executionInfo":{"status":"ok","timestamp":1634046836695,"user_tz":180,"elapsed":147694,"user":{"displayName":"LIRA PUC-Rio","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08755616930299333039"}},"outputId":"a321c8cf-d8a9-44be-c62c-278c1c5391fd"},"source":["cnn_config = {\n","  'type':'vgg11',\n","  'name':'vgg11_2048'\n","}\n","os.chdir('/content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/src/model_training')\n","\n","df_prediction2  = run_cnn_experiment(model_type = cnn_config['type'],\n","                    model_name = cnn_config['name'],\n","                    classes = ['AD','CN'],\n","                    mri_reference = df,\n","                    prediction_dataset_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/data/reference/',\n","                    model_path = '/content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/models/',\n","                    additional_experiment_params = None)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading untrained model...\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (12): ReLU(inplace=True)\n","    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (14): ReLU(inplace=True)\n","    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (17): ReLU(inplace=True)\n","    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (19): ReLU(inplace=True)\n","    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=2048, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=2048, out_features=2048, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=2048, out_features=1, bias=True)\n","  )\n",")\n","\n","Total number of trainable parameters: 64800001\n","Setting up experiment parameters...\n","Train size: 1712\n","Validation size: 357\n","Test size: 349\n","\n","---------------------------------------------------------------------\n","Running Epoch 1 of  100\n","Loss::      Train 0.0391      Validation 0.0335\n","AUC::       Train 0.4992      Validation 0.5000\n","Accuracy::  Train 0.7155      Validation 0.7815\n","F1::        Train 0.0081      Validation 0.0000\n","Precision:: Train 0.2222      Validation 0.0000\n","Recall::    Train 0.0041      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 1 took 6.06 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.5000\n","\n","---------------------------------------------------------------------\n","Running Epoch 2 of  100\n","Loss::      Train 0.0383      Validation 0.0345\n","AUC::       Train 0.5000      Validation 0.5000\n","Accuracy::  Train 0.7185      Validation 0.7815\n","F1::        Train 0.0000      Validation 0.0000\n","Precision:: Train 0.0000      Validation 0.0000\n","Recall::    Train 0.0000      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 2 took 5.02 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 3 of  100\n","Loss::      Train 0.0376      Validation 0.0343\n","AUC::       Train 0.5000      Validation 0.5000\n","Accuracy::  Train 0.7185      Validation 0.7815\n","F1::        Train 0.0000      Validation 0.0000\n","Precision:: Train 0.0000      Validation 0.0000\n","Recall::    Train 0.0000      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 3 took 7.67 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 4 of  100\n","Loss::      Train 0.0373      Validation 0.0330\n","AUC::       Train 0.5000      Validation 0.5000\n","Accuracy::  Train 0.7185      Validation 0.7815\n","F1::        Train 0.0000      Validation 0.0000\n","Precision:: Train 0.0000      Validation 0.0000\n","Recall::    Train 0.0000      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 4 took 5.41 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 5 of  100\n","Loss::      Train 0.0372      Validation 0.0326\n","AUC::       Train 0.5000      Validation 0.5000\n","Accuracy::  Train 0.7185      Validation 0.7815\n","F1::        Train 0.0000      Validation 0.0000\n","Precision:: Train 0.0000      Validation 0.0000\n","Recall::    Train 0.0000      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 5 took 5.02 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 6 of  100\n","Loss::      Train 0.0369      Validation 0.0329\n","AUC::       Train 0.5000      Validation 0.5000\n","Accuracy::  Train 0.7185      Validation 0.7815\n","F1::        Train 0.0000      Validation 0.0000\n","Precision:: Train 0.0000      Validation 0.0000\n","Recall::    Train 0.0000      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 6 took 5.30 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 7 of  100\n","Loss::      Train 0.0372      Validation 0.0331\n","AUC::       Train 0.5000      Validation 0.5000\n","Accuracy::  Train 0.7185      Validation 0.7815\n","F1::        Train 0.0000      Validation 0.0000\n","Precision:: Train 0.0000      Validation 0.0000\n","Recall::    Train 0.0000      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 7 took 4.99 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 8 of  100\n","Loss::      Train 0.0366      Validation 0.0332\n","AUC::       Train 0.5000      Validation 0.5000\n","Accuracy::  Train 0.7185      Validation 0.7815\n","F1::        Train 0.0000      Validation 0.0000\n","Precision:: Train 0.0000      Validation 0.0000\n","Recall::    Train 0.0000      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 8 took 5.54 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 9 of  100\n","Loss::      Train 0.0358      Validation 0.0328\n","AUC::       Train 0.5000      Validation 0.5000\n","Accuracy::  Train 0.7185      Validation 0.7815\n","F1::        Train 0.0000      Validation 0.0000\n","Precision:: Train 0.0000      Validation 0.0000\n","Recall::    Train 0.0000      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 9 took 5.34 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 10 of  100\n","Loss::      Train 0.0336      Validation 0.0324\n","AUC::       Train 0.5000      Validation 0.5000\n","Accuracy::  Train 0.7185      Validation 0.7815\n","F1::        Train 0.0000      Validation 0.0000\n","Precision:: Train 0.0000      Validation 0.0000\n","Recall::    Train 0.0000      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[279   0]\n"," [ 78   0]]\n","\n","Epoch 10 took 5.37 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 11 of  100\n","Loss::      Train 0.0306      Validation 0.0324\n","AUC::       Train 0.6131      Validation 0.5316\n","Accuracy::  Train 0.7558      Validation 0.7731\n","F1::        Train 0.3977      Validation 0.1649\n","Precision:: Train 0.6509      Validation 0.4211\n","Recall::    Train 0.2863      Validation 0.1026\n","Validation Confusion Matrix:\n"," [[268  11]\n"," [ 70   8]]\n","\n","Epoch 11 took 5.38 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.5316\n","\n","---------------------------------------------------------------------\n","Running Epoch 12 of  100\n","Loss::      Train 0.0278      Validation 0.0318\n","AUC::       Train 0.7335      Validation 0.5416\n","Accuracy::  Train 0.8037      Validation 0.7815\n","F1::        Train 0.6216      Validation 0.1875\n","Precision:: Train 0.6798      Validation 0.5000\n","Recall::    Train 0.5726      Validation 0.1154\n","Validation Confusion Matrix:\n"," [[270   9]\n"," [ 69   9]]\n","\n","Epoch 12 took 5.20 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.5416\n","\n","---------------------------------------------------------------------\n","Running Epoch 13 of  100\n","Loss::      Train 0.0230      Validation 0.0413\n","AUC::       Train 0.7967      Validation 0.5077\n","Accuracy::  Train 0.8493      Validation 0.7647\n","F1::        Train 0.7165      Validation 0.0870\n","Precision:: Train 0.7617      Validation 0.2857\n","Recall::    Train 0.6763      Validation 0.0513\n","Validation Confusion Matrix:\n"," [[269  10]\n"," [ 74   4]]\n","\n","Epoch 13 took 5.25 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 14 of  100\n","Loss::      Train 0.0181      Validation 0.0497\n","AUC::       Train 0.8595      Validation 0.5306\n","Accuracy::  Train 0.8879      Validation 0.7283\n","F1::        Train 0.7996      Validation 0.2240\n","Precision:: Train 0.8046      Validation 0.2979\n","Recall::    Train 0.7946      Validation 0.1795\n","Validation Confusion Matrix:\n"," [[246  33]\n"," [ 64  14]]\n","\n","Epoch 14 took 5.28 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 15 of  100\n","Loss::      Train 0.0153      Validation 0.0456\n","AUC::       Train 0.8882      Validation 0.5524\n","Accuracy::  Train 0.9083      Validation 0.7479\n","F1::        Train 0.8380      Validation 0.2623\n","Precision:: Train 0.8337      Validation 0.3636\n","Recall::    Train 0.8423      Validation 0.2051\n","Validation Confusion Matrix:\n"," [[251  28]\n"," [ 62  16]]\n","\n","Epoch 15 took 5.29 seconds\n","---------------------------------------------------------------------\n","Best validation AUC so far: 0.5524\n","\n","---------------------------------------------------------------------\n","Running Epoch 16 of  100\n","Loss::      Train 0.0133      Validation 0.0438\n","AUC::       Train 0.8984      Validation 0.5188\n","Accuracy::  Train 0.9229      Validation 0.7171\n","F1::        Train 0.8602      Validation 0.2047\n","Precision:: Train 0.8788      Validation 0.2653\n","Recall::    Train 0.8423      Validation 0.1667\n","Validation Confusion Matrix:\n"," [[243  36]\n"," [ 65  13]]\n","\n","Epoch 16 took 5.33 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 17 of  100\n","Loss::      Train 0.0128      Validation 0.0604\n","AUC::       Train 0.9076      Validation 0.5113\n","Accuracy::  Train 0.9270      Validation 0.7703\n","F1::        Train 0.8694      Validation 0.0889\n","Precision:: Train 0.8758      Validation 0.3333\n","Recall::    Train 0.8631      Validation 0.0513\n","Validation Confusion Matrix:\n"," [[271   8]\n"," [ 74   4]]\n","\n","Epoch 17 took 5.26 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 18 of  100\n","Loss::      Train 0.0090      Validation 0.0834\n","AUC::       Train 0.9288      Validation 0.4895\n","Accuracy::  Train 0.9457      Validation 0.7507\n","F1::        Train 0.9022      Validation 0.0430\n","Precision:: Train 0.9147      Validation 0.1333\n","Recall::    Train 0.8900      Validation 0.0256\n","Validation Confusion Matrix:\n"," [[266  13]\n"," [ 76   2]]\n","\n","Epoch 18 took 5.61 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 19 of  100\n","Loss::      Train 0.0066      Validation 0.0900\n","AUC::       Train 0.9594      Validation 0.4931\n","Accuracy::  Train 0.9644      Validation 0.7563\n","F1::        Train 0.9374      Validation 0.0440\n","Precision:: Train 0.9270      Validation 0.1538\n","Recall::    Train 0.9481      Validation 0.0256\n","Validation Confusion Matrix:\n"," [[268  11]\n"," [ 76   2]]\n","\n","Epoch 19 took 5.30 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 20 of  100\n","Loss::      Train 0.0049      Validation 0.0946\n","AUC::       Train 0.9633      Validation 0.4959\n","Accuracy::  Train 0.9708      Validation 0.7535\n","F1::        Train 0.9480      Validation 0.0638\n","Precision:: Train 0.9500      Validation 0.1875\n","Recall::    Train 0.9461      Validation 0.0385\n","Validation Confusion Matrix:\n"," [[266  13]\n"," [ 75   3]]\n","\n","Epoch 20 took 5.29 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 21 of  100\n","Loss::      Train 0.0041      Validation 0.1087\n","AUC::       Train 0.9738      Validation 0.4939\n","Accuracy::  Train 0.9778      Validation 0.7647\n","F1::        Train 0.9607      Validation 0.0233\n","Precision:: Train 0.9568      Validation 0.1250\n","Recall::    Train 0.9647      Validation 0.0128\n","Validation Confusion Matrix:\n"," [[272   7]\n"," [ 77   1]]\n","\n","Epoch 21 took 5.08 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 22 of  100\n","Loss::      Train 0.0041      Validation 0.1156\n","AUC::       Train 0.9705      Validation 0.4857\n","Accuracy::  Train 0.9766      Validation 0.7591\n","F1::        Train 0.9584      Validation 0.0000\n","Precision:: Train 0.9604      Validation 0.0000\n","Recall::    Train 0.9564      Validation 0.0000\n","Validation Confusion Matrix:\n"," [[271   8]\n"," [ 78   0]]\n","\n","Epoch 22 took 5.31 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 23 of  100\n","Loss::      Train 0.0028      Validation 0.1286\n","AUC::       Train 0.9792      Validation 0.5095\n","Accuracy::  Train 0.9836      Validation 0.7675\n","F1::        Train 0.9709      Validation 0.0879\n","Precision:: Train 0.9729      Validation 0.3077\n","Recall::    Train 0.9689      Validation 0.0513\n","Validation Confusion Matrix:\n"," [[270   9]\n"," [ 74   4]]\n","\n","Epoch 23 took 5.08 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 24 of  100\n","Loss::      Train 0.0055      Validation 0.1189\n","AUC::       Train 0.9572      Validation 0.4941\n","Accuracy::  Train 0.9685      Validation 0.7507\n","F1::        Train 0.9433      Validation 0.0632\n","Precision:: Train 0.9553      Validation 0.1765\n","Recall::    Train 0.9315      Validation 0.0385\n","Validation Confusion Matrix:\n"," [[265  14]\n"," [ 75   3]]\n","\n","Epoch 24 took 5.61 seconds\n","---------------------------------------------------------------------\n","\n","---------------------------------------------------------------------\n","Running Epoch 25 of  100\n","Loss::      Train 0.0050      Validation 0.0700\n","AUC::       Train 0.9640      Validation 0.5508\n","Accuracy::  Train 0.9737      Validation 0.7815\n","F1::        Train 0.9528      Validation 0.2200\n","Precision:: Train 0.9639      Validation 0.5000\n","Recall::    Train 0.9419      Validation 0.1410\n","Validation Confusion Matrix:\n"," [[268  11]\n"," [ 67  11]]\n","\n","Epoch 25 took 5.26 seconds\n","---------------------------------------------------------------------\n","\n","Exiting training... It hit early stopping criteria of: 10 epochs\n","Saving model at: /content/gdrive/MyDrive/Lucas_Thimoteo/mmml-alzheimer-diagnosis/models/\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","-------------------------------\n","Best metrics for validation set on Epoch 15:\n","Loss::      0.0456\n","AUC::       0.5524\n","Accuracy::  0.7479\n","F1::        0.2623\n","Precision:: 0.3636\n","Recall::    0.2051\n","Confusion Matrix:\n"," [[251  28]\n"," [ 62  16]]\n","-------------------------------\n","\n","Performance for test set:\n","Loss::      0.0570\n","AUC::       0.5849\n","Accuracy::  0.8166\n","F1::        0.3043\n","Precision:: 0.5385\n","Recall::    0.2121\n","Confusion Matrix:\n"," [[271  12]\n"," [ 52  14]]\n","Saving predictions from trained model...\n","Computing Predictions for train set.\n","dataset size: (1712, 14)\n","Performance for test set:\n","Loss::      0.0055\n","AUC::       0.9388\n","Accuracy::  0.9655\n","F1::        0.9348\n","Precision:: 1.0000\n","Recall::    0.8776\n","Confusion Matrix:\n"," [[1230    0]\n"," [  59  423]]\n","Computing Predictions for validation set.\n","dataset size: (357, 14)\n","Performance for test set:\n","Loss::      0.0704\n","AUC::       0.5426\n","Accuracy::  0.7759\n","F1::        0.2000\n","Precision:: 0.4545\n","Recall::    0.1282\n","Confusion Matrix:\n"," [[267  12]\n"," [ 68  10]]\n","Computing Predictions for test set.\n","dataset size: (349, 14)\n","Performance for test set:\n","Loss::      0.0570\n","AUC::       0.5849\n","Accuracy::  0.8166\n","F1::        0.3043\n","Precision:: 0.5385\n","Recall::    0.2121\n","Confusion Matrix:\n"," [[271  12]\n"," [ 52  14]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"UnqR_CGXG_F-"},"source":["## Coronal - Trying other architectures"]},{"cell_type":"code","metadata":{"id":"F-HRbZMDHB6f"},"source":["import torch\n","# from torch.nn.functional import one_hot\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","from torch.nn import Linear, ReLU, BCEWithLogitsLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, AdaptiveAvgPool2d\n","from torch.optim import Adam, SGD\n","\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda, Compose\n","import torchvision.models as models\n","\n","class NeuralNetwork(Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.features = Sequential(\n","            Conv2d(in_channels =1, out_channels =8, kernel_size=3, stride=1, padding=1),\n","            BatchNorm2d(num_features=8),\n","            ReLU(inplace=True),\n","            MaxPool2d(2,2),\n","\n","            Conv2d(in_channels =8, out_channels =16, kernel_size=3, stride=1, padding=0),\n","            BatchNorm2d(num_features=16),\n","            ReLU(inplace=True),\n","            MaxPool2d(2,2),\n","            \n","            Conv2d(in_channels =16, out_channels =32, kernel_size=3, stride=1, padding=0),\n","            BatchNorm2d(num_features=32),\n","            ReLU(inplace=True),\n","            MaxPool2d(2,2),\n","            \n","            Conv2d(in_channels =32, out_channels =64, kernel_size=3, stride=1, padding=0),\n","            ReLU(inplace=True)\n","        )\n","        self.avgpool = AdaptiveAvgPool2d(output_size=(8, 8))\n","        self.classifier = Sequential(\n","            # Remember changing the x.view() number as well. It needs to be flattenend!\n","            Linear(in_features=64*8*8, out_features=512, bias=True),\n","            ReLU(inplace=True),\n","            # Dropout(p=0.5, inplace=False),\n","            Linear(in_features=512, out_features=512, bias=True),\n","            ReLU(inplace=True),\n","            # Dropout(p=0.5, inplace=False),\n","            # Linear(in_features=512, out_features=512, bias=True),\n","            # ReLU(inplace=True),\n","            # Dropout(p=0.5, inplace=False),\n","            Linear(in_features=512, out_features=1, bias=True)\n","\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.avgpool(x)\n","        # flattenning \n","        x = x.view(-1,64*8*8)\n","        logits = self.classifier(x)\n","        return logits\n","\n","def create_adapted_vgg11():\n","    vgg = models.vgg11()\n","    vgg.features[0] = Conv2d(1,64, 3, stride=1,padding=1)\n","    vgg.classifier[0] = Linear(in_features=7*7*512, out_features=2048,bias=True)\n","    vgg.classifier[3] = Linear(in_features=2048, out_features=2048,bias=True)\n","    vgg.classifier[-1] = Linear(in_features=2048, out_features=1,bias=True)\n","    return vgg"],"execution_count":null,"outputs":[]}]}